Thesis Title	Thesis Abstract
"21I-2191 Laraib Afzal



Prosodic alignment for Automatic dubbing

"	Automatic dubbing is the process of replacing the audio track of a video with a different language. In automatic dubbing, prosodic alignment is used to match the suprasegmental features like timbre, prosody, duration, pauses and intonation of the original speech with synthesed speech, in order to produce a natural-sounding dubbed video. This is done by analyzing and mapping these features of the original and translated speech. Existing research on automatic dubbing lack to addresses these features in source video which impact the overall naturalness and fluency of Synthesized speech. To solve this we proposed end-to-end architecture, following modular approach, to generate high quality dubbed video. In this research, we mainly focus on TTS module by considering mentioned features for prosodic alignment in generated speech with synchronization of original utterance. We train our model learn to predict the suprasegmental features of the input voice and generate synthesized speech that matches the pattern of stress and intonation of the input voice. This help our proposed model to create a more natural and coherent output and improve the overall accuracy of end to end architecture. We explore auto-regressive decoder models and Constructive voice-voice pre-training model for our TTS module. We used a common voice English dataset which contains English text and corresponding voices. To evaluate our model we perform Quantitative Evaluation by calculating Mel Cepstral Distortion (MCD) with Dynamic Time Warping (DTW) and Word Error Rate.
"21I-2195 Ansa Liaqat


Boundary-Aware Multiscale Brain Tumor Segmentation 
with a Compact Model using Spatial Pyramid Pooling"	One of the most difficult tasks in medical image analysis is brain tumor segmentation. To accurately delineate the regions of brain tumors is the aim of brain tumor segmentation. Deep learning techniques have recently shown promising results in resolving a variety of computer vision problems, including semantic segmentation, object detection, and image classification. Many deep learning-based techniques have been used to segment brain tumors, and the results are encouraging. Existing studies propose solutions for brain tumor segmentation with large computing resources. Our goal is to minimize computational time. We first segment the tumor region on the basis of which we crop the images. Then sent to networks for accurate and fast segmentation of sub-regions.
"21I-2225 Maryam Shahbaz


Leukemia Type Classification and Identification of Cause-
Effect Relationship on Clinical Datasets"	"Data related to leukemia was collected from 209 countries and territories in 2019 by [1], which identified it as the most common cancer among children. Therefore, it is crucial to adopt a lifestyle that can help prevent leukemia. Although similar research has been conducted previously,but it has not been carried out specifically in Pakistan. People may have different lifestyles due to varying regions. In this study, we aimed to identify the lifestyle and demographic factors associated with the development of leukemia and predict the type of leukemia using clinical data. We collected data from a sample of 1258 individuals from IBGE Islamabad, Pakistan, which was categorized into laboratory, demographic, and lifestyle data.To analyze the demographic and lifestyle data, XGBoost, odd ratios, and CDR are utilized to predict the risk of leukemia. Our findings suggest that passive smoking, residing in rural areas, exposure to a polluted environment, poor nutrition, and lack of perfume usage increase the likelihood of developing leukemia. Similarly, from demographic perspective, children are more vulnerable to leukemia. Furthermore, we
transformed the complete clinical data into neo4j graph data and utilized it to classify the type of leukemia. Comparing the accuracy of our classification using both graph and tabular data, tabular data demonstrated higher accuracy, achieving a 96% accuracy rate on over-sampled data using random forest algorithm."
"21I-2313 Khadija Mahmood


Improvement of deep learning model for Human Pose Estimation"	Human Pose Estimation has gained high prominence in the computer vision domain because of its wide variety of demands in real-world applications. Fast inference time for estimating human poses is highly required such as action recognition of humans by robots for responding, human-computer interaction, and augmented reality. However, Existing State-of-the-art Multi-Person pose estimation methods require heavy computational resources for accurate predictions sacrificing Time Efficiency due to utilizing over-parameterized models. In this work, a compressed architecture based on deep neural networks for gaining time and resource efficiency has been proposed named: Distill Transpose. Distill Transpose consists of three modules feature extractor, distill encoder, and head. Feature extractor utilizes MobileNet network with the minor modification of removing the downsampling layer outputs high-resolution feature maps. Distill encoder is the compressed structure of the transformer’s encoder in which pruning-based methods have been used for the compression generating heat maps. The Final Head Module is a post-processing method used for refining the heat maps, giving the final predicted human body key points. The benchmark datasets: COCO and MPII human pose shall be used for this work
"20I-2014 - Mutahher Mahmood


A Smart IDS in IoT Systems to Detect Zero-day Attacks using Automated 
Signature update"	Protecting industry infrastructure from cyber-attacks is the necessity of time. We are using Firewalls, Anti-viruses, IPS (Intrusion Prevention Systems) and IDS (Intrusion Detection Systems), etc., to make our industry perimeter secure. But we also face zero-day attacks and we can’t prevent them. There is a need for smart IDS that can detect intrusion in networks and systems, and prevent them as well. We heard of zero-day attacks and now every industry is facing them. The death of the Perimeter term in cybersecurity defines that we can’t make our infrastructure 100% secure. Some previous work is already been done to detect zero-day attacks in networks, and they are using different approaches based on anomaly detection using Machine Learning algorithms. Machine Learning provides many benefits including and not limited to zero-day attacks by analyzing previously learned and trained datasets. ML algorithms are limited to false-positives and false-negatives and that leads to less accurate results. Our approach is using old-fashioned signature-based detection, which guarantees 100% accuracy but is limited to a zero-day attack. To handle zero-day attacks, we’re using our approach with the latest ML algorithms to detect zero-day intrusion in a network and update their signatures automatically. Our approach will guarantee prevention from known threatsusing signatures and more accuracy in the detection of zero-day attacks by using ML algorithms.
"21I-2231 -Ayesha Aziz


Anomaly Detection of Logs using Machine Learning"	The detection of anomalies is critical for computer system security and reliability. In almost every computer system, logs are the primary source for anomaly detection methods. General information, errors, warnings, and debugging information are all contained in these logs. Previous detection methods, due to log-parsing imperfections, tended to lose the semantic meaning of log messages, resulting in inaccurate detection results. Deep learning-based methods such as Deeplog and LogAnomaly techniques are used but they are incapable of detecting anomalies in log structures. There are numerous issues with testing large-scale systems that are rapidly changing states. When automated testing fails to identify problems, manual log analysis is required. Can we do this in real-time when any unseen data is given and reduce the false alarms? To address such issues, in this research, we propose a hybrid anomaly detection approach that combines unsupervised techniques such as Self-Organizing Maps, Bert Encoder, and Autoencoders to detect anomalies in log data. The proposed approach utilizes Bert Encoder to generate semantic vectors for log messages and Autoencoders to learn the underlying patterns in the data. The Self-Organizing Map is then used to cluster the learned features into a low-dimensional representation, which facilitates the iden- tification of anomalies. The experimental results show that the proposed approach can detect anomalies with higher accuracy compared to traditional methods. The proposed approach can be useful for detecting anomalies in various domains, including system logs, network traffic, and financial transactions.
"21I-2237 - Jalaluddin Hashmi



Influence Preserving Graph Summarization using Weighted LSH at 
Billion-Scale"	Graph data is a valuable resource that is used to represent complex relationships and patterns in a variety of applications. Its importance has grown with the rise of big data, as it can help to uncover hidden patterns and insights in large and complex datasets. [3] Graph data plays a critical role in data analysis and machine learning, facilitating better understanding of complex data and supporting decision-making processes. Graphs can contain thousands or even millions of nodes and edges, making them difficult to visualize, process, and analyze efficiently. So [5] Graph summarization is a form of compression to enable the efficient and effective analysis of the large and complex graph data. Traditional graph summarization techniques typically aim to capture the most significant features of the graph as a whole. However, in many cases, this approach may not be sufficient, especially in applications where the graph data is personalized or context-specific. [6] For example, in social networks, different users have distinct patterns of connections, interests, and influence, and a generalized summary of the network may not capture these individual differences accurately. So the question is how to obtain the compressed form of graph by preserving the influence and importance of the specific data in the graph? In this work, we introduce a new problem, namely Influence preserving graph summarization, where our aim is to obtain the summary graph based on the specific user or preserve the influence, importance, or impact of the specific user on graph data. Influence preserving is essential in such cases, as it tailors the summary to the specific user or context, improving the accuracy and effectiveness of graph analysis. The aim of influence-preserving graph summarization is to obtain the summary graph while preserving the influence, importance, or impact of a specific user on graph data. Applications of influence preserving or personalized graph summarization include social networks, citation network personalized advertising, and recommendation systems.
"20I-1201- Muhammad Zulqarnain


Evaluating Robustness of Deep Learning Models in Radiology"	Deep neural networks have gained significant popularity in various disciplines including computer vision, natural languag e processing and medical images processing. However, recent research shows that these models exhibit unexpected behavior when exposed to small variations in the data, indicating their fragility. This study focuses on evaluating the robustness of deep learning models against variations in the radiology datasets caused by external noise, scanner equipment, and scanner parameters. Al-though accuracy is a crucial metric, it is inadequate in evaluating model performance in the presence of data variations. We evaluated the model’s robustness by performing various perturbations, including pixel-wise random noise, blurring, brightness and contrast adjustments, geometric perturbations, scaling, image-specific perturbations, and universal perturbations. Among these experiments, image-specific perturbations have a high impact on the model performance, the models misclassified 84% for the ACL dataset and 42% for the Breast dataset, demonstrating the susceptibility of deep models. To quantify the model’s robustness, we propose a framework that can evaluate model’s robustness against such data variations.
"20I-2215 -Irfan Danish



Spatio-Temporal Scene Graph Generation"	A scene graph is a structured characterization of a visual scene that effectively illus trates the objects, qualities, and connections between objects within the scene. The scene graph serves as a comprehensive depiction of a scene, offering significant advantages in various computer vision tasks including image retrieval, captioning of images and videos, visual question answering (VQA), relationship detection, and image gener tion. Currently, several research studies have been presented regarding the generation of scene graphs for images, but very less attention has been paid to video scene graph generation. As compared to images, it is more difficult to enerate a scene graph from videos because of the dynamic nature of relationships among objects and their temporal interdependence across frames, allowing for a deeper semantic interpretation. In our work, we present the STSGG model, comprising of the two-stream spatial and temporal backbone with a Modified STTran head to generate the Scene Graph.
"21I-2295 Muhammad Ammar



Disaster response identification for multi-modal data using
Text-Image Attention Layer Mechanism (Novel)"	"The research paper focuses on addressing the challenge of classifying social media posts related to disasters by utilizing and processing both text and image data in parallel. The primary objective is to develop a robust  rchitecture that combines the strengths of Natural Language Processing (NLP) and Computer Vision to improve the classification accuracy. To achieve this, a novel architecture is proposed, which introduces a unified  ipeline capable of processing both text and image inputs. The architecture incorporates several key components, including the utilization of transformers&#39; encoder part, transpose functions, weighted addition modules, and dropout layers. These elements work together to extract relevant features and generate attention scores for different modalities, such as text-to-text, image-to-image, and text-to-image. The evaluation of the proposed model demonstrates its superior performance, achieving an impressive f1-score of 89.21%. This score surpasses the previous state-of-the-art benchmark of 84%, highlighting the effectiveness of the developed architecture for disaster-related post classification. The significance of this research extends beyond the specific problem domain, as it contributes to the advancement of both NLP and Computer Vision fields. By utilizing attention mechanisms to integrate multimodal data, the proposed architecture opens up opportunities for further enhancements and applications in various data pipelines. For instance, it can be extended
to handle other combinations of data, such as image-audio or video-text, enabling broader utilization of the architecture in diverse domains."
"21I-2180   Muhammad Aashir


Multi Modal Toxic Span Detection for Urdu"	"Everyone nowadays uses social media to express themselves because social media is the primary source of knowledge and pleasure. However, social media and internet mate- rial play a detrimental influence in terms of hate, offense, and toxicity. People spread negativity through social media, and the problem is so large that manual screening is impossible. Converting video to audio signals and audio to text does not accurately detect toxicity because, during conversion, we lose the tone and pitch of the audio signal. This is important because humans sometimes use non-hateful phrases as hate speech in a sarcastic manner and use various voice tones. Similarly, we lose infor- mation like facial expressions when we convert video to audio, which also helps find toxicity. As a result, we must determine the toxicity of social media and online content. We must identify the toxicity and determine the exact time stamp at which toxicity exists. As a result, there is a need for a system that can automatically detect toxicity in a video and either put out a beep or erase the hazardous area. For the detection of toxicity, our study provides a multi-modal deep learning system that combines audio and facial expressions from the video. Multi-modality is critical because it will learn all
audio and video characteristics and provide a result. However, some work in toxicity
classification has already been done. Still, to my knowledge, no work has been done
to pinpoint the exact timestamp in which toxicity is present."
"20I-2218-Talha Anwar


[Traffic Forecasting using Deep Neural Network]"	"In today’s world, everyone is in a hurry. Similarly, the drivers want to reach their destination as soon as possible. Therefore, by traffic forecast system, they should know the route where the traffic jammed and by using the alternative paths, they can easily reach their destination without any obstacles. Especially, the ambulance drivers can use this system to reach their destination in time. The Institute of Advanced Research in Artificial Intelligence (IARAI) and the company HERE Technologies organized the Traffic4cast competition in 2021. The goal of this competition is to predict the city-wide traffic status until next 60 minute intervals by providing 
the past hour traffic data. Until now, to tackle this problem different methods used like simple UNet architecture, CNN’s, LSTM’s, U-Net++ with preprocessed data, etc. We proposed a solution by preprocessed the data with some techniques and then trained the pre-processed data on the Graph based U-Net model."
"21I-2087- Maryam Nawaz


Urdu Fusion Voice Cloning"	Despite producing strong results, deep learning techniques are data-hungry. For high resource languages, text to speech synthesis can perform well; but, due to the quantity and quality of data, these techniques do not perform well for low resource languages. Because of its attention-based seq-2-seq architecture, which enables it to learn co-articulation and duration features directly from text and speech, Tacotron 2, Fast- Speech2 architecture has continued to be the state-of-the-art model for text to speech synthesis for many languages. In this study, we suggested a novel strategy, Fusion of different model at different stages which produce effective mel-spectrogram by focusing on Synthesizing stage consisting of duration predictor, prosody extractor.
"21I-2278 - Shoaib Farooq


Using Mixture of Expert approach for Improving Semi-
Supervised Learning for Image Classification"	The Mixture of Experts (MoE) is a machine learning technique that aims to enhance parameter selection in supervised learning by decomposing complex problems into simpler ones. In our research, we propose a scalable Mixture of Experts-based model to improve semi-supervised image classification, which is based on multi-model approaches. Our approach focuses on reducing model and architecture complexity while optimizing high weights used for semi-supervised image classification. To address computational costs and minimize prediction expenses, we employ a decision-based model and assign high-priority weights. We evaluate our approach on four benchmark datasets (MNIST, Fashion MNIST, SVHN, EuroSat) and conduct experiments to improve pseudo label quality, reduce processing time, and minimize the number of parameters. Our results demonstrate that the Mixture of Experts-based model is computationally efficient and reduces prediction costs compared to existing multi-model approaches. Additionally, our method utilizes 50% fewer parameters than current approaches. This article presents a comprehensive evaluation of our proposed approach and showcases its effectiveness in enhancing semi-supervised image classification.
"21I-2305 -Atif Saeed


Accurate Stock Price Prediction with Economic & Social Indicators
 using Generative Adversarial Networks (GANs)"	A stock market is a place in every country that companies used to collect their investment, and the general public can invest their money to earn higher profits. So this market is still challenging for both economists and computer scientists to find ways that will maximize profits. Many factors are involved in the stock price movements, i.e. country’s economic indicators (Gross Domestic Product), Imports, Exports, Social Sentiments, Political Movements, and Company’s internal news and sentiments. With the help of these all financial information and public sentiment analysis, we can better predict stock prices and investors can decide whether they have to buy the stocks or sell their existing stock. In the past decade, there has been a growing focus among researchers, including economists and computer scientists, on analyzing stock price movements and predicting future stock prices. This has led to the exploration of various approaches based on machine learning, deep learning, and artificial intelligence. The objective of this research is to investigate the impact of different factors on stock price movements and examine their correlations. To achieve this, the research is divided into four distinct phases. In the first phase, we utilized five different machine learning and deep learning techniques: Random Forest (RF), Artificial Neural Network (ANN), Recurrent Neural Network (RNN), Long Short-term Memory (LSTM), and Convolutional Neural Network. These techniques were applied solely to historical stock prices. Subsequently, the data was merged with US Dollar Exchanges to incorporate additional variables. Moving on to the second phase, we generated augmented data using two different Generative Adversarial Network (GAN) based pproaches. The augmented data, along with the historical data, was then subjected to the same five machine learning and deep learning techniques mentione dearlier. By comparing the results obtained from the three proposed models, we aimed to evaluate the effectiveness of the augmented data in improving predictions. Finally, in the third phase, we expanded our analysis by incorporating not only historical data and USD rates but also economic indicators. This enriched dataset was then subjected to all five machine learning and deep learning techniques to examine their performance in predicting stock prices. Overall, this research seeks to explore the relationship between various factors and stock price movements, employing a range of machine learning and deep learning approaches across different phases to gain insights and enhance prediction accuracy.
"21I-2310 Hizbullah Jadoon


A Semi Supervised Learning Approach for Image
Classification"	"Image classification is a fundamental problem in the field of deep learning, aiming to accurately categorize images into predefined classes. However, in scenarios where labeled data is limited while unlabeled data is abundant, obtaining precise pseudo labels becomes crucial for effective classification. One approach to assigning pseudo labels to unlabeled data involves the use of binary classifiers. By leveraging binary classifiers, the advantage of generating class-specific predictions can be realized. To tackle the class imbalance problem inherent in binary classifiers, a one-vs-all approach is commonly employed. This strategy involves training multiple binary classifiers, where each classifier distinguishes between one class and the rest. However, this approach often requires oversampling techniques to address the class imbalance issue effectively. To mitigate the need for oversampling, we have developed a novel method that utilizes multiple binary classifiers to train a multi-class classifier capable of generating pseudo labels with a high threshold. The final trained multi-class classifier is then applied to the test dataset, where its performance is evaluated. In our experiments, we have assessed the effectiveness of our model using two widely used datasets, namely MNIST and Fashion MNIST. The achieved test accuracies for the generation of pseudo labels were found to be 95.59% and 84.62%, for the MNIST and Fashion MNIST datasets, respectively. These results highlight the efficacy of our proposed approach in generating accurate pseudo labels, even in situations where labeled data is limited. By leveraging the strengths of binary classifiers and employing a multi-class classification framework, we have achieved notable performance in
image classification tasks. These findings contribute to the broader field of deep learning and provide valuable insights into overcoming challenges associated with limited labeled data. The demonstrated potential of our model opens up possibilities for enhancing the accuracy and scalability of image classification systems in real-world applications."
"20I-2071-Ali Raza 

Detection of Fake Images Generated by GANs Using Deep Learning"	"Social media does not come with a truth filter and ever since the advent of deep fakes, they have become the major source of disinformation. Generative Adversarial Networks (GANs) are the underlying technology in deepfake images. Deepfakes are manipulated media, particularly images, created using GANs. These GANs have undergone remarkable advancements in recent years, generating fake images that are virtually ndistinguishable from the human eye. So, with this advancement in technology, we must come up with strong tools to be able to detect fake and real images. Some tools and techniques are existing in the market
like Forensically, FotoForensics, and Amped Authenticate, these applications have multiple tools like a magnifier, ELA (error level analysis), and Clone detection available that can detect fake images, but the major drawback of these tools is one must be an expert in forensics to know how to use them and they are manual tools and are not scaleable. To address these challenges, the proposed application is a comprehensive solution that combines four different models into a single desktop-based application. This application aims to detect multiple features within GAN-generated images, enhancing the accuracy and efficiency of deepfake detection. The proposed solution utilizes co-occurrence matrices, the Gram-Net architecture, ResNet50V2, and DenseNet201 models. By integrating these models, I have achieved promising results. Experimental evaluations conducted on the StyleGAN dataset have demonstrated the effectiveness of my solution, achieving accuracy rates of over 90% in automatically detecting deepfake-generated images without the need for manual assessment. The proposed solution, which combines multiple models in a user-friendly desktop application, shows great promise in combating the proliferation of deepfake images. By leveraging advanced techniques and achieving high accuracy rates, I aim to equip both experts and non-experts with a scalable tool to combat the spread of fake images and safeguard the integrity of visual information in the digital realm."
"20I-2070  Mohsin Tanveer


Text Description to Facial Sketch Generation using GANs"	Text to face generation is the process of creating human faces from their textual description. Due to the unavailability of open-source largely available face datasets, there is room to create such a tool where people can create a picture of their minds. With the advancement in generative adversarial networks from the past few years, this work has been made possible where a combination of CNN can create realistic images using Generator and Discriminator architecture. Natural language is the most convenient method in human interaction to describe human features, hence the tool will also be capable of solving some complex problems such as criminal face identification where it takes hours for the sketch artist to create such faces based on eyewitness descriptions. The TTF includes the labeling of human face images that describes their facial features such as ‘curly hair’ or ‘pointed nose’ etc. A natural language model will extract useful information from the given descriptions. That textual information is then fed to the generator which creates a realistic human face image that is identified as close to the given description using a discriminator. We are most likely to provide a friendly interface for the user where they can easily interact to provide a textual description and identify if the created image is according to their given description.
"21I-2166  Sabeeh Banaras


An Improved Framework for Reversible Color to Grayscale Conversion"	"A magnificent range of novel techniques have evolved as a result of the technology’s quick improvements, completely transforming how we conserve valuable computing resources. One of the most amazing developments is the potential to significantly decrease the cost of internet-based picture transmission. Imagine a world in which high-quality photographs may be fluidly transported throughout the digital universe, effortlessly bridging distances and sparing priceless processing capacity. This amaz- ing advancement not only improves productivity but also lays the path for a more connected and visually appealing internet experience. Color to Grayscale conversion plays a significant role in image processing applications which includes compression, enhancement and analysis of reconstructed image. However traditional color to grayscale conversion techniques has the limitation of loss of irreversible information which is a challenging to extract original color information rom respective grayscale image. One additional limitation of current work is depen-
dent on color reordering based on human visual perception, as it can vary from person to person and can produce inconsistencies while generating grayscale image. We have proposed a new Reversible Color to Grayscale Conversion Framework that not only allow the extraction of the color image accurately but also helps to reduce differences between actual and reconstructed image. We presented a new color-reoder techniques for RCGC. These techniques give the preservation of different colour components during conversion a higher priority while also considering their perception view. By carefully studying the colour distribution
and spatial relationships within the image, our method achieves a correct balance between the grayscale representation and embedded colour information results in producing high-quality reconstructions of images.
To evaluate the effectiveness of our proposed method experiments are conducted  on standard Kodak Dataset. The experimental finding shows that the suggested frame work performs better than current RCGC approaches in terms of embedding capacity and reconstruction of colored image.  Colors have a significant impact on how we interpret pictures. Our eyes are extremely sensitive to different colors and how they interact with one another. Some colors have the ability to draw our attention and have a big influence on our visual experience. We contribute to the field of color image processing in our study by propos- ing a dependable approach for transforming color photos to grayscale without losing any significant information with color information generated using human visual per ception. This technological development enables a reversible conversion procedure that preserves the original image’s integrity."
"21I-2169  Osama Nusrat


Depression Detection Through Twitter"	Depression is a significant issue nowadays; nearly most people suffer from this mental health disease. According to the world health organization (WHO) [41], more than 280 million people suffer from depression in 2023. This is a huge number, and if this is; not taken seriously, these numbers will increase rapidly. Almost 4.89 billion people use social media [35]; people express their feelings and emotions on platforms like Twitter, Facebook, Reddit, Instagram, etc. So these platforms contain valuable information which can be used to do research. Much work has been done on different social media platforms to predict depression. Still, there are some limitations in those works, such as binary classification, and the dataset is incorrectly labelled (if the tweet has the word depression, it is labelled as depressed without reading the whole context of the sentence). In this research work, I have used Twitter to predict types of depression in tweets based on lexicon labelling. Apify was used for scrapping the tweets based on the lexicon or phrase verified by domain experts. I have also used explainable AI to give reasoning by highlighting the parts of tweets which are considered while predicting depression. BERT is used for feature extraction as well as for training. I trained my model using machine learning, deep learning and NLP (Natural Language Processing) models. BERT gave the most promising results with an accuracy of 0.93. This research will be helpful for mental health clinicians and other aspiring researchers planning to research in this domain.
"21I-2183 Zonera Anjum


Real-Time Deep Fakes Detection using Spatial and Temporal
 illumination"	Deep-fakes are being popular ever since the invention of GANs. [1] However since Covid-19 Pandemic, when everything was moved online, it has expanded quicker than ever. Numerous work has been done on images, audio and video datasets, but there is a need to work on the real-time detection as it has not mastered enough. Many researchers have presented deep learning approaches from CNNs to Trans-formers for this purpose, but some haven’t predicted accurately, and others have re-source constraints due to which it can’t be deployed in real-time. Farid et al. [2] has introduced a novel way for detection using active illumination which was not intro- duced before. The model they developed performed admirably, however it comes with the drawback of not working well with non-deterministic lighting patterns. Addition- ally, there was a temporal delay when this pattern was displayed on the screen. This leads me to address these two issues along with working on iris region of the caller to detect it accurately.
"21I-2184 Kiran Iqbal

Diagnosis of cervical cancer through deep learning pipeline"	Cervical cancer is the fourth most frequent cancer in women overall, with over 528, 000 new cases each year. In less developed nations, new cases made up about 85% of the total. The high death rate in these nations is mostly a result of a dearth of qualified medical personnel and effective medical prescreening processes. The gold standard for detecting cervical cancer is a cervigram, or a picture of the cervical area. Cervi- grams show considerable inter-rater variability, especially among medical profession-als with less training. Traditional methods employ testing and diagnosing procedures that cause discomfort to the patient and require at least 24 hours to deliver results.There is also always a chance of making a mistake. The process of data discovery and use has been considerably changed by the development of artificial intelligence (AI). This has the potential to improve and simplify many people’s lives in the medi-cal sector. Digital methods are used by artificial intelligence (AI) in medicine to treat, diagnose, and forecast results. In this study, we propose a fully automated pipeline for cervix detection, cervigram-based cervical cancer classification, and mitigation of specularity impact on detection performance. We offer a specular reflection reduction approach to precisely detect and inpaint these spots.
"21I-2197 Usba Sattar


Vehicle Lane Change Detection Using Deep Learning"	This article focuses on two key aspects of computer vision: vehicle detection and image visibility restoration. Recognizing and locating things of interest inside an image is a fundamental component of object detection in computer vision. YOLO is a deep learning model that is capable of doing object identification in real-time with a high degree of accuracy. In order for the YOLO model to function, the image is first segmented into a grid, and then bounding boxes and class probabilities are predicted for each cell of the grid. This method enables effective object recognition without the need for area suggestions, which is one reason why it is a favorite option for a wide variety of computer vision applications. Visibility restoration, on the other hand, is a method that changes a picture’s contrast and brightness in order to improve its legibility. This is accomplished by altering the image. CLAHE is an established image improvement method that makes use of histogram equalization to enhance the contrast of a picture while keeping the whole brightness of the image the same. The dual gamma approach is an improvement that may be used to CLAHE increase the quality of the results. This is accomplished by altering the gamma values of both the original picture and the equalized version of the image. This strategy may assist in maintaining the image’s details while simultaneously enhancing its visibility. The use of YOLOv8 and CLAHE in conjunction with the dual gamma method has the potential to find a variety of applications in a variety of areas, including autonomous driving, surveillance, and medical imaging. When applied to the DAWN dataset, a mixture of object detection and image enhancement approaches has the potential to dramatically increase the performance of lane-change vehicle recognition while maintaining a high level of accuracy.
"21I-2198 Usama Khan


Human Action Recognition using Deep Learning"	Detecting human actions in videos is an active area of research in the field of computer vision and pattern recognition. Today, human behavior requires artificial intelligent (AI)-based systems for security and safety purposes. Current action recognition techniques mainly use pre-trained weights of different AI architectures to generate visual representations of video frames. However, fast and accurate detection of human actions in complex environments with restricted resources are a major challenge. To meet these challenges, I proposed an attention based two-directional long-term short-term memory (BiLSTM) mechanism with capabilities that selectively focuses on effective features in the input frame to recognize different human actions. in videos.
"21I-2381  Muhammad Hanan

A hybrid whale optimization Algorithm based on sine cosine optimization
 for multi-objective task scheduling in a Federated Cloud environment."	As we are well aware that cloud computing is one of the major advancements in the IT industry and today’s world almost every IT company and Researcher are using cloud technology to execute their workflows. orkflows are multiple dependent and independent sets of tasks that must be executed in a precise sequential manner, these workflows become more and more complex when a scientific phenomenon is implemented in form of workflows known as scientific workflow scheduling. In cloud computing executing a scientific workflow scheduling is already a complicated task. A Federated cloud is a multinationalcloud system, a combination of a private, public, and community cloud into a scalable cloud platform. When a scientific workflow is executed on a federated cloud minimizing makespan and task execution cost is a major multi-objective optimization problem. A heuristic- based hybrid optimization algorithm is needed for overcoming this multi-objective optimization challenge. Four multi-objective optimization algorithms are implemented for task scheduling on Five different Scientific workflows and results shows that heuristic-based multi-objective hybrid optimization algorithm performed significantly better than another simple multi-objective optimization algorithm.
"21I-2400 Obaid Ullah
Detecting Resource Leaks in Android Applications by Alias Analysis
"	In today’s digital world each and every person owns a smartphone. Android is the most common operating system that is used in the smartphone devices. The number of android users is continuously increasing. Android devices are energy constrained devices. Therefore, saving a littleamount of energy is beneficial. In response to this issue, researchers have proposed various tools and techniques. The issue is broadly categorized into three main categories: resource leaks, issuesrelated to GUI, and the Anti-Patterns. Major studies in the literature are focused on the first category, i.e., the resource leaks. Resource leaks mean that an application has acquired a resourceand does not release it or releases it too late. According to the literature, the issue occurs mostly because of the event-driven programming architecture of android and the focus of the developerson delivering the main functionality of the application. To address these issues, many studies havebeen proposed that detect some of the resource leaks in the android applications using mainly staticprogram analysis techniques. Most studies either build an automaton of the application or use machine learning algorithms to detect the leaks but still many resource leaks have been left for thedetection. The leaks that have been detected have a limitation of false positive (there is no resource leak, but the technique is detecting it as a leak) and false negative rates (there is a leak, but the technique is unable to find it). After a thorough analysis of the literature, it was found that if the resources are aliased within the same application, then the false positive and false negative rate ishigh, and no study has tackled this issue. Hence, the major contribution of this work is to detect the resource leaks that arise when the resources are aliased within the application. The proposed approach does alias analysis using the Points-to Analysis provided by the Soot framework in addition with building the Resource Flow Graph of the application. The results of both the analysesare combined to predict the presence of a resource leak. The results of the proposed approach on 15 real world android applications show that the approach is effective in detecting the resource leaks having an accuracy of 97.7%. The work acts as a helping guide for the researchers and will serve as a pathway towards detection of the resource leaks and ultimately saving the battery of thesmartphone devices.
"20I-1957- Saqlain Ahmad

Detection of Trigger Based Adversarial Attack in IoT-Enabled UAV’s"	Unmanned Aerial Vehicles (UAVs) are being used for multidimensional roles in military as well as for civilian purposes. In military it is being used for offensive operations and information gathering. In civilian purposes they are being used for multiple purposes, however its use for goods delivery is increasing, for that they have to move with in cities and there are lots of certain kind of objects with which these UAV’s could collide like trees, buildings, traffic lights, mobile towers and electricity poles. To avoid these collisions deep learning based collisions probability detection models are being used in UAV’s which by recognizing objects predict collision probability and whenever collision probability is high which means there are certain kind of objects with which UAV could collide and with the help of steering angles UAV avoid these collisions. However, there are also backdoor attacks which target these deep-learning based models and algorithms and changes its model collision probability prediction. Backdoor attacks against deep learning models are of two types poison based-backdoor attacks and adversarial backdoor attacks. The main focus of this thesis is Adversarial backdoor attacks and its types. In adversarial backdoor attacks a certain amount of perturbation is added in dataset to poison the samples. There are two types of trigger based adversarial attacks. Those are static trigger based adversarial attack and dynamic trigger based adversarial attack this thesis have poison the  AV data set using dynamic random trigger based adversarial attack also this thesis have misclassified the UAV DroNet  model using that poison data once the model is misclassified, so even there is high collision probability but the model is misclassified and unable to recognize it. Then this thesis have also applied a backdoor detection technique based on input agnostic. This thesis have applied feature scattering based on neural networks and trained this thesis deep learning based models CNN and VGG16 on benign images as well as on mallicious images which will be able to detect if there will any kind of millicious activity going. This thesis have created multiple attack variations in which triggers of 3.84% density size, 6.26% density size, and 11.56% density size have created and detected using VGG16 model which in return significantly droped the attack success rate.
"20I-2056- Umad Khan

The ICCMS-Based Automated Treatment planning for dental caries"	An innovative automated treatment planning solution for dental caries based on the International Caries Classification and Management System (ICCMS) is proposed. Dental caries, commonly known as tooth decay or cavities, remains a prevalent oral health issue that affects individuals of  all ages worldwide. To address this problem effectively, the proposed solution integrates state-of-the-art machine learning algorithms, to process and analyze clinical data. The proposed solution operates by classifying patients based on their clinical characteristics, which can be extended to accurately recommend personalized treatment plans tailored to each individual's needs. By leveraging the power of machine learning, the system optimizes the decision-making process, leading to more precise and efficient treatment strategies. Moreover, it reduces the dependency on manual diagnosis and planning, enhancing overall dental healthcare efficiency. The automated treatment planning solution offers several advantages, including improved diagnostic accuracy, standardized treatment protocols, and enhanced patient outcomes. By streamlining the treatment planning process, dental professionals can save valuable time, allowing  for more focus on patient care and communication. Additionally, the system promotes evidence-based practices by aligning with the ICCMS guidelines, fostering consistency and reliability in dental care settings. The solution demonstrates significant potential in transforming dental health infrastructure and promoting patient-centered care. By providing reliable, accurate, and timely treatment recommendations, it contributes to enhancing the overall quality of life for patients and reducing the burden of dental caries-related complications.
"21I-2380 Salwa Khatoon

Exploring Usable Security in Web &amp; Mobile Applications"	"In developing interactive software systems, applications, and products which include information systems, banking systems, safety-critical systems, healthcare systems, web and mobile applications, etc., finding a balance that offers satisfying levels of security and safety is crucial. In such systems, usability, and security are simultaneously required to maintain the effectiveness of the technology. Failing to design and achieve this equilibrium may lead to unrecoverable and destructive security breaches in the long term. However, users tend to reject unusable solutions. Therefore, having well-balanced amounts of both is a prerequisite for a system software or a product to be accepted by a user. Through this research, we explored the severity and impact of ISO 25010 usability-security factors, primarily focusing on the insubstantially investigated usability factors by conducting an experimental study over web and mobile applications. The selected applications were Daraz.pk &amp; Easypaisa. By reviewing the existing literature, we identified the inconsiderably explored usability factors.
These were Learnability, Accessibility, User Error Protection, and Appropriateness Recognizability for usability. For security, the considered factors were Confidentiality, Integrity, and Availability. These factors are analyzed over web and mobile applications&#39; multiple user interface elements, not limited to login credentials. Using the experimental results, we performed an extensive data analysis and validation involving different analysis
methods and techniques e.g.; multi-criteria decision and sensitivity analysis methods. Based on the derived results, we proposed an optimize solution in the form of a usable security pattern named as User Accessible Data Integrity, which emphasizes on guaranteeing accessibility and integrity in software applications by delivering a structure for encompassing usability and security measures. It confronts the necessity for moderation between data integrity and user accessibility. The study delivers a systematic structure for integrating usability and security measurements assuring accessibility and integrity in software applications confronts the requirement for symmetry between user accessibility and data integrity. It also contributes to on-going research debate of resolving usability-security conflict. More ever, it also helps the beginners or naïve researchers with similar interest to have more knowledge and insight helping them to explore and learn."
" 21i-2322 Sajjad Saleem


Semantic Analysis and Recommender System for Generating New Star Ratings
from Reviews using transfer learning for Hotel Recommendations"	In today's era of abundant user reviews on web platforms, selecting an appropriate hotel that aligns with individual preferences has become increasingly challenging. To address this issue, we propose a novel hotel recommendation model leveraging transformers-based techniques. Unlike existing approaches that utilize machine learning and deep learning techniques, our system aims to generate star ratings from user comments and reviews, and subsequently utilize these ratings for hotel recommendations. Our research paper comprises three main parts. Firstly, we employ the BERT model to analyze user comments and convert them into star ratings, capturing the sentiment and opinion expressed in each review. Secondly, we conduct a comparative analysis of the generated ratings, considering factors such as rating consistency and user agreement. Finally, we recommend the top five hotels based on the combined ratings. To evaluate the performance of our model, we utilize a dataset from TripAdvisor, a widely recognized platform for hotel reviews. The effectiveness of our system will be assessed using multiple evaluation measures, including accuracy, F1 score, precision, and recall, which are widely adopted in recommendation system research. By developing this transformers-based hotel recommendation model, we aim to alleviate the burden on travelers when selecting hotels by providing reliable and personalized recommendations based on comprehensive user reviews. Our research contributes to the field of recommendation systems and showcases the effectiveness of transformers in handling sentiment analysis and recommendation tasks.
"19I-1242 Misbah Haider


Multiple Attacks Detection and Vehicular Type Identification scheme
 in VANET’s"	"Intelligent Transportation Systems (ITS) is a group of automated technologies that connect automobiles, roads, and public transportation via the Internet.These technologies include wireless and automated systems that enhance safety, efficiency, and sustainability. Attackers in vehicle to-vehicle communication are a serious threat to the security of modern vehicle networks. As these networks grow more complex, malicious attacks become more likely, making it crucial to implement rigid security protocols. In this research work, we proposed a methodology to detect the attacks in vehicle-to-vehicle communication as well as attacker and legitimate vehicle
in vehicular network system. Our suggested mechanism works on two major steps. First step includes the detection of legitimate and attacker vehicle while in the second step detects the type of attack performed. Our proposed model detects 14 different type of attacks.We use seven different models to detect the attacker vehicle and attack types. The models includes Decision Tree Classifier, KNN, LSTM, GRU, SVM, ANN and Random forest. Training of these models have been done on Veremi Extension dataset and measured the performance of our purposed solution with the help of well-known performance indicators accuracy, precision, recall and F1- score. For attacker vehicle detection, the Decision Tree classifier performed well with an accuracy of 92% , KNN with 86%,SVM’s accuracy is of 90%, whereas ANN overall accuracy is 94%, LSTM model accuracy is 86%, Random Forest accuracy is 96.8%, and GRU model accuracy is 85%. For the detection of attack type, Decision Tree classifier got an accuracy 94%, KNN accuracy is 92%, LSTM model accuracy is 90%, Random Forest has got the highest accuracy of 95%, whereas SVM’s accuracy is 90%, ANN with 93% and GRU model accuracy is 90%. After doing a comparative study for all the implemented models, it is concluded that Random Forest classifier outperforms all the other ML models in predicting vehicle type as well as in identifying attacks in vehicle to vehicle network."
"19I-1802 Muhammad Junaid


Time syncronization in digital cloud forensics"	"IoT technology has ballooned in recent past years and these devices are now an essential part of our daily lives. There has been very little research on digital forensics in the field of the internet of things. Many digital forensic frameworks and tools have been developed for the cloud but due to the distributed and heterogeneous nature of IoT, present digital forensic tools and techniques are unable to address the challenges of the IoT environment. Many researchers proposed digital forensic frameworks for IoT environments but mostly they have worked on the acquisition of data from IoT environments. These studies still have some limitations as they have not addressed evidence integrity challenges. Therefore, this study presents a fog and blockchain-based digital forensics framework for oT systems that support evidence integrity, confidentiality, perform analytics on
evidence, and store the evidence in a secure manner. 
Keywords: Internet of Things, Digital Forensics, Blockchain, Integrity"
"19I-1803 Ali Zafar


Access Control in Cloud Environment"	"Billions of IoT devices work within a heterogeneous environment. So today, our biggest nightmare is IoT security, such as data breaches, integrity, and the confidentiality of data because of unauthorized access to IoT devices. In an ad-hoc environment where IoT devices are communicated, there is no access control scheme for that environment. The researchers want to propose a hybrid-based access control scheme for an open IoT environment. For identity, researchers use TPM (Trust Platform Module) or trusted computing for authorization of the entity. The attributes of the entity and judges go to TPM and TPM authorizes or compares the last measurement of the running stack. After that with the help of a machine learning-based algorithm that is on the cloud the smart entity is legitimate or not. If the entity is legitimate, then the system grants full access to the resource. Nevertheless, the entity does not provide proper attributes or identity satisfactorily, and the system will give specific access to the resource. This model is more efficient and scalable for an open, heterogeneous environment because it is a hybrid.
Key Words: Hybrid access control scheme, ABAC, IBAC, TPM, Trusted computing"
"19I-1821 Raheel Asim


Windows Based Malware Analysis for Computers Devices using API Calls
 and Memory Imaging"	"Malware is becoming the greatest threat to computers and information systems all around the world as the shadow internet economy grows. Every day, 350K virus and potentially harmful applications are submitted to AV-TEST. Threat actors engage in fraudulent activities within the business realm or engage in the act of stealing personal information, subsequently exploiting this acquired data for malicious purposes. The protection of information and data has become a significant concern within the malware research community due to the rising number of cyber-attacks. In previous studies, researchers have employed an API call sequence to determine the presence of malware in a given file. Malware analysis is classified into two types. The first is a static analysis, whereas the second is a dynamic analysis. In the static analysis, the malware file is analyzed without
its actual execution. The researcher extracts feature from the file, such as a signature, and bases decisions on those features. In contrast, in dynamic analysis, the malware is executed in an isolated environment and its behavior is analyzed. The analyzer decides whether a file is malicious based on its behavior. In [1] the researcher extracts the API call features from the malware and good wares and generated two clusters one for malware and the second one for good ware. To detect a file is malware or not the researcher extracts the API call sequence from the file and matches them with those two clusters. If the API call sequence matches from the malware cluster, then the file is malware or otherwise good ware. The proposed approach aims to protect windows computer systems from malware attacks. In this work, we will employ a robust and efficient approach for malware detection by analyzing both memory imaging and dynamic analysis. We will extract malicious features of malware from memory images and combine them with the characteristics of dynamic analysis."
"21I-2285 Shamayla Batool


Estimation of Hematological parameters for mHealth Applications"	"Hemoglobin (Hb) is a protein in red blood cells that carries oxygen. A low hemoglobin level is characterized as Anemia. An Hb test measures the level of Hemoglobin in your blood, the traditional method for which is an invasive procedure that requires drawing blood and studying its pathology by an expert Hematologist using state of the art lab equipment. This test not only requires specialized equipment in laboratories but also trained professionals. Most of the people of Pakistan live in rural areas where specialized testing is not available. An Hb level test is a necessary part of investigations in case of pre-operative patient assessment, pre- and post-delivery and blood related diseases such as thalassemia major patient care as well as in routine examinations. With smart phones being a commodity in recent times, Smart-Phone based health care solutions as a first diagnostic response is an active area of research. Smart phones have been successfully employed in research for prediction of Blood Pressure, Heart Rate and Oxygen saturation among others. Research is also underway for measurement of blood pathology using PPG signals captured via Smart Phones. There has been limited research on the use of fingerprint videos to estimate Hb values, most of the work in the field relies on video captured via single smart phone and light source. For a solution to be available to the masses there needs to be extensive research on various factors that impact the quality of the generated PPG signal. One such parameter
is the quality of the camera used to capture the video. This study aims to perform a comparative analysis on how the quality of the captured video impacts the predicted results. We intend to lay a foundation for a remotely available solution that can be easily accessible to the masses even in remote areas where clinical lab facilities are not available."
"20I-2272 Abdul Hannan


LVM optimization using Graph Neural Network"	"Data warehouse is a subject-oriented, integrated, time variant and non-volatile collection of data in support of management’s decision-making processes. Due to strategic importance of data warehouse, it is absolutely crucial for organization to guarantee the quality of data warehouse so that the decision makers can make better decisions. Quality of data warehouse multidimensional model has a great influence on the overall data arehouse quality. Very little work is done to assess the quality of multidimensional model objectively using metrics. Some statistical techniques like correlation analysis, univariate and multivariate regression techniques, etc. have been used which indicated that these metrics are significantly related to the quality of multidimensional models for data warehouse. However, in context of data warehouse, very little work has been done to predict the multidimensional model quality using machine learning
techniques"
"20I-2001 Abubakar Attiq

An explainable approach to Memory Based detection of
Malware using Machine Learning"	"Cyber Attacks are growing more common largely owing it to being the digital era. Due to the large scale availability of the Internet, which has made it easier for attackers to pass malware as genuine software and as a direct consequence alware itself is evolving at a rapid pace. To counter malware attacks, security analysts need to analyze and determine its behavior in order to successfully prevent future infections as well as to remove it from already affected devices. Existing common detection and analysis techniques i.e. dynamic and static analysis have their uses but lack in certain aspects, which is why in recent years attempts at detecting malware via memory analysis is being heavily focuses upon. Unfortunately, due to the high influx of data obtained from ever evolving malware it is humanely impossible to go through each malware variant. This is the point where Machine Learning enters in the field of cyber security. Classi- fiers can be trained to detect Malware and aid analysts in processing the huge amounts of data. The main drawback of this whole process is the lack of expla-
nations. Complex Classifiers act as a black box hence it is impossible to assign a reason as to why the classifier tagged a particular sample as malicious thereby making it less trustworthy. The main contribution of this Thesis is to establish explainability within a system designed to detect malware via classifiers that are trained on data acquired through Memory Forensic techniques. The process includes acquiring memory dumps via pre-existing data sets or through reports obtained from cuckoo sandbox which is an automated malware analysis tool, the memory dumps are then used to obtain features that will be used to train the classifiers, this can be done using tools such as volatility, which is a memory forensic tool comprising of a large number of APIs that can be used to extract specific data from dumps, the next step involves training and testing the classifier. Additionally, a surrogate model will be approximated to the predictions of the classifier and will be used to generate explanations for the decisions of the classifier."
"21I-2247 Saira Farooq

Herbarium Specimen Classification Using Deep Learning Approach"	Apple is a popular fruit crop that is susceptible to a variety of foliar diseases. Detecting foliar diseases in apple trees is a critical aspect of orchard management, as it can prevent yield losses and maintain food security. Currently, disease detection is carried out through manual inspection and visual assessment, which can be time-consuming, subjective, and prone to errors. Early and accurate detection of these diseases is crucial for effective disease management. This paper proposes a hybrid approach that combines machine learning and deep learning techniques to detect foliar diseases in apple trees. The proposed methodology involves collecting digital images of apple leaves, preprocessing the images, extracting relevant features using machine learning algorithms, and training a Convolutional Neural Network (CNN) model to recognize the visual patterns associated with different foliar diseases. The performance of the model is evaluated based on its accuracy, precision, and recall. The results indicate that the hybrid approach can achieve high accuracy in detecting various foliar diseases in apple trees. The proposed approach can provide a fast, reliable, and accurate tool for apple growers to monitor the health status of their trees and take timely action against diseases. Further research can explore on two datasets to check the performance of proposed approach.
"21I-2251 Sabahat Asad

Herbarium Specimen Classification Using Deep Learning Approach"	"Numerous specimens have been preserved for many years for scientific study, one can be found as herbarium specimens. A herbarium specimen is a preserved plant specimen collected from wild or cultivated sources that is carefully mounted, dried, and stored for scientific purposes. It is necessary to have an automated identification system that can classify the species to their respective categories appropriately. However, creating such a classifier is difficult due to the visual similarity of leaves as well as intra and inter-class variations. And it becomes more challenging when the leaves are dry. Deep Learning presents itself as a powerful approach to solving sucha complicated problem. Our proposed approach aims to improve the performance of herbarium specimen classification by emphasizing on the fine variations in the visual traits among distinct species. For the ssification of different species of the flowering plant family ’Melastomataceae’, we implemented pre-processing, undersampling, augmentation, and different deep-learning models. The distribution of majority classes
with higher numbers of images is improved by applying undersampling and minor ity classes with fewer numbers of images is improved using data augmentation techniques. For classification, multiple Convolutional Neural Network (CNN)-based deep learning models are used. The proposed method outperformed existing approaches in a performance comparison using a publicly available dataset of Herbarium Specimen, with an accuracy of 94.3% and an F1 score of 0.95 for inaccurate classification of different herbarium specimen species. It will help in the development of a part, or perhaps, completely automated system to assist taxonomic classification and other botanists in their identification, and revision work. Keywords: Convolutional Neural Network, Deep Learning, Herbarium Specimen Classification, Plants species Identification, MobileNet121, InceptionV3"
"20I-2208 Haseeb Waheed

Herbarium Specimen Classification Using Deep Learning Approach"	"Cervical spine fractures are the one of the most severe and commonly encountered spinal cord injuries. In the United States, an estimated 1.5 million vertebral fractures are reported annually and most of them are located in the cervical spine. Cervical spine consists of seven stacked vertebrae labeled as C1 to C7, positioned directly below the human skull. Due to its crucial role in supporting the head, injuries to the cervical spine can have devastating consequences like damaging the nerves, paralysis or sometimes leads to death. These fractures are mainly caused by trauma like road accidents, sports injuries, falling from height or osteoporosis etc. Timely and correct identification are crucial for the patient with cervical spine fractures. However, missed fractures or delay in identification could lead to complications and can impact the patient's health. To address this challenge, medical imaging has played a very important role in improving the diagnostic capabilities, particularly in the field of cervical spine fracture. Among the various imaging techniques, Computer Tomography (CT) has emerged as a gold standard for the evaluation of cervical spine due to its ability to provide detailed and high resolution images. CT scans images allows radiologists to visualize the structures and other anatomical features in great detail. They also reveal the presence and location of the fracture in a vertebrae which is the most essential information for its treatment. Recent advancements in the field of artificial intelligence (AI) and deep learning techniques have drastically improved the diagnostic process. Deep convolutional neural networks analyze the CT images and extract the important features  specific to the cervical spine fracture which identifies the abnormalities and the patterns identifies the presence of fractures. Integration of medical imaging, partially CT scan images with AI bases approaches has improved the detection of cervical spine fractures. This combined approach facilitates early detection and timely diagnosis will help define the correct pathway for the treatment of the patient which results in overall patient well-being.In this research paper, our proposed model uses the EfficientNet model as the backbone for the classification of fractures from non-fractures. The importance of using this state of the art architecture lies in its superior performance and complex medical image data handling capabilities. The proposed model was trained and evaluated on the dataset consisting of 2019 CT scans where each scan consists of more than 300 images. Experimental results of our proposed
model have achieved remarkable results like average accuracy of 94% for vertebral level fracture detection and around 73% patient level fracture detection . By identifying cervical spine fractures using capabilities of the proposed model timely and accurately can help take precautionary measures to save lives and improve patient health."
"20I-2232 Tanveer Ahmed

Traffic Forecasting using Advanced Deep Learning Technique"	In the past few years, there has been a surge of interest in traffic forecasting, and several deep learning architectures have been introduced for this purpose. Accurate traffic forecasting at the appropriate time is crucial for managing and controlling urban traffic, given the significant spatial and temporal complexities associated with long-term predictions. To model these dependencies, d eep learning techniques such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs) have typically been used in traffic forecasting challenges. Traditionally, traffic graphs were divided into grids, and CNNs were used to capture spatial dependencies. In this study, we propose a graph-based method called Graph Neural Networks (GNNs) to address the temporal prediction problem in traffic control. GNNs are a type of deep learning algorithm that has been suggested in recent decades for processing graph data.
"20I-2234 Muhammad Zubair


Deep Learning Approaches for Wheat Crop Segmentation in Remote
 Sensing Imagery"	The global population is on the rise, especially in developing nations, and food security has become a pressing issue. To tackle the issue of food security in the face of a growing global population, precise agriculture research is essential in areas such as monitoring agricultural land, analyzing and classifying land use, and optimizing land use for high yields. Deep learning-based algorithms have proven more dependable and accurate in remote sensing image classification than their traditional counterparts. This study introduces the transfer learning UNet with Resnet, DeeplabV3+ with resnet model, and the proposed model is a cutting-edge deep neural network that uses semantic segmentation to classify and divide wheat cover through remote sensing images. This exceptional model takes advantage of residual networks, transfer learning, and UNet architecture, combining their benefits to deliver unparalleled results. 
"21I-2079 Sidra Bibi

Node-Pruning based Deep Neural Network Compression"	The advancements in deep learning have resulted in highly accurate models for various tasks. However, these models have also become larger in size and slower in terms of prediction latency. In real-world scenarios, there is a growing demand for smaller, faster, and more efficient networks that can be easily deployed on mobile devices . In this study, graph summarization techniques serve as the inspiration for proposing a few methods to compress neural networks. By setting a threshold, nodes with weight differences below this threshold are combined. This process involves modifying the architecture with superneurons and their respective new weights, resulting in significant compression with a slight compromise in accuracy. These approaches offer a promising solution for reducing the size of neural networks while still maintaining satisfactory performance levels.
"21I-2299 Qandeel Zainab

Detection of Sleep Apnea using PPG and SpO2 signals"	This study investigates the detection and classification of potentially harmful sleep apnea and hypopnea episodes using photoplethysmography (PPG) and SpO2 signals. Sleep apnea, or uneven breathing while sleeping, may have serious ramifications for both people and the healthcare industry as a whole. Traditional diagnostic methods include extensive physiological data, are costly, and require professional analysis. In order to assess blood flow near to the skin, this study uses the medical data of 53 critically ill patients with a non-invasive electro-optic technique called PPG. By employing PPG and SpO2 measurements to tally the number of apnea episodes per minute and per hour, the Apnea-Hypopnea Index (AHI) is retrieved from the detection technique. Apnea episodes are then categorized using Temporal Convolutional Networks (TCN) and Long Short-Term Memory (LSTM), respectively, with accuracy levels of 91.65% and 93.21%, after 10-fold and hold-out cross-validation processes. By contrasting the results of the proposed technique with those of current classifiers, its efficacy is demonstrated, highlighting its potential for accurate and cost-effective sleep apnea detection.
"21I-2301 Mahnoor Munir

Summarizing and Querying Text data using Frequent Subgraph Mining"	In Our research, we explore how graph mining techniques, specifically frequent subgraph mining (FSM), can be applied to text summarization. Graph mining has gained recognition as a valuable field for analyzing complex interconnected data. FSM, which is a challenging task within graph mining, involves extracting informative subgraphs that frequently occur in the original data. Our algorithm, Order-Maintaining using Gspan (OMGSPAN), is introduced in this approach. It utilizes FSM and gspan to extract relevant and informative sentences from text documents, aiming to generate high-quality summaries with grammatical consistency and maintained phrase order. This integration of FSM and text summarization has the potential to facilitate efficient information extraction and improve comprehension of textual data in various domains. The developed algorithm has been tested using the DUC dataset, and it has been compared with the state-of-the-art algorithm [3]. The state-of-the-art algorithm achieves a rogue score recall of 0.58, while OMGSPAN achieves a rogue score recall of 0.75.
"21I-2315 Usama Ahmed

Generation of Monet-Style Paintings from Real Images using CycleGAN and 
Diffusion Models"	Computer vision has made remarkable advances in the domain of image synthesis, image segmentation, and image translation. Style transfer is one of the computer vision processes that redraw an image using imitation without losing its semantic content. In this discipline of image synthesis, many researchers worked on image-to-art creation but it still needs improvement, in improving diversity, learning Artist’s unique  painting style, improving accuracy, faster training time, FID score, originality content of image generation, brighter–and–dark image translation and lowering cycle consis-tency loss. In recent years, Generative Adversarial Networks commonly known as GANs and Diffusion Models have gained popularity as a powerful method for achieving style transfer. These are now often employed to learn certain artist painting istribution. In this study, our main objective will be to learn the painting style of the famous French artist Claude Monet on the complete dataset and mean average-based sub-categories of the same dataset, for creating high-quality and realistic paintings that accurately emulate Monet’s and to generate exact content of the image using GAN and Diffusion model. We fine-tuned the parameters of our proposed systems that helped in improving accuracy score, high-quality image generation, handling varied and extreme geometric changes, and doing a comparative analysis of performance. All of our proposed systems based upon Stable Diffusion showed excellent results in capturing the unique style of the Artist and higher quality image generation. We evaluated the performance of our systems quantitatively and qualitatively by human visual inspection. Our Average FID score for all dataset categories for cycleGAN is near 10 and for Diffusion Model it’s near 4.43. Our proposed systems showed great improvement when compared to previous research work. All in all, CycleGAN and Diffusion models are stable, adaptive, diverse, unique, and generalize well in learning all styles and modes. However, achieving improved and efficient results with these methods typically requires expensive computational resources. In the future, CycleGAN could be explored to generate hybrid styles that combine elements of different styles and it also be explored for alternative loss functions, while Diffusion Model could be explored for new metrics or evaluation methods on image synthesis tasks.
"20I-2286 Muhammad Haris

Predicting State Bank of Pakistan’s Monetary Policy with NLP"	"Everything in this world is directly related to the economy and the factors that influence the economic model of our world, and the influence which central banks have on the formation of these economic models is far too massive to ignore. Decisions made by the central banks are not on an adhoc basis, in fact the amount of data that central banks hold is massive in scale and the decisions they make are purely based on the careful analysis of that data. Clearly, they allude towards what is coming next in their conversations and board meeting minutes. The aim of this study is to predict the monetary policy of the State Bank of Pakistan with the help of Natural Language techniques. Accurate monetary policy predictions have significant implications for financial institutions, businesses, and individuals, enabling them to make informed decisions and mitigate risks. There are many existing techniques which vary on the basis of the requirement and the scope. This study aims to predict the monetary policy for the next quarter by analyzing the language and vocabulary used in the minutes of the Board
members meeting of SBP. The technique used in this study is the generation of the domain specific embeddings by ‘Domain Adaptation’ using state of the art embeddings generators. Future work can involve exploring advanced NLP techniques and incorporating additional data sources to improve prediction accuracy. Overall, this research contributes to the field of predicting monetary policy by leveraging Natural Language techniques and domain-specific embeddings."
"21I-2026 Kumail Abbas

A novel systematic method for conversational conflict resolution"	One of the largest contemporary issues in the globe is sectarian violence and hatred. People are becoming more involved in such violent sectarian conflicts without having any prior domain knowledge as a result of social media platforms becoming more widely accessible. Serious issues both inside and beyond the nation are a result of these disagreements.The disputes on sectarian animosity on social media platforms will be corrected by our suggested strategy, which will produce neutralising remarks to foster inter-sect harmony.All preexisting techniques either work for a single text for analysis. Moreover conventional methods either targets a single task like detection or classification task, text generation task but their is no task specificity in this domain. Our proposed model is pipeline of all the existing models like data creation , detection/classification , text generation. Roman urdu add complexity as well as novelty to this model as there is no technique has been introduced as this model.
"21I-2177 Hummayoun Mustafa

Disambiguate Medicine Names in Handwritten Medical Prescriptions using Deep Learning"	Digitizing medical prescriptions has always been a hard task due to unavailability of data, the unstructured text on prescriptions and variations in handwriting that make it hard to detect and recognise the text. If a medicine is classified incorrectly it can result in fatal consequences. In order to reduce these problems we use existing techniques to generate data that is similiar to a doctor handwriting and train a document understanding model to detect different features such as diagnosis, history, temper- ature,blood pressure, weight, medicine type, doctor specilization that can help us to classify a medicine in an efficient way. Existing approaches only detect the text and don’t use these features which can lead to a wrong medicine especially when two medicines have similiar names. We train our approach on our dataset and existing state of the art architectures. The proposed approach outperforms the existing handwriting detection models.
"21I-2178 Shaina Laraib

Key-Word Spotting in Low Resource Speech"	"The basic mode of communication in humans to express their feelings is speech. A lot of information carried by speech signals can be utilized to perform various machine-learning tasks. Automatic Speech Recognition (ASR) is being greatly used by researchers due to its high accuracy and less consumption time. ASR technology has improved human-machine learning interactions. It has several real-world applications such as voice-based language translation, speaker identification, voice-based biometric verification, voice-to-text conversions, and voice command recognition in voice assistants. Whenever humans communicate, a lot of speech data is generated, which can be used to extract hidden information for intelligent task performance by machines. The acoustic embedding-based approach is used to extend spoken term detection to the Urdu language. A keyword audio data set is initially prepared, ensuring multiple samples are available for each word. Pre-processing is done to remove any background noise from the samples. Spectral features of the speech recordings are
extracted, then, acoustic word embeddings are computed by fine-tuning the already trained embedding extraction model. The speech stream is subsequently segmented into smaller parts, each representing one word. Embeddings are also calculated for these segmented audio frames. In the final step, keywords are detected by comparing embeddings using a Cosine similarity metric. The proposed approach is tested on the Common Voice dataset of continuous speech recordings and evaluation metrics are computed. Our approach achieved satisfactory precision and recall for the Urdu dataset."
"21I-2181 Saad Munir

Multiple Features Based Bi-Lingual Fake News Detection using an
Ensemble Approach (BiL-FEND)"	As we already know fake news detection is a popular research topic but when we talk about multi-lingual fake news detection it is still evolving. The fake news data is also available over the internet, but the issue is that majority of data is not categorized, the features are very much limited in the datasets available online, most of the data available is monolingual mostly available in English Language. To increase the features of the datasets is one the main reason to go with this topic. Features can play a vital role in the detection of the fake news. As already mentioned, we are diving in this project with two Languages one is English which richly resourced language and the other one is Urdu which is not richly resourced language. That’s why we can’t just go with conventional approach of using only ‘Body’ and ‘Title’ of the news, we must take other features into  consideration.
"21I-2380 Salwa Khatoon

Exploring Usable Security in Web &amp; Mobile Applications"	In developing interactive software systems, applications, and products which include information systems, banking systems, safety-critical systems, healthcare systems, web and mobile applications, etc., finding a balance that offers satisfying levels of security and safety is crucial. In such systems, usability, and security are simultaneously required to maintain the effectiveness of the technology. Failing to design and achieve this equilibrium may lead to unrecoverable and destructive security breaches in the long term. However, users tend to reject unusable solutions. Therefore, having well-balanced amounts of both is a prerequisite for a system software or a product to be accepted by a user. Through this research, we explored the severity and impact of ISO 25010 usability-security factors, primarily focusing on the insubstantially investigated usability factors by conducting an experimental study over web and mobile applications. The selected applications were Daraz.pk & Easypaisa. By reviewing  the existing literature, we identified the inconsiderably explored usability factors. These were Learnability, Accessibility, User Error Protection, and Appropriateness Recognizability for usability. For security, the considered factors were Confidentiality, Integrity, and Availability. These factors are analyzed over web and mobile applications' multiple user interface elements, not limited to login credentials. Using the experimental results, we performed an extensive data analysis and validation involving different analysis methods and techniques e.g.; multi-criteria decision and sensitivity analysis methods. Based on the derived results, we proposed an optimize solution in the form of a usable security pattern named as User Accessible Data Integrity, which emphasizes on guaranteeing accessibility and integrity in software applications by delivering a structure for encompassing usability and security measures. It confronts the necessity for moderation between data integrity and user accessibility. The study delivers a systematic structure for integrating usability and security measurements assuring accessibility and integrity in software applications confronts the requirement for symmetry between user accessibility and data integrity. It also contributes to on-going research debate of resolving usability-security conflict. More ever, it also helps the beginners or naïve researchers with similar interest to have more knowledge and insight helping them to explore and learn. 
"21I-2386 Ateeque Rahman

MEREC-WISP(S) Integration extended with Fermatean Fuzzy Set for 
Requirement Prioritization"	"The successful and efficient prioritization of requirements is crucial to the success of software projects, as they are frequently bound by time, budget, and quality constraints. To balance
conflicting criteria, MCDM techniques are frequently used, but they struggle with defining the ranking order of options due to involvement from multiple parties. Existing MCDM prioritization
methods have several drawbacks, such as inappropriate management of uncertainties. In the context of software development, this thesis introduces the novel WISP-S technique to requirement
prioritization. The strategy makes use of the dynamic combination of the WISP(S) approach and the MEREC method. This approach makes use of Fermatean fuzzy numbers to handle qualitative
data and uncertain information effectively. The approach addresses the drawbacks of existing MCDM methods, providing a more efficient and effective way to prioritize software requirements
within time, budget, and quality constraints. The two distinct phases of this study both add significantly to the field of requirements prioritization. The introduction of an enhanced MEREC
technique, created explicitly to compute the objective weights of each criteria within the context of Fermatean Fuzzy Sets (FFS), occurs in the first phase. By combining the distinctive features of
FFS, this expansion improves the current MEREC technique and enables a more thorough and precise examination of criteria weights. The second step integrates the WISP(S) method with the
suggested generalized weighted Fermatean fuzzy aggregated operator and MEREC technology. Through this integration, alternatives can be ranked and evaluated in a context of prioritization.
The study provides a strong and robust strategy to prioritize alternatives, taking into account both qualitative and uncertain data, by integrating two novel methods. The validity and robustness of
the approach are confirmed through comparisons with existing models and sensitivity analysis, and the proposed approach is demonstrated through multiple real-world case studies. Overall, the
WISP-S approach provides a novel and effective technique for integrated Fermatean fuzzy information-based decision-making, which can handle complex decision-making problems in
software development. The approach has the potential to improve the success of software projects and addresses the shortcomings of existing MCDM methods."
"20I-2012 Ateeque Rahman (MS Project)

Integrated Requirements Specification,Validation and Traceability Tool"	Requirements management is defined as gathering, analysing, verifying and validation the needs and requirements of a software product. Better requirements management leads to better development of software products which meets all the expectations of stakeholders. Requirements management tools solve the problem of poor requirements engineering process. In software development different types of requirements are specified from users like business requirements, functional and non-functional requirements. To facilitate the engineering requirements process, various tools can be used. These tools help tacking, controlling, monitoring requirements for the software project. This project explores existing requirements management tools and proposes state of the art tools in requirements management. The tool is a web-based application targeting all types of software development teams from small to medium to large scale. Main features of the tool are requirements specification, requirements validation and requirements traceability. The tool facilitates teams in communication, collaboration, and stakeholders’ involvement in the requirements process.
"19I-1806 Talha Manzoor

Detecting Malicious Traffic from Encrypted Network Trafficof Mobile Devices and 
Identifying Apps generating them"	There is persistent development in the acquisition of network traffic encryption. The well-known applications safeguard the client’s privacy by using certain protocols of encryption. Where the use of these encryption protocols gave user privacy protection it has risen some serious issues of malware spread as this malware hides itself beneath this encrypted traffic. Therefore, it is necessary to assess this encrypted network traffic because it can cause some serious damage to the organizational assets. The modern solutions provide functionality to uncover such malicious traffic but they rely on DPI where network traffic packets are analyzed by decrypting them, and the user privacy is compromised. These solutions are also resource intensive. So, we developed a solution which can detect malicious network traffic by utilizing less resources and maintaining user privacy. We extracted network traffic features from the packets, analyzed these features, and then isolated the malicious traffic based on these features. Afterwards, we fingerprinted the mobile applications generating that malicious traffic, so that the applications can be blocked on the network. We achieved an accuracy and F-1 score of more than 98%. This approach applies and performs well on both Android and IOS devices.
"19I-1810 Muhammad Shah

Machine Learning based open SIEM solution"	The quantity of logging events and the administration of these logs are growing daily in this age of digitalization because many things have been converted to digital form. The industry makes use of SIEM solutions to monitor these records. Security incident and event management, or SIEM, is a solution that gathers logs from various devices, analyzes these security events, and generates alarms based on the happening of any malicious events. However, a SIEM is a fully commercial solution, and because to its high cost, it might not be an appropriate choice for small businesses. and accessible Scalability, Management Security Service Provider (MSSP), and Anamoly attack detection are lacking in open SIEM solutions. The development of a simple, open-source solution is addressed in this study. After developing the solution described earlier, a study on the scalability factor will be conducted in order to determine the best option for this use. Scalability and anomalybased detection features are the main highlights of this open source Security Information and Event Management (SIEM) solution. The issue of successfully managing and identifying security issues in the face of growing data quantities and sophisticated cyber threats is addressed by the solution. The open source SIEM system gives enterprises a flexible and affordable way to improve their security posture by utilizing scalability approaches and anomaly-based detection methods. A MLSIEM was the end product of the final deployment. Eventually, the proposed design will be incorporated into the actual production environment for small and medium-sized businesses.
"19I-1813 Ahmed Zaka

Lightweight and Efficient Trust Mechanism for Sybil Attacks in IoT"	The IoT sensor nodes are responsible for gathering data from their surrounding environment. The IoT sensor nodes forward the data collected from the environment to an access point (AP). The data collection is necessary for data fusion. The IoT sensor nodes are deployed in an environment which is usually unattended. This environment can also be hostile for IoT sensor nodes. The IoT sensor nodes as a device has also some resource onstraints. These constraints include limited battery power, memory and computing capabilities. Due to environmental and resource constraints, it is easier for an attacker to compromise the IoT sensor nodes. The attacker can execute numerous attacks from these compromised IoT sensor nodes in IoT network. One of the most important attacks is the sybil attack. In sybil attack, the compromised IoT sensor node becomes an IoT sybil node. The sybil node creates multiple identities. These identities can be either new one or existing identities of legitimate IoT sensor nodes. The sybil node can influence the IoT network due to the large number of identities. A lot of research work has been done to protect the RPL protocol in IoT network from the sybil attack. The traditional techniques of trust management system (TMS) are not suitable for IoT devices because it badly affects their battery life. Therefore, we are going to propose a novel trust- based mechanism to protect the IoT devices from the sybil attack. In our proposed technique, it is not necessary for a node to monitor its neighboring nodes in its communication radius. When a data packet arrives at the root node, it will extract and store the required information. The root node which is a powerful node will do all the calculations related to trust values. The root node will also store the complete information about the IoT network for future reference.
"20I-1963 Junaid Khan



Lightweight Trust-Based Security Mechanism for Grey
Hole Attack in RPL in IoT Network"	The rapid evolution of technology has led to the widespread adoption of Internet of Things (IoT) devices, providing convenience and connectivity to users. However, this connectivity also introduces security challenges, necessitating the protection of IoT systems and devices. One significant challenge is the grey-hole attack in RPL-based networks, where malicious nodes selectively drop traffic. Detecting and mitigating such internal attacks pose a considerable concern as the compromised nodes may already be authorized and compliant with network security parameters. Identifying rogue nodes within an internal IoT network is a key challenge. The other big challenge is the identification of malicious nodes, either the traffic is dropped because of a grey hole attack or its normal routine network traffic drop. In this research, we propose a Lightweight Trust-Based Mechanism for grey hole attack detection and mitigation in RPL networks. The detection of grey hole-dropped traffic is a particularly challenging aspect that our system addresses. Our approach leverages dynamic threshold values and cross-checking Packet Delivery Ratio (CCPDR) to accurately classify nodes as benign or malicious based on their traffic behaviour. Through extensive simulations using the Cooja 3.0 simulator, we compare the performance of our mechanism with the traditional RPL protocol. Evaluation metrics encompass attack detection accuracy, packet delivery ratio, end-to-end delay, power consumption, and energy usage. The results demonstrate the superiority of our proposed mechanism, showcasing improved attack detection accuracy, higher packet delivery ratio, reduced end-to-end delay, and optimized power and energy consumption. By effectively distinguishing between normal and maliciously dropped traffic, our research contributes to the enhanced trustworthiness and resilience of RPL-based IoT networks. Considering the increasing adoption of IoT technology and the critical need for secure and reliable communication, our research highlights the significance of detecting and mitigating internal attacks like the grey hole. By implementing our Lightweight Trust-Based Mechanism, IoT networks can bolster their security measures and protect against these evolving threats, ensuring uninterrupted service delivery and safeguarding the integrity of IoT systems.
"21I-2203 Umer Bilal

Dynamic allocation of window size for detection of the low-rate DDoS attack"	"Distributed denial of service (DDoS) attacks are a major concern in the world of cybersecurity. In the early 1990s, the first instances of what would later be called Distributed Denial of Service attacks were documented. In order to disrupt or slow down the services of legitimate users, DDoS attacks utilize networks of hundreds or thousands of computers to launch simultaneous attacks. High-velocity (H-DDoS) and low-velocity (L-DDoS) DDoS attacks are the two most common varieties. Slowly but gradually, low-rate DDoS attacks have become the norm and are significantly reducing network capacity. To correctly detect threats, the conventional Multi Classifier System uses entropy based on attributes and a machine learning technique. Low-Rate DDoS attacks were previously detected using a predetermined window of time. The one drawback of the approach is that it is limited to a certain time frame. If no suspicious data packets are identified within that time, they will change the time period statically. However, we were unable to successfully detect the complicated attacks using this approach since the attacker sends the attack packet at a certain time. Recent research has focused on ways to detect slow DDOS attacks using just static monitoring data. To solve this issue, we compared the results of different machine learning classifiers and deep learning algorithms, such as Multilayer perceptron (MLP), alternating decision tree (ADT), recurrent neural network (RNN), long short-term memory (LSTM), and random forest
(RF), to propose a dynamic allocation of the window size for recognizing DDoS attacks. The window size is constantly calculated based on analysis of the incoming data, allowing for the capture of changing traffic patterns during the evolution of an attack. We evaluate the proposed system using a publicly available network traffic dataset, demonstrating its ability to effectively identify DDoS attacks while lowering the number of false positives. Using the UNSW_NB15 datasets, we evaluated three different methods and shared our results. This study proposes a strategy for enhancing the accuracy and reliability of DDoS attack detection in practice by adjusting the window size at which characteristics of network traffic are obtained. We train the datasets using historical data, then utilize the resulting patterns to guide the model's development."
"21I-2209 Ameer Hamza

Preventing Session Hijacking and cookie poisoning using One-Time-cookies and Blockchain."	"After the user's credentials have been validated, online applications will use a cookie as an authentication token. They are at risk of being stolen, pirated, or improperly distributed since they are stored on the client's end. Strategies for bolstering cookie safety may be found in the existing literature. However, it is still common practice to steal someone else's seesion and claim them as your own. Session cookies enable users to avoid routinely logging in and out. If an adversary has access to a user's session data, they may pretend to be that user. Using blockchain technology, nonfungible tokens, One-Time-Cookies, and smart contracts, our recommended architecture prevents attacks in which an adversary obtains a user's session cookies. When a user authenticates successfully, the web server generates a session ticket in their name. Due to the fact that the
blockchain verifies the validity of each request and provides new cookies with each, distributed cookie verification is simplified. The long-term goal of this method is to make it harder for bad factors to take over a user's session. Thereby reducing the likelihood of identity theft and cookiebased impersonation."
"21I-2309 Abubakar Shafiq

Web-Sum: an intelligent framework for Multi-modal summarization on web corpus"	"As the time is approaching in which the growth of data is exponential, a large body of researchers have emerged to work on multi-modular approaches for text summarization. Majority of them focus on producing a summary from a single document with relevant image recommendation. These existing methods mostly focus on either abstractive or extractive summarization on a single document and they use image caption for its recommendation. Some of the proposed model used multiple documents for summarization .Our proposed model is the first to generate multi-modular summarization on multiple documents on web scrapped data. This model is using a bidirectional encoder along with auto-regressive decoder based transformer for generating abstractive summary along with a visual guided decoder for image recommendation/image retrieval based on matching the generated summary with the images. This visual decoder helps in understanding and integrating the images with text generation. The results generated from the transformer and the visual guided decoder are then integrated together to generate a single output. This newly proposed technique can help bringing a great improvement in the multi-modal summarization task.

"
"21I-2276 Tayyab Jalil

NLP-Based multimodal approach for classification of unstructured textual documents"	Abstract text should be based on three aspects: 1) Introduction and background of the field/domain in which you are working. 2) Overview of the existing techniques in the core research domain and the potential limitations of those research works. 3) Overview of your proposed approach or solution.
"21I-2286 Ahmad Raza

Opinion Mining on Amazon Product Reviews With & Without Emoticons using fine-tuned 
BERT (Emojify BERT)
"	"Sentiment analysis (SA) additionally known as opinion mining is the latest fashion in a day. Nowadays, people are who prefer online buying and, on this attitude, E-commerce is developing very speedy. Customers proportion their thoughts approximately a particular product by sharing an internet evaluation. Sentiment evaluation is categorizing the sentiment to effective, terrible or impartial. Sentiment analysis of product evaluate the use of dataset from amazon.com changed into completed. The dataset gathered from Amazon S3 garage public APIs. Four datasets of four one-of-a-kind categories were fetched from four different APIs. The dataset (after Pre-processing) includes four features (i.e. star_rating, emojis, reviews & labels) and 54,456 rows. Use of Emoticons in textual content can affect the overall sentiment score. BERT is presently maximum frequently used model and it offers a better accuracy and better outcomes compared to different NLP transformer-primarily based models. BERT doesn’t have pre-educated embeddings to classify emojis. Consequently, we proposed an extended variant of BERT (base) model called ‘Emojify BERT’ with a view to classify sentiments with & without emoticons. Our proposed study compiled the effects as 97.98% accuracy with Emoticons & 96.30% accuracy without Emoticons in testing phase. In conclusion, our proposed method stepped forward the accuracy of model whilst emojis has been delivered in text.
"
"21I-2314 Tariq Aziz

Islamabad Real Estate Investment: A Valuation Assessment using Predictive Analytics"	"Real estate valuation is vital for the formation of real estate policies and can help real estate owners, agents, and investors make informed decisions. Since 2010, demand for real estate properties in Pakistan has started growing. Till date, almost 2767 residential societies are registered in Pakistan, and the number is increasing by the day, while the size of the real estate market is about 15 to 20 trillion rupees. This study aims at a valuation
of real estate properties using predictive analytics techniques, e.g., machine learning and deep learning, on publicly gathered real estate data from online real estate sites, e.g., zameen.com, grana.com, etc. The study will
deploy a data-oriented approach to the real estate valuation problem to help online real estate agents valuate their listings using machine learning algorithms."
"21I-2375 Maria Salim

A NOVEL UNCERTAINTY AWARE Q-ROFS – MEREC - WISP BASED DECISION
SUPPORT FRAMEWORK FOR MULTI-CRITERIA DECISION-MAKING PROBLEMS"	Multi-criteria decision making (MCDM) is an active subfield of operations research focused on evaluating and prioritizing alternatives under conflicting criteria. MCDM-based solutions provide a ranked list of alternatives based on multiple conflicting criteria and a predefined preference structure to identify an ideal solution. Growing interest in uncertainty-aware and data-driven decision making aims to address pervasive incomplete, vague, and imprecise information. The MCDM community has undergone a paradigm shift regarding methodological, theoretical, and application aspects of fuzzy set theory (FST). Numerous fuzzy set extensions have been proposed to model complex decision-centric data since the inception of FST. Among these, Q-rung orthopair fuzzy sets (Q-ROFS) are a recent and widely applied extension, generalizing intuitionistic, Pythagorean, and Fermatean fuzzy sets while affording expanded preference expression. This work presents a novel integrated decision framework combining the Method Based on the Removal Effects of Criteria (MEREC) and Simple Weighted Sum-Product Method (WISP) under a Q-ROFS environment. This allows flexible judgment and preference articulation by decision makers. Its usefulness is demonstrated through case studies on communication tool selection and green supply chain management. Robustness is verified via a two-fold sensitivity analysis. Comparative analysis validates the proposed model against existing Q-ROFS-based MCDM techniques. Reliability and validity are further evaluated using Spearman's correlation and hierarchical clustering. Rigorous assessment reveals that the framework captures user preferences more comprehensively while representing a wider space relative to extant fuzzy set extensions. To our knowledge, this is the first integration of MEREC and WISP under Q-ROFS with thorough evaluation of the framework.
"21I-2392 Nadia Bashir


QAEAR -LSTM: An Automated Quality Concerns Identification Approach for App Reviews
 Using Deep Learning Models"	"With the recent adaption of mobile applications, User reviews are regarded as one of the most vital information sources about an app. A significant challenge has emerged in the classification and analysis of reviews to extract information. Because the mobile app market is so competitive, functionally similar applications are distributed through app distribution platforms. Review feedback from users is provided to mobile applications, which can assist developers in identifying apps with improved functionality and extracting useful information pertaining to user requirements, bugs, descriptions of the user experiences connected to the current features, as well as suggestions for future features. The study of app reviews is a relatively young field in software engineering because of the massive user base and the potential benefits of automated feature and bug extraction. Numerous recent studies have been conducted with the aim of mining and classifying user reviews, feature requests, bug reports and actionable software maintenance requests. App Quality is essential for meeting customer demands and expectations. In general, App quality is a functional behavior that is heavily influenced by quality concerns. However, existing literature has largely concentrated on mining functional aspects and analyzing user reviews and for extraction and synthesis quality concerns are largely ignored. Addressing these requirements is critical to user satisfaction and survival in the app market. Manualanalysis is impractical for the enormous volume of reviews that are received daily. As a result, text mining techniques have been employed in research on mining app reviews to extract meaningful information from the reviews. A classification model is trained to categories reviews into groups like ""feature request,"" ""feature evaluation,"" ""bug report,"" and others, the need to enable developers to extract automatically meaningful information from reviews. Additionally, some research works have focused on extracting quality concerns from evaluations of mobile apps. When analyzing users' perceptions of the app quality, the mechanism utilized to automatically extract such information is critical in terms of accuracy. Due to the wide range of opinions people express opinions about an app's quality in user reviews, automatic extraction of quality concerns is a challenging task. However, some previous studies that have already been conducted have concentrated on a few quality concerns of their own choice like performance, usability, portability, and security. They have chosen quality concerns and have not followed a particular latest quality model ISO 25010 (Product Quality and Quality in use) as a basis of their studies. Therefore, there is a need for a classification model that automatically extracts the user quality concerns by considering the latest quality model ISO 25010 from commercial mobile app reviews.  he study aims to what users want and say about quality concerns. So, in the next version, we will update the architecture, address these quality concerns, and facilitate the requirement elicitation process. In this study, the topic is formulated as a multi-label classification problem and provides a classification model. Furthermore, the suggested model is founded on 20,000 reviews extracted from 28 Android apps. This is the first study of its kind in the classification of mobile app reviews, which uses a classification model to categories reviews into multiple categories of ISO 25010 quality concerns. Deep learning models were chosen for the classification of quality concerns in this investigation, as few studies have utilized these models for this problem. A comparative study was conducted to evaluate the effectiveness of three deep learning algorithms, namely Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM), for the classification of quality concerns. The study utilized a dataset of 20,000 Android mobile app reviews and employed three different word embedding techniques, namely Word2Vec, Glove, and FastText. Two separate comparative studies were performed, one without addressing the issue of class imbalance and another one addressing the class imbalance issue using the SMOTE technique. In addition, a comparative study was conducted using the most used basic machine learning classifiers, namely Naive Bayes, Support Vector Machine (SVM), and Logistic Regression. However, the performance of these classifiers was found to be inferior when compared to the deep learning approaches employed in the study. The results indicate that the deep learning models outperformed the basic machine learning classifiers in terms of classification accuracy and overall performance. The results of the comparative study without addressing the class imbalance issue indicated that the QAEAR-RNN model, implemented with the Word2Vec word embedding approach, outperformed both the CNN and LSTM models in terms of classification accuracy. On the other hand, the results of the comparative study addressing the class imbalance issue showed that the proposed model QAEAR -LSTM model, implemented with the Word2Vec word embedding approach, outperformed both the CNN and RNN models in terms of classification accuracy. 20% of the data was used for testing, while the remaining 80% was used for training. The models were trained using training data, and the suggested model's effectiveness was evaluated using testing data. To classify quality concerns, the produced vectors were fed into the models. The study results reveal that in the absence of addressing he class imbalance issue, the QAEAR -RNN model utilizing the Word2Vec word embedding technique outperformed the other word embedding techniques, achieving an accuracy of 97.9%. Conversely, in the study where the class imbalance issue was addressed, the proposed QAEAR -LSTM model with Word2Vec demonstrated superior performance compared to the other word embedding techniques, achieving an accuracy of 98.7%. The effectiveness of the suggested models was assessed using evaluation measures like “accuracy,” “precision,” “recall,” and “f1-score”. The proposed models outperform the alternative approaches, according to a comparative evaluation that was also conducted using various studies."
"21I-2163 -Usman Khan


Efficient Deep Learning Based Document Classification Using Cosine 
Similarity Based Methods"	DocumentAI is becoming an increasingly prominent subfield of AI. The research was conducted on the efficiency and effectiveness of the document categorization problem using a variety of methods to determine whether or not we can achieve a reasonable performance with a small model. This research was conducted to determine whether or not we can compete with the existing state-of-the-art models by any means. After completing a number of experiments, it was discovered that the proposed model has achieved an astounding level of accuracy while being exponentially smaller than other models that are currently regarded as state-of-the-art. Our model contains 28 million parameters, and its accuracy has been increased to over 93%. In contrast, the current state-of-the-art systems have between 113 million and 380 million parameters while still achieving nearly 95% accuracy.
"21I-2387        Itrooba Marrium


Just-in-Time Software Defect Prediction in Mobile Applications"	Software defect prediction is a way to detect buggy code so that developers/testers can oversee it early. Nowadays as different developers are working on the same project at a time. So, it is difficult for the testers to detect the buggy code. We need efficient ways of detecting the bugs in the code. Just-in-time software defect prediction (JITSDP) is a model to predict whether the commit is buggy. Researchers have proposed many machine learning, deep learning, and, ensemble techniques for just-in-time software defect prediction in the traditional software application domain. They focused on class-imbalance issues, feature extraction, and for mprovement of models to a fine-grained level for detecting buggy lines in the commit. Mobile applications are different from traditional software and have less historical data. Moreover, traditional features cannot be directly mapped in this domain. Just-in-time software defect prediction in the mobile application domain only focused on class imbalance and feature extraction issues. There is a need to work on defect prediction at the fine-grained level in this domain. We developed a model using hunk level metrics along with changed metrics to predict the buggy lines in the commit. We used random forest, logistic regression, and Naïve Bayes classifier for prediction model and N-gram language model for localization model. Our approach helps detect buggy lines in commits with 77% accuracy with prediction model and 69% Top10 accuracy with localization model. This will give insights to the researchers to further develop improved fine-grained models in the mobile application domain and practitioners to reduce their effort at inspection.
"Sara Afzal 



Multiclass Classification of Malicious URLs using Contextualized Embeddings"	With 4.48 billion active users today, Online Social Platforms (OSNs) play a huge role in people’s lives. As a result, it is critical to safeguard OSNs against cybercriminals. Cybercriminals can use multiple platforms to target a big number of people and cause them harm. The objective for this research comprises of multi-class classification of URLs keeping OSNs as the primary focus in order to protect their users. Existing research relies heavily on features that can only be accessed after visiting a URL, such as machine activity features. Because these features need the URL to be clicked on, poten tially inflicting damage to the user or the machine, it is not an appropriate method for assessing the maliciousness of a URL. Utilizing static features like the domain, length,count, or lexical features is another technique for extracting features. However, this method prevents the model from storing the contextual significance of various words in a URL. Other than that, the majority of current research concentrates on binary classification and does not classify URLs into different categories of maliciousness so that the proper course of action can be performed. Because of this, we suggest a system in which we first use BERT to obtain contextual embeddings of a URL and then divide the URLs into five categories: benign, spam, defacement, phishing, and malware. Using the suggested model, we achieve an accuracy of 0.998 overall.
"Nasir Hussain


An Automated Approach for Cross-Platform 
Testing of Web Applications"	A large number of users in both personal and business activities use web applications. Web application users can access them through multiple devices like desktops, tablets and mobile devices of their interest and ease of use. These users expect consistent and error-free behaviour of web applications across multiple devices. Managing web applications across different platforms requires more time and testing effort, so there are high chances of incompatibilities in web applications. Cross-Platform incompatibilities (XPI’s) becoming an important and considerable problem of web applications. These incompatibilities range from minor issues to high-level functional bugs, and failure in the detection and prevention of these incompatibilities even after testing degrades the user experience. Cross-platform testing (CPT) for web applications is used to identify and prevent these incompatibilities, it aims to find layout incompatibilities along with functional incompatibilities. The existing state-of-the-art approaches focus on identifying layout incompatibilities across cross-platform. These incompatibilities also affect the test cases and test scripts across cross platform. Practical approach to test these test scripts on other platforms is to rewrite separate test scripts from scratch, by keeping platform properties in mind, it requires a lot of resources and significant testing effort and time. Considering the above-mentioned limitations, we are going to present an automated approach for cross platform testing of web applications, which will migrate test scripts of web applications from one platform (desktop) to another platform (mobile devices) by preventing breakages that exist in cross platform web applications. Three subject applications from different domain are used to check effectiveness of the proposed approach. Our proposed approach successfully migrates and tailors 87.5% of test cases from desktop version to mobile version web application while maintaining fault-finding capability and same test coverage.
"Pir Sami Ullah

Towards MLOps: DevOps Tools Recommender System for Operationalization of Machine Learning Systems"	Applying DevOps practices to machine learning system is termed as MLOps and machine learning systems evolve on new data unlike to traditional systems on requirements. The objective of MLOps is to establish a connection between different open-source tools to construct a pipeline that can automatically perform engineering to construct a dataset, train the machine learning model and deploy the model to the production as well as store different versions of model as well as the dataset. Moreover, the purpose of MLOps is to make sure the fast delivery of the latest trained model to the production in order to have accurate results. Furthermore, MLOps impacts the overall quality of the software products. And, MLOps process is completely dependent on open-source tools while selection of best tool chain is considered as challenge. Therefore, this thesis presents an automatic ML-based system that processes the contextual information (e.g., nature of data, type of the data) of the machine learning project and recommends a relevant tool-chain (tech-stack) for the operationalization of machine learning project. Four different approaches such as rule-based approach and machine learning approaches i.e., random forest, decision trees and k-nearest neighbors are investigated and upon the greater value of f-score metric, the random forest is selected and integrated with the product for the use of end-users.
"Bushra Amjad


A Computational Modeling of Empathy in Open-Domain Dialogues"	Measuring empathy in conversation can be challenging, as empathy is a complex and multifaceted psychological construct that involves both cognitive and emotional components. Conversational AI enables the system to have natural conversations with humans or other agents in the form of automated messages in text or voice format. We proposed a novel approach to automatically measure Empathy in open-domain dialogues considering the high variability of user behavior. The proposed technique can be used in improving empathetic Dialogue generation. We proposed an emotion scale that is helpful in modeling empathy as per social science experts. We tested  our metric on state-of-the-art dialogue generation models and provided a comparative analysis that can be helpful in future research for dialogue models. Our empathy scores are pretty inclined with the human-annotated bench-marked datasets. We tested our computational approach on state-of-the-art conversation models like dialoGPT or facebookblender and compared the results. Examples are shown for comparison between our predicted scores and human-annotated values. The correlation between our prediction and ground truth values is 0.6 which shows a moderate linear relationship between the two different approaches.
"Tabish Tehseen 




Price Forecasting for Household
Electronics Using Time Series Data"	E-commerce is increasingly becoming the preferred method of selling a product to a wider segment of the population. Online retailers i.e. OLX, Amazon, have grown rapidly in recent years. Additionally, every day, online shopping markets sell millions of products. In such emerging trend of e-commerce, price forecasting can significantly help customers to grab future promotions on the product of their choice. Therefore, we have developed a framework that can perform price forecasting for seasonal as well as non-seasonal products. To server the purpose, we generated pricing information of roducts listed on Amazon.com, by using specialised APIs and dedicated crawlers, for the time series model i.e. AR, ARIMA-X, SARIMA-X, LSTM, and GRU. A grid search has been implemented to select the best combination of the parameters for selected models, to get the better prediction. In addition to that, this research work has used exponential moving average technique for data smoothing instead of using the original pricing data for prediction. We discovered through experimentation that this technique produces relatively good results for prediction as compared to original price information. Furthermore, this research work has also evaluated the impact of environmental variables on price forecasting i.e. Inflation Rate, Quality Score, and Popularity Score. We have used the extended versions of ARIMA and SARMA, known as ARIMA-X and SARIMA-X, where X refers to Environmental variables. Moreover, results generated by earlier mentioned time series models have been compared. ARIMA-X has produced good results for Non-Seasonal products, on the other hand SARIMA-X was a better choice in case of Seasonal products. Whereas, LSTM and GRU has produced comparatively less accurate results in terms of RMSE and MAPE as shared in results section. Keywords: Time series; Amazon; Keepa; AR, ARIMAX; SARIMAX; LSTM; GRU; Machine Learning; Grid Search
"Hira Tahir

Generating Episode-wise Textual Highlights of Urdu Dramas by Extracting Metadata from User Comments"	YouTube is one of the biggest platform for fetching and analysing user comments for data mining. Top Pakistani YouTube channels are entertainment channels that up- load the Pakistani dramas and get the most views from the audience. People comment under the dramas showing their sentiments, liking or disliking about particular dramas and its scenes. In this work, multilingual dataset is gathered from YouTube comments of Pakistani dramas. Roman Urdu and English is the considered language for this work. Dataset is processed in order to generate the drama summary and highlights from the metadata of user comments. Multiple text summarization and topic model- ing approaches are used in this study. Two graph-based approaches i.e. TextRank & LexRank are used along with transformer based BertSum model. We compared our automated proposed approach with LSA and LUHN model. BART is used as abstractive model to generate the textual highlight. Evaluation is performed using SentenceBert. Keywords: Text summarization, Abstractive summary, Extractive summary, Bilingual dataset, Machine learning, NLP, LDA, BART, BertSum
" Ahmad Awan

Fault Tolerance Aware Deadline-Constrained Cloud Scheduling"	Cloud computing is an online and on-demand service that allows users to acquire services or hardware such as CPU, GPU, storage, database, etc. In recent years, there has been a boom in cloud computing, especially for small businesses due to its ease of hardware acquirement, pay-as-you-use plan, and the ability to only acquire those services or hardware that you need, for only as long as needed, in a region close by. Due to the increase in usage, more emphasis is being placed on making the technology and its different aspects more intelligent in key areas, one such area being job scheduling. A job scheduler needs to assign different tasks from a task queue to different virtual machines (VM), in a manner that leads to efficient resource utilization, within the user’s specified deadline. If a task can run on a VM within its specified deadline, the task is moved to the scheduled queue for that VM, otherwise, it is rejected. However, certain tasks could have avoided rejection if they had arrived sooner and had been positioned higher in the task queue. Using this knowledge, we can alter both the task queue and scheduled queue to improve performance. The task in the task queue can be sorted in a way that prioritizes tasks with small deadlines relative to the task’s length. The task can also be placed higher up in the scheduled queue rather than at the end if it does not affect the deadlines of the other tasks. The scheduler should also leverage the elastic nature of cloud computing to acquire new resources and release them as needed. While acquiring and releasing resources, the scheduler must account for delays, such as boot time and resource acquisition delay. Even after scheduling all tasks, a hardware failure can cause us to lose all the progress made by the scheduler. To solve this, we can clone the tasks and schedule them on multiple machines rather than a single machine. But this method of fault tolerance is too resource-intensive, so it must be done in a way that is not too resource-intensive and prioritizes tasks by their deadline. A scheduler is presented called DFARM (Deadline Fault aware task Adjusting and Resource Managing scheduler) that dynamically schedules deadline-constrained tasks using the length of the task relative to its deadline. The scheduler is fully capable of dynam ically allocating and releasing resources as needed while offering fault tolerance using a hybrid replication-resubmission method. The scheduler is compared with others such as Random Selection, Round Robin, Minimum Completion Time, RALBA, and OG-RADL.
"Rohail Younas 

Urdu TTS with multi-speaker support and Few Shot Learning"	In recent years, there has been significant progress in the adoption of text-to-speech (TTS) systems in academia and industry. The question remains whether these systems can achieve human-level quality and be judged/reliably measured in those terms, as well as how they can be implemented. The performance of automated TTS systems has improved considerably due to deep learning techniques. However, a considerable amount of text-speech paired data is required to train these models, which can be costly. Multi-speaker models have shown superior results in constructing low-resource, single-speaker TTS models. To train and test various deep learning models, a limited Urdu dataset with text and audio pairs will be used. To evaluate the quality of the synthesized speech, I assess the model's ability to assume speaker identity features in both seen and unseen scenarios.
" Talal Tariq

Story Generation and Understanding system"	Story Generation is seen as a sub-task of Natural Language Generation. Stories are however, a sequence of events that have inter-related connections amongst them. There have been a multitude of frameworks to define stories. Stories generated because of direct natural language generation paradigm lack coherence, fail to capture, or represent a world state and fundamentally suffer from entity coreference resolution. Hierarchical and Multi-Modal approaches have been used to generate stories with State-of-the-Art Results via Deep Learning Methods. Previous decades relied upon Rule-Based approaches. Neither approach on its own produces coherent plots that follow a sensible direction. Studies have shown that all stories follow certain emotional shapes or plotlines. Representation Learning of story plots is a task that involves generating events that are connected and drive the story towards the end goal. As such, keeping a track of the world state and the state of entities and their interactions in the world in view of the goal can help us bring that coherence in generated stories. Temporal connections and causality between events are exceedingly difficult to map and a multitude of techniques from Rule-Based generation algorithms to graph based state embeddings have been tried to that end. Multi-modal techniques have also been used to better capture the state representations of the world via a sequence of images. No attempts have been made to model generation systems that can generate comprehensive stories that follow emotional patterns leading towards the goal state resolution. We propose a einforcement learning framework that incorporates language models and breaks down the various aspects of story generation such as the world state and the entity sates towards the end state goal via an Agent that acts as the writer. The intuition being that modelling a writer as opposed to a story can help us bring coherence to the overall generation system. To do so, we propose a knowledge base that the writer can access. Therefore, it can be argued that natural language understanding is a key component to generating comprehensive stories. A knowledge base at the center from where the Writer (Agent) can extract and use information to bring global coherence and a respectable level of diversity is an integration of both, NLU and NLG. 
" M Mattah 

Entropy-based Detection of IoT based DoS attack using Multi-Classifiers"	"An Internet of things (IoT) device’s service may be temporarily or permanently disabled by a denial of service (DoS) cyberattack . This attack type has often been cited as the most prevalent and makes up a significant share of all cyberattacks. These assaults are also becoming more frequent daily, endangering the ecology of cyber security. In the modern era, these assaults target various IoT devices and harm them. DoS as saults are simple to use but difficult to stop. While there are several ways to lessen he effect of assaults, none provide a perfect answer. Further investigation into DoS detection techniques has shown that the Entropy-based Detection method employing Multi-Classifiers performs better than other techniques. A denial-of-service assault is initiated by a malicious actor that repeatedly accesses the attacked system by sending many requests through the network. Due to the extreme congestion, no packet can get through. It has been claimed that a machine learning-based technique is used to iden-
tify assaults on Transmission Control Protocol (TCP) for IoT devices. In recent years, entropy-based features have been used to detect DoS assaults. Most of the time, the current approaches depend on a few entropy-based features. A multiclassifier system is using multiple entropy-based features to maximize effectiveness. We used a voting system with three classifiers. Our approach is implemented on the most up-to-date IoT-based dataset, the CIC IoT Dataset 2022. In the complexity of IoT information, entropy-based characteristics are used to categorize attacks and normal traffic to spot outliers. The goal of this study is to develop a more effective method of detecting DDoS attacks utilizing a combination of the Support Vector Machine (SVM), Alternat ing Decision Tree (ADT), and Multilayer Perceptron (MLP) . In Our Implementation, it is shown that our multi classifier model is outperforming the single classifier we also tested our model five times with different Kfolds. Keywords: IoT, DDoS, Deep Learning."
"Umair Ahmad

EMT-DocNet: Framework for Extracting Marked Data Objects from Unstructured Visually Rich Documents"	The task of text detection and extraction is quite challenging itself for having a complex layout, different formats, table-like structure, lines and character overlapped. Traditional optical character recognition (OCR) algorithms, and computer vision models which are commonly used for document digitization, can struggle with different layouts and visually rich documents having various font, size, and tables like structures. In contrast, multi-modal architectures with abilities to capture spatial and textual features are able to learn and adapt to these variations, allowing for more accurate and reliable digitization. To extract the key with its values, researchers first use the OCR engines with some table detection model to extract the textual data from different layouts and then apply Name Entity Recognition (NER) to map and extract the required keys with its values. However, above mentioned, they lack appropriate document understanding abilities and contextual information, preventing them from capturing the correct keys with their values, such as dates, names, and addresses from unstructured documents. In this thesis, We proposed our end-to-end multi-modal architecture EMT DocNet which will detect the data objects by using a deep neural network feature extractor and layout language model on top of EMT-DocNet to identify and extract the key with its values by using spatial and textual features. we address the problem of marked text detection along with the extraction of key-value pair mapping. We utilized transfer learning to detect the handwritten marked text from the image containing the complex table like structure. We have collected a small dataset of patients’ medical history collection forms. Also preprocessing was done before applying any deep learning model. After successful detection, maintaining the context of detected text with its key attribute got lost, so this challenge of key-value information mapping and extraction was studied in previous literature many of them applied name entity recognition after extracting all the text from the image but keeping in view the only text might not have import features which can be captured from the image like the position and textural features, because text reading and extraction are mutually correlated. We keep this observation into consideration and used ayoutLM Language Model and customize our detector in this architecture called EMT-DocNet to map the key with their values and then extract it. we implemented the EMT-DocNet model and evaluated its  erformance on a benchmark dataset. The results showed that the EMT-DocNet model achieved detection mean average precision of 0.96 and Key value mapping accuracy of 0.94, outperforming several state-of-the-art models including LayoutLMv3, YOLO v5, Faster RCNN, and VGG. These findings demonstrate the effectiveness of the EMTDocNet model for the task at hand and suggest that it may be a promising approach for similar tasks in the future.
"Abdullah Bilal

Tagging Youtube Videos based on Users Interest using Social Data"	Social media platforms like Facebook, Instagram, YouTube, and WhatsApp have become popular modes of communication worldwide, allowing users to connect with others around the globe. These platforms also facilitate user interaction through features such as comments. In order to make it easier for users to search for and find relevant content, it is important to accurately tag YouTube videos. However, manually tagging videos can be tedious and prone to errors. In this study, we explored using machine learning to automate the process of generating tags for YouTube videos from user comments. We compiled a large dataset of YouTube videos and their associated comments, and used a combination of semi-supervised and unsupervised techniques to train a machine learning model. Our results demonstrate that our approach is ableto generate accurate and relevant tags for YouTube videos with a high level of precision and recall. These findings suggest that machine learning can be a valuable tool for automating the process of tagging YouTube videos, potentially saving time and improving the accuracy of video tagging.
" Hassan Raza 

Code Smells in MVC Variants &amp; Their Detection in Knockout.js Applications"	A Code Smell is a characteristic of code that indicates the possibility of sub-optimal coding choices which could negatively impact the maintainability of the code. This definition is quite general nd the research done in this area mainly focuses on design issues that could impact any system regardless of its architecture. Applications nowadays are made with the help of frameworks that allow specific design patterns. A developer must follow those design principals to maintain software maintainability and evolvability. Model-View-Controller (MVC) is a widely adopted design pattern in web applications. With the emergence of time, different variants with important architectural changes were introduced to address the limitations of MVC. Due to the architectural changes between MVC and its variants, code smells of MVC architecture could not be used for its other variants like Model-View-Template (MVT) and Model-View-ViewModel (MVVM). This research focuses on learning MVC code smells from the iterature and identification of the smells for Model-View-ViewModel architecture through mapping of MVC smell. Also, MVVM-Checker tool is introduced to detect these smells specific to the Model-View-ViewModel variant in Knockout.js applications.
"20I-2016 Usama Saleem 

Blockchain based social media 
WebApp"	Social entertainment is becoming one of the predominant ways of communicating [11] [9]. Prior to social media, individuals were incredibly restricted in their means to connect with others, and they were restricted generally to individuals that they knew face to face. Since the last era, the social networking platform has supported as an entrance for starting connections, sharing content and social associations for numerous users. Be that as it may, this effect on individuals has harmed security. Alternative measures have been proposed to conquer current social media issues [1]. In this context, blockchain is one of the most encouraging technologies that can solve this user privacy issues. In this research, we will propose a new social media platform. With this platform we aim to solve common problems of known decentralized platform like bot accounts and gas cost issues [16] [11]. This social media platform will reward its users based on their activities, engaging user to create community friendly content. In 2014, Reddit put forward that its platform would be enhanced if everybody who contributed to reddit.com by uploading stories, comments or polling were compensated with a fair part in Reddit, Inc.
"19I-2066 Mohsin Kaleem Anwar

Apple Quality Ranking Using Deep
Learning"	Agriculture has long been a significant social and economic aspect of human society. Typically, every house purchase fruits and vegetables because they are rich in fiber, minerals, vitamins, potassium, and other important nutrients. Fruit quality is critical for consumer acceptance, not just in the export market but also in the domestic market. Achieving fruit quality according to customer expectations not only encourages customers to buy more, but also allows farmers to improve profits and gain access to the export market. A key technique for refining the apple sales market and boosting sales is the classification of apples based on quality. The intended research work focuses on apple quality identification. In the past, traditional methods like manual inspection were done by a human expert quality assessment which is time-consuming. These are critical challenges for apple growers and apple exporters who want to sell high-quality apples. In our research work, we have proposed an advanced approach for ranking apple quality using innovative image processing and image classification techniques. We will develop a solution in this proposed study to automatically classify apples based on quality into four ranking classes: the first rank is the export quality apples that have shiny skin, second rank apples have no more than two marks or bruises, third rank apples have more than two marks/bruises on skin and skin appear aged and fourth rank is the rejected or non- consumable category showing sing of disease and almost half of the apple has discoloration. Firstly, image segmentation is used to avoid a decrease in recognition accuracy. Secondly, the segmented images are input into the generative adversarial networks (GAN) model, which is used for data expansion. These three CNNs (DenseNet201, GoogLeNet, Inception-ResNet-V2) will be used with hyperparameters to process the classification process strongly and fast. Inception-ResNet-V2 and inception- V3 give 85% and 81% accuracy respectively as compared to the above models. Inception- ResNet-V2 and GoogLeNet give 96.33% for binary and 92% for hierarchical classification.
"19I-1226 Haroon Haider      
 
Rice Leaf Disease Recognition Using
 Deep Learning"	Deep learning has played a key role in the recognition and categorization of disease in crops, vegetables, and fruits in recent years. As a result, the quality and production of crops, vegetables, and fruits have improved. Several diseases have a significant impact on crop quality and yield. In existing approach, they worked on a small dataset of Mendeley 2020. The AlexNet model is used as the principal network, and in terms of speed, model size, and accuracy, it is compared with other network models. Their results show that their approach minimizes model size and prediction while retaining an accuracy of 81.60. In my approach I have worked on new deep learning models with more speed, less model size and better accuracy for rice leaf disease recognition .In this research, an another pre-trained deep learning model has been used to increase the dataset's size, image augmentation and Generative adversarial networks (GAN). Moreover, Image segmentation has been used which helped in reducing the complexity of images. Transfer learning have been applied to retrain the previously taught model. Keywords: Segmentation, Augmentation, Support vector machine, Deep Learning, Classification, Generative adversarial networks
"20i-2271 Umer Kamran

Creating Adaptive Adversaries for Fighting Games using
Deep Reinforcement Learning"	"Deep Neural Networks (DNN) combined with Reinforcement learning (RL) have created favorable results in the field of Artificial Intelligence (AI), exceeding human level play in multiple environments, such as chess to even real time action games. There have yet to be truly adaptive agents in more complex environments due to the extensive possible states and actions. To further elaborate, many AIs are fine tuned to a specific strategy, they will react in ways that promote their chosen approach. Due to the complex and changing states of these environments, this thesis work proposes a way for the agent to change their strategy mid-simulation to reach the goal. The approach uses a ‘1 vs 1’ fighting game named “Street Fighter 2”, trained using Proximal Policy optimization, Deep Reinforcement Learning (DRL), having 2 different approaches created by applying reward shaping and self-play against scripted AIs. With the agents trained and ready, a
heuristic will decide which policy would be best applied for the current situation, allowing the agent to change how it approaches its goal. Our hypothesis is that this approach will generate better
results than a normal agent that uses a generalized strategy to reach their goal. Keyword: Deep Reinforcement learning, Proximal Policy Optimization, Adaptive AI, Self-Play, Scripted AI, Opponent Analysis, Reward Shaping, Fighting Games, Imperfect Information, Actor Critic Reinforcement Learning"
"21I-2082 Umair Alam

A Constrained Shortest Path in
E-Learning using Graph Neural Networks"	"It is essential for learners in an online learning environment to follow the optimal learning direction based on their existing knowledge and skills. Personalized learning approaches should be utilized to determine students’ particular needs and create multiple learning paths with relevant content, providing a better learning direction for each student to reduce individual’s knowledge gaps. A weighted directed graph is used to simulate e-learning systems, with each node representing a course. We worked on classification techniques to locate various shortest paths in a course as a node (CN) graph to enable the learners to follow the content at their own pace. In the case of a set of mandatory (core courses) or must-visit (MV) nodes, the traditional e-learning studies on the learning path have problems estimating the optimal shortest path (SP) considering different node, edge, and graph level preferences. The graph neural net-work approaches the SP problem as a classification problem, study [1] focused on determining the nodes and edges in the graph to be classified as the SP. To resolve the above-mentioned challenge we used an updated recurrent graph neural network-based technique to learn the SP containing MV nodes along with the edge and the node level attributes through a set of message-passing steps. We have conducted experiments
to validate the technique with different hyperparameters using similar datasets and achieved an accuracy score of greater than 98%."
"21I-2092 Muhammad Toqeer

Spatial Graph based Trajectories mining"	"Intelligent Transport Systems (ITS) are required in metropolitan areas to regulate the majority of traffic in order to locate better routes. It also reduces congestion and increases safety measures. In rajectory data, we have two primary features: the longitude and latitude of the object. By using trajectory data mining, one can analyze congestion and determine the fastest way for a vehicle to each a destination. The purpose of this research is to discover interesting travel areas during different time periods on trajectory data using different mining techniques. To achieve this, researchers have implemented grid density-based clustering on geospatial points. Density-based clustering is based on the mean base comparison between grid cells but mean-based approaches are not ffective for a power-law distribution. To overcome this draw- back, we proposed an algorithm that calculates pair-wise comparisons between cells to achieve refined and outlier-free clusters. But this approach has high time complexity. Also, the above two approaches work on grid cells that lack network architecture (theconnection between points). To accomplish this, we proposed our second algorithm, which converts the points into graphs before applying pair-wise clustering (based on neighborhood information). Afterward, we covered network information in the form
of edge-link, but the time complexity is still there. Our main approach is to reduce the time complexity of graph data using Locality Sensitive Hashing (LSH). On the basis
of this revolutionary approach, we perform fast and outlier-free clustering to discover attractive regions in trajectory data."
"20I-2011 Danyail Mateen

Representation learning network for classifying
& segmenting multilabel images"	"Any practical machine learning system requires a model that has been trained on a huge dataset. But getting annotated data isn't always easy, dense prediction tasks such as object detection, emantic segmentation, panoptic segmentation, key point detection, etc requires a lot of manual effort which can get both time consuming and expensive as the application scales. To alleviate this problem, a great deal of effort has been put into unsupervised or self-supervised learning approaches [1, 2, 3, 4, 5, 6, 7, 8]. The gist of such approaches is to pretrain the network on a large nlabeled dataset in a task-agnostic way and fine-tune it on a small labeled dataset in a task-specific way. To pretrain a network a number of pretext tasks have been proposed which range from adding color to grayscale images [10] to solving image jigsaw puzzles [9] to predicting the image’s rotation. The nature of these tasks is such that the labels are derived from the data itself. The visual epresentations learned from the pretext task can be then used for the downstream actual task with task-specific finetuning. This setting can help when there is little annotated data
available."
"19I-2073 Tayyaba Nisar

FACT CHECKING USING KNOWLEDGE GRAPH 
EMBEDDINGS"	The volume of linked open data on the web is growing exponentially. With the increasing size of linked open data, large scale knowledge graphs are emerging. There- fore, the need for validating the knowledge contained therein is increasing. Manual factchecking is an inconvenient solution considering the size and quantity of knowl- edge graphs used within real-world applications. Recently, many automatic factchecking approaches are proposed that assist in the validation of facts in a knowl- edge graph. One of those automatic fact-checking algorithms is a text-based approach dubbed as FactCheck. FactCheck is based on locating supporting evidence sentences from a reference corpus. After extracting such proofs using a search engine, it calculates a confidence score indicating the validity of the input fact. It validates the input fact using provenance data of sources, and NLP features that are extracted from the text. All text-based fact-checking approaches, including FactCheck, suffers from less performance due to manual NLP feature extraction. This NLP feature extraction is a difficult task that demands manual human effort (i.e., finding out which features are important for the fact-checking task). For this purpose, we propose an embedding based approach that takes benefits from pre-trained sentence embeddings in order to filter relevant pieces of evidence and calculate the final score. Keywords: knowledge graph,factchecking,text-based approaches,embeddings,features, evidence
"20I-2201 Zarah Amer

Leukemia Ontology for Risk Prediction
using Real-world EHR data"	Leukemia is the second largest death-inducing disease in the world. It is estimated that Within the next 20 years, there will be a 70% increase in leukemia induced deaths. Therefore we need to make improvements in our leukemia data infrastructure and adapt to the changes needed. Ontologies play a critical infrastructural role in organizing and making sense of EHR data elements and their relationships. Bringing all the data in one place, then managing and organizing in a way that is closer to human and computer cognitive thinking gives a holistic view of the patient phenotype, its disease and helps in making efficient decisions. The Ontologies provide a more effective way of expressing, organizing, managing, and utilizing massive data which is more intelligent. Knowledge Graphs have shown promising results when used for clinical applications. They represent biomedical concepts and relationships in a formal, structured, human-and-computer interpret-able representation which helps in making decisions and analyzing risks efficiently and in the light of the evidence. Ontologies can be constructed from Natural Language Processing (NLP) techniques. These techniques rely on the ”black box”, and lack domain knowledge, and explanatory powers to make decisions. This research aims to develop a manually curated leukemia ontology with multivariate data including patient family history, clinical reports, patient environmental data and personal information. The ontology maps similarities and differences in patients’ properties in order to see the risk factors involved. The knowledge graph is then fed to DeepWalk Graph Embedding to be used by machine learning algorithms to predict the possibility of leukemia and calculate patient risk factors. We used 6 machine learning algorithms; 1)KNN got 67.71% accuracy 2)Gaussian Naive Bayes got 48.91% accuracy 3)Random Forest got 70.60% accuracy 4)Logistic Regression got 65.54% accuracy 5)Ada Boost got 65.53% accuracy 6) Decision Tree got 60.0% accuracy. We got the highest accuracy and highest F1-score: 0.83 from the Random Forest. Then we extracted potential risk factors for leukemia and made a user interface where he enters his data and can get a prediction of whether or not he might get leukemia.
"20I-2207 Ahsan Farooqui

Object classification for non-euclidean
geometric surfaces"	3D object detection on point cloud data is a challenging task in the field computer vision. The translation and rotation invariant properties and non-Euclidean nature of point cloud data makes traditional algorithms ineffective on the point cloud data. One of the problems of real world dataset and applications of 3D point clouds like in self driving cars is the variability of data at test time, i.e. encountering the classes that may not be present in the training set. The traditional algorithms may misclassify the object resulting in wrong decisions. Very less research has been done on Open Set for 3D point clouds so far. In this thesis we studied the various point cloud classification algorithms and their behaviour with the state of the art open set loss function devel- oped for 2D images. We tested two algorithms against the state of the art open set loss function and evaluated results. Further we also studied the effect of density of point clouds on these algorithms in an open set condition and evaluated their results.
"20I-2214 Junaid Muzaffar

Point Cloud Up-Sampling using Diffusion Models"	To visualize 3D data the most commonly used technique is to use point clouds. And for the collection of these point clouds data is performed by the use of depth sensors, and a famously common depth sensor is of course LiDAR. These depth sensors are not only able to present the spatial locations of objects present in a given scene, but also able to convey the 3D geometric structures. However, we are depending on a hardware to collect data for us in 3D, which means there are computational and hardware constraints. Which ultimately results in noisy and sparse point clouds; therefore, we face evident limitations for objects that small in size or placed at a considerable distance. One naive solution to deal with sparse, noisy and incomplete point clouds is to use expensive sensors with like a 64-channel LiDAR sensor which in terms of price will not be feasible for those who don’t have the budget. Therefore, different Deep Learning techniques were used to up-sample, increase or complete the noisy point clouds generated by normal depth sensors. Therefore, the idea here is to exploit the diffusion models which will try to learn the up-sampling in reverse manner, which could be then used for several applications like autonomous vehicles, object detection and recognition and generation of synthetic data.
"20I-2221 Ahmed Affan

Detecting multi-class kidney abnormalities using
 Deep learning"	Deep learning is being powerful tool in medical imaging and lot of medical data with labels is required for deep learning algorithms to enhance their perform. Issues related to Kidney like stone, cyst and tumor are common. We have used deep learning models that will classify these images of kidney. Using classification models of deep learning like VGG-16. We are working on two dataset with same CT-scan images of human anatomy. One dataset is provided with labels for segmentation and other one is just to perform classification. So we used U-Net to perform segmentation for the images. The labelled data we have is from only one class that its segmentation is done for kidney tumor and the other three classes the model of U-Net will learn for that single class dataset and generate segmentation for kidney, tumor, stone and cyst The dice score for rest of the classes is calculated by using the sample of manually labelled images for other two classes of cyst and stone.
"20I-2261 Talha Nazar

Localizing and Analyzing the Infographics in 
Document Using Deep Learning"	In explaining complicated concepts, infographics are a far more effective medium of communication than regular prose. In recent years, deep learning has seen a lot of success in a range of applications requiring pattern identification and artificial intelligence. One of these applications is image recognition. There are many kinds of infograph ics that may be used in resumes and CVs to demonstrate the degree of competence. The objective was to identify those infographics that were already existing in the CV and to determine the word that corresponded to each infographic before attempting to measure each infographic using numeric character. The YOLO algorithm was used to identify infographics, while OCR was utilized in order to identify associated words. The filled component of the infographic was distinguished from the unfilled area by using the image processing techniques i.e image thresholding, contours etc.
"20I-2262 Shabir Ahmad

Word Embedding Evaluation for Urdu"	Word Embedding represents a word as a vector that captures its semantic and syntactic meaning. To the best of our knowledge, this research provides the first complete evaluation of different word embedding methods for the Urdu language. Three standard word embeddings models, particularly, Word2Vec (each Skip-gram and CBOW), Glove, and FastText, are evaluated in two forms of evaluation techniques: extrinsic and intrinsic. Word analogy and word relatedness evaluations are part of the intrinsic evaluation, whereas sentiment analysis and tagging of parts of speech (POS) is part of the extrinsic evaluation method. CBOW variant performed well in analogy tasks and Skip-gram in sentiment analysis, while FastText outperformed other models in general.
"20I-1803 Muhammad Shoaib

Securing Southbound Traffic in SDN
Against TLS Downgrade Attack"	The rapid growth of internet traffic and application demands a flexible and centralized control of network devices. Software-defined networking (SDN) enables the programmability in networking nodes where the network manager runs the different services and applications at a single point called a controller. The controller runs the network operating system and is able to manage the data plane of SDN (sometimes called the infrastructure plane). The separation of controller and data plane from a single network node also creates some challenges, particularly security-related challenges. These challenges make the SDN communication between the controller and switches vulnerable. The attacker uses the Man in the middle (MITD) attack to sniff all traffic and make sure all network traffic goes through the attacker so that it can perform the malicious activity. For this purpose, we are using the prevention model to tackle this kind of attack and mitigate the threat vector. Our proposed model is implemented with the TLS and provides a trusted environment. Keywords: Software-defined networks, southbound, security, TLS, Encryption
"20I-1954 Abdul Mohiz

Optimizing Mempool of Blockchain-based
Cryptocurrencies"	Since the last few years, cryptocurrency demand and market value have skyrocketed. Bitcoin, Litecoin, and Ethereum are examples of blockchain-based cryptocurrencies that have seen significant market value growth over the past ten years, however, the size of their full nodes is also been increasing, ultimately escalating the requirement of compute resources like processing power, memory and storage which is discouraging most of the miners to mine full node. On the bitcoin network/litecoin network, full nodes play huge role in providing security to bitcoin’s /litecoin’s blockchain by verifying each transaction in every node by downloading and validating all blocks starting from the genesis block. Blockchain-based cryptocurrencies are also targeted by DDoS attacks. One of them is on mempool, as it is being targeted by DDoS attacks, due to which valid transactions cannot be added to the blockchain node. In bitcoin, the default size of the mempool is 1 Mb, and the maximum size of the mempool is 300 Mb. If mempool is filled with dust transactions, the valid transactions will be dropped out, and that has cost millions of dollars of loss in the past few years. Dust transactions are transactions with small input values and are considered spam transactions. These transactions consume the same space as valid transactions, but their effect on exchange value is tiny and can be neglected. Attackers use small-value UTXOs from their wallets to form a dust transaction. To minimize the resource requirement to mine full node and reduce the memory consumption of mempool and make mempool resilient against flood attacks, it is necessary to optimize the mempool of blockchain-based cryptocurrencies to relieve the memory pressure on full nodes as well as make the mempool resilient against DDoS attacks and to store more transactions than existing mempool. Our proposed solution is to; replace the existing data structures of mempool with the space-efficient probabilistic algorithm: bloom filter, which stores, searches and processes more transactions than the already existing data structure. It optimizes mempool size as it is able to reduce the requirement of compute resources to mine full node and recover from DDoS attacks without dropping valid transactions from legitimate users, as well as perform efficiently even when flooded by low-value dust transactions. Our proposed solution has made DDoS attacks more expensive and difficult
"20I-2213 Javeria Kanwal

Precision Psychiatry and Personalized treatment
 outcome prediction using Machine Learning"	Precision psychiatry aims to improve the accuracy and effectiveness of drug re-sponse prediction in the treatment of mental health disorders. However, limited datasets and the suboptimal performance of baseline machine learning models have hindered progress in this field. In this study, we propose a hybrid machine learning approach to enhance drug response prediction in precision psychiatry. Our methodology in- corporates a bagging model with XGBoost as the baseline, leveraging the strengths of both algorithms to improve accuracy and robustness. We conducted experiments on a sample of 275 patients diagnosed with Major Depressive Disorder (MDD) using four different types of antidepressants. Results show that our hybrid model outperformed baseline models, achieving an 86% balanced accuracy, sensitivity of 0.80, and specificity of 0.92. Moreover, we identified important factors that influence drug response prediction, such as Depression Severity Score, Family Size, BMI, Age, Total Duration of medication, Years of Education, Reason of Depression, Dose, and Duration with Current antidepressant. These findings demonstrate the potential of hybrid machine learning models in precision psychiatry and contribute to a better understanding of the factors influencing drug response. Despite the small dataset size, our results provide valuable insights and pave the way for future research and advancements in personal- ized treatment planning for mental health disorders.
"20I-2219 Abdullah Khan

Open Set Recognition using Federated 
Learning."	Deep learning models have revolutionized the field of computer vision, some deep learning models performance even surpasses the human performance. But train a deep learning model a large amount of data is required. Due to increase in smart devices a lot of data is produced daily. But this data is in the distributed form and can be used directly to train a model due to privacy concerns of the users. Federated learning provides us a way to train deep learning models using this data. FedAvg is the federated learning scheme used to train the model in federated learning. Deep learning models are trained with the ‘closed set’ assumption. According to closed set assumption the number of classes that appeared in training data set is equal to the number of classes presented to in the test dataset. While in real world the all problem are ‘open set’ that is the number of classes in training dataset is finite and an infinite number of classes are presented to model during testing. Unseen classes that occur in testing phase can be misclassified as positive classes. To avoid this open set recognition schemes are used to train the deep learning models. In this research we train the deep learning model using open set recognition technique in federated learning scenario and evaluate it using model trained in non federated scenario.
"20I-2236 Haseeb Javaid

Real Time Algorithm for Detecting Road 
Surface Condition Using Machine
Learning Approach"	Bad roads are a public annoyance, and as a result, the people are subjected to passenger discomfort, vehicle damage, and the possibility of accidents. The circumstances associated with the poor road-related factors in the United States contribute to over 22,000 of the 42,000 traffic deaths that occur each year1 . Despite our constant complaints about poor road conditions, we have no efficient mechanism to identify or report them on a large scale. This paper explores the use of smartphone devices for the detection of road conditions and road anomalies, and rate the specific path from the user feedback. We present a novel approach by utilizing the machine learning algorithms to monitor the road infrastructure by collecting sensor data from the smartphones (accelerometer, gyroscope, GPS) present in the pocket of the user in the vehicles. This proposed system, which we call Detecting Road Surface Condition Using Smartphone Sensors, uses the public vehicles, collecting the vibration’s data of the vehicles using the accelerometer and the gyroscope sensor along with its location from the GPS sensor for different road conditions, and then we present the algorithm to process the data for cleaning. Two variations of data will be collected from different road conditions ranging from very good road conditions to very bad road conditions and for different vehicles, covering all the road-related events. We trained the SVM models for both, car and motorcycle, to distinguish between different road conditions with the F1-score of 91% and 78.2% respectively. The models utilize the sensor data to identify the road condition as the user drives. Furthermore, these results are used to produce data-rich maps that show the conditions of the city’s roadways. With our approach, city authorities would be empowered to detect and fix broken roadways that annoy commuters and cause accidents.
"21i-2060 Zair Abbas

Enforcing Data Geolocation Policies in
Public Cloud using Trusted Computing"	Cloud computing allows us to acquire on-demand computing resources like storage, server, and software which can be provisioned or released without any extensive effort. Its advantages are low-maintenance cost, accessibility, backup data, pay-per-use models, unlimited storage, and processing power. Despite the numerous advantages of cloud computing, the geolocation of data is a massive concern, which relates to the performance and government legislation that will be applied to data. User has no physical control over data when they upload it to the cloud. The location of the data can be decided on SLA but it is not sufficient. In this work, we have used trusted computing to attest the geolocation of the host remotely. With this model, the user will upload the data whose decryption key will be shared with a third-party attestation server only. The decryption key will be available to the host under authorized geolocation and platform state.
"Anam Irfan 

Dialogue Explanation Using Transfer Learning
on General Knowledge Extracted from Semantic
Networks"	Dialogues are a day to day activity that comes very naturally to humans. Each sentence of those dialogues contain information, contexts and relations behind it that can be used to extract information. The human mind can infer and process all this information in the background before prompting the human to respond back to the query or statement. If we want machine understanding to reach the level of human under standing, we must incorporate human mind thinking patterns in the processing of text. Every piece of text generated by the computer should be meaningful. So, we are proposing a system that will generate some text based on the contextual knowledge associated with it. For this research, we take the scenario of 2 agents having a conversation which leads to a generation of dialogues. Each sentence or responses in the dialogue can be represented as a story having subjects, actions and objects in a given scenario and a contextual relationship as well. Rather than the typical, more common methodologies of training the models with huge data for sentence generation, the aimof this research paper is to analyze the story behind a single dialogue text and identify the different contexts behind these dialogues based on which the sentences are generated for explanation of the dialogue. To the best of my knowledge, this is a unique approach proposed which has a blend of many state of the art technologies for explanation of dialogue. For this approach, we will be using semantic network graphs for grabbing knowledge and reasoning and then utilizing that knowledge in constrainedtext generation task, transfer learning and deep learning transformers to generate sentences from those concepts. Experiments show promising results and scores of the text generated with this approach. Keywords: Story Analysis, Dialogue Explaination, Machine Understanding, Contextual eaning of Text.
"Ali Raza 

Impact of Risk Factors in Mortality
Prediction of Intracerebral Hemorrhage"	Intracerebral hemorrhage (ICH) is one of the serious and most deadly stroke in the family of neurological disorders and approximately affect 2 million people world wide family of neurological disorders and approximately affect 2 million people world wide every year [12,13]. ICH stroke is now a high rated neurological emergency in intensive care units (ICU) . ICH stroke is approximately 6.5 to 19 % of all strokes and having highest morbidity, mortality and disability rates among all types of strokes [3]. Mor-tality rate of ICH patients approaches 40-50 % on an average ICU stays. Research find out that 35 % ICH patients die within 7 days and approximately 50 % patients die out that 35 % ICH patients die within 7 days and approximately 50 % patients die within 30 days survival of this deadly stroke[3]. ICH stroke is least treatable type of stroke and there is no proven therapy for the improvement after the outcome of ICH[9] stroke and there is no proven therapy for the improvement after the outcome of ICH[9] . Intracerebral hemorrhage is caused by a damage of Intracerebral small to chromatic hypertension or amyloid angiopathy which can lead to a blood clot andvessels owing stroke chances are increased[5].
"Fatima Rehan

Movement prediction using audio data
via Deep Learning Models"	Structural alignment in biomolecules is pivotal in determining what kind of functions they can perform. Biomolecules like proteins, RNA and DNA are three-dimensional structures, made up of smaller atomic components. Protein structure alignment refers to the way protein sequences are arranged. This helps in knowing which proteins are more likely to have relationships with each other. The sequencing is highly intricate and a large number of combinations exist which can make up different proteins. Therefore, finding the ideal alignments is crucial to understanding the functions that can be performed, how each complex has evolved over time,and which complexes are evolutionally related to each other. We are proposing a method that helps in achieving such alignments in an efficient manner so that computational costs are low,accuracy is high, and minimum preprocessing is required when finding the alignments. We propose to achieve this by computing the proteins as graphs, and then applying graph theoryconcepts on them to achieve our purpose, while incorporating a very simple yet efficient similarity measure, the Jaccard similarity index, to help achieve our goal.
"Kainat Iqbal 

Movement prediction using audio data
via Deep Learning Models"	Honeybees plays an vital role in the life preservation and health of an environment. Bees not only provide pollination services but beekeepers also use them for the produc tion of honey, beeswax and royal jelly. Swarming is a technique of colony reproduction used by honey bees. Swarming of bee colonies significantly effect the profitability of the beekeepers. It results in the loss of bees when bees try to split into groups. Acoustic monitoring of beehives helps identify different states of bee colonies. Currently, research on sound analysis is being carried out employing deep learning techniques combined with several data processing approaches that extract features from acoustic signals. Although, there is limited knowledge on how audio scenes are recognized by deep learning models, as studies on image recognition shows. Hence, in this study we use waveplot features, mel spectrogram, mel Frequency Cepstral oefficients (MFCC) to compare the performance of machine learning algorithms with deep learning algorithms. We use Naive Bayes, K-nearest Neighbors (KNN) and Support Vector Machines (SVM) as machine learning model and for deep learning models, we use Convolution Neural Network (CNN), Long Short Term Memory (LSTM) and Transformer. We use classification accuracy metric for the comparative evaluation of our models. For machine learning algorithms, SVM performed best with mel spectrogram as input data and achieved the accuracy of aroung 97%. But CNN outperformed all the models and achieved the accuracy of 99%, using MFCC features as input data. We propose that by the classification of sounds inside beehives, our results can be utilized to design a monitoring system that can accurately identify abnormal situations in beehives early.
"Haris Abbasi 

Detection and Prevention of In-Browser
Cryptojacking Attacks"	Since the emerging of cryptocurrency many people are trying to mine them in order to get some coins as a reward. Cryptomining requires high computational resources and thus miners are continuously working to find innovative ways to overcome this issue. This has led to the introduction of a new malware threat known as cryptojacking in which an attacker uses the computing resources of another person for mining without the explicit permission of that person. This kind of malware gained more attention after 2017 when coins like Monero appeared. Both static and dynamic features of webbased cryptojacking malware, known as in-browser cryptojacking, have been used in machine learning algorithms like SVM, Random Forest, etc., to detect this malware. But only some techniques have been deployed to prevent it like either suspending or killing the malicious identified process. These prevention techniques come with the limitation that they are only efficient against web-assembly (WASM) based cryptojacking malware and lack the capability to handle mining service providing scripts that use non-WASM modules. This technique extends the state-of-the-art prevention work to detect and mitigate all types of in-browser cryptojacking malwares. It utilizes the blacklisting technique and performs statistical code analysis to identify unique features in the form of malicious API calls of non-WASM cryptojacking malwares to detect and prevent these malwares from executing in real-time. This approach has improved the detection results by an accuracy from 97.6% to 99.6%, a recall value from 40% to 90% and a F1-score value from 51.7% to 94.7%.
"Osama Khalid 

Machine Learning Based Technique for
Fileless Malware Detection"	Malware is a type of computer program that infects the target system by infecting the other programs installed on the system. Malware is designed by cybercriminals to steal, damage, or alter the data, and take control of the computer system. Malware and viruses have existed since the dawn of the computer age. The cyber security industry has also come up with new and better programs to detect and prevent malware. In 2002, there is a huge development in the malware industry that changed the entire  landscape for malware development. Therefore, cybercriminals became more sophisticated by advancing their techniques for malware development from file-based malware to fileless malware. As file-based malware depends on files to spread itself but on the other hand, fileless malware does not completely depend on the file to carry out its malicious activity. Fileless malware do not require a traditional file system and uses benign processes to carry out its malicious intent therefore it evades the traditional detection techniques used by antivirus programs and remains stealthy. This thesis provides a brief understanding of fileless malware, its life cycle, and its infection chain. Moreover this thesis proposes a detection technique based on the features analysis using machine learning for fileless malware detection. The memory dumps had been acquired from the virtual machine upon executing the malicious and non-malicious (benign) samples. After that necessary features are extracted by using the Volatil- ity memory forensics tool. Then the extracted features are analyzed using machine learning algorithms including Random Forest, Decision Tree, Support Vector Machine (SNM), Logistic Regression, K-Nearest Neighbour (KNN), Naive Bayes, XGBoost andGradient Boosting and from them, the best algorithm is selected based on the k-fold cross-validation score. From analysis, random forest is selected as the best algorithm as it achieved an accuracy of 93.33% with an f1 score of 93.33%.
"Earass Ahmad 

Finding Interesting Insights from Digital Media using Graph Mining"	Digital media provides huge amount of data. Most of this data is in raw form and has a potential to be explored. This data has a rich content and gives us an opportunity to find interesting insights from it. To find such interesting insights, many approaches have been proposed so far. A shortcoming of such approaches is that the structure of the documents is neglected as the primary attribute remains the frequency. This, as a result, loses some of the valuable characteristics of the documents. In this work, we build a framework called Social Pulse that uses keywords to extract live tweets from Twitter and extracts multifold meaningful information from it. It is a complete framework that consists of a data pipeline that fetches and processes tweets, incorporates graph mining, has micro-services to serve data from backend to front-end, and provides a dashb oard to visualize the analysis in the form of charts and graphs. At the core of the Social Pulse, we use gSpan which is a famous and one of the most efficient Frequent Subgraph Mining (FSM) algorithms. We create a parallel implementation of gSpan in which we leverage the multicore processing technique to run gSpan in parallel to improve the execution time. The parallel implementation is imperative because the social media data grows large in size so the sequential run would take a lot of time to process it. Our approach uses the co-occurrence graphs to represent textual data in graphical form. The tweets’ texts from Twitter are preprocessed and converted into co-occurrence graphs. The gSpan then extracts the frequent subgraphs from the graph database to infer the most common phrases occurring in the texts. Along with the tweets text, there are multiple other attributes associated with the tweet. We use those attributes to infer multiple meaningful insights from the data.
"Irfan Ullah 

Template-based Automatic code generation for 
Web application and APIs"	Code generators are used to automatically generate code from any UML artifact. The generators may generate template-based CRUD, UIs, APIs or may simply convert the UML artifacts into code. The template-based generators use file-based formatted templates for generating target code, which are designed to generate code for embedded systems, web and mobile applications, PIs. They target certain areas, such as: UI generation, CRUD generation, APIs generation and language or framework specific code generation. The reviewed generators are language specific, take manually designed lengthy inputs and are not scalable. The manual designed inputs and language specific nature of the generators compromises the very idea of automatic code generation;therefore, this research proposes a template-based automatic code generation approach for web application and APIs using class diagram. The approach will utilize template-based code eneration technique. Some templates will already be available in the proposed generator while, unlike the current generators, it will support template modifications, imports. The proposed generator will take class diagram as input and will generate CRUD-based business logic, backend UIs, ORM, Routes and APIs.
"Amna Khan 

Towards a Secure Architecture for Interoperable CPS"	Cyber Physical systems (CPS) are emerging day by day due to their applicability and interoperability. From smart homes to pacemakers the internet-of-things (IOT) based systems are gaining users. With increased connectivity and omni-presence, CPS bring challenges like security (cyber-security). A cyber physical system (CPS) is a smart system that uses the Internet to incorporate sensing, computing, control, and communication into physical processes and objects. A set of computing resources and physical assets, such as actuators and sensors, are included in each CPS. These systems are used for managing and controlling homogeneous or heterogeneous software systems. it plays a key part in current growing sectors including smart grid, Industrial control systems, robotic systems, automatic pilot avionics, the factories of the future, and the Industrial Internet of Things (IIOT). In recent years, CPS security-related issues gained increasing attention, not only in academic study but also in an advanced sector of industry. Power grids and water management sectors specifically are the most vulnerable sectors to cyber threats. So, security is one of the major concerns as it deals with the protection of CPS from institutional attack. For instance, in most of the situations providing security on a single layer especially in the case of interoperable cyber physical system is not sufficient. In this regard, challenges associated with the architecture of cps have been explored i.e., the physical aspects and complexity of computing, integration of diverse devices [1], Adaptability, a variety of protocols and hardware specifications [2], control timing [3], assurance of security, lack of general architecture and unified framework. Therefore, there is a need of an architecture that provides security on multiple layers of interoperable CPS. In order to, cover this gap, this study aims to: (i) provide a generic architecture for CPS (specially SCADA systems). (ii) Apply generic architecture to improve architecture of already existing systems i-e dam system, ICS-Tetra packaging (iii) Validate proposed architecture by generating attack. The results show that if we use SDN in Cyber physical systems it will not only helps to secure our system but the system will be easily scalable. Using Honeypots along with SDN will secure the physical part of the CPS as well. 
"Tehmina Safdar 

Using Design Thinking for Software or
Mobile Application Development"	In today’s era, most of the basic routine work or manual work is done by computer programs due to the emergence of new technology. In order to solve complex problems, professionals must have strong intellectual capabilities. In the Industrial Revolution, where knowledge is accepted and regarded as a base or skill, therefore, it is important for students to develop a strong set of abilities to survive in the 21st century. Therefore the twentieth century educational approach is no longer acceptable because it follows the traditionaleducation approach. Previous research considerably argues that design thinking creates value for organizations. The major purpose of this research is to examine the impact of design thinking on students’ motivation and learning outcomes through the Human Computer Interaction course. To explore this area of research, a theoretical framework is developed to explain the relationship among variables. It comprises one independent variable which is design thinking (DT) methodology and two dependent variables which are motivation and learning outcome of students. So, the statistical techniques will be applied to the data gathered from the questionnaires and project work. The internal consistency was measured using Cronbach alpha with an achieved value of 0.9 for the questionnaire.
"Sania Imran 

Impact of Co-occurrences of Code Smells
and Design Patterns on Internal Quality
Attributes"	Software systems are frequently designed in such a manner that good practices of the object-oriented paradigm are not fulfilled, causing the occurrence of code smells. Code smells are basically the structural characteristics in a region of code that may suggest the presence of a deeper problem in the system design or code. On the other hand, design patterns are intended to catalog the best practices for developing object-oriented software systems. Although apparently widely divergent, there may be a co-occurrence of design patterns and bad smells, since this phenomenon is rarely discussed in the literature in the software engineering field. Therefore, this research performs an empirical analysis in order to explore the impact of co-occurrence of design patterns and code smells on internal quality attributes in the gaming domain that is increasing day by day. For this purpose, we performed an experiment with JavaScript open-source medium-size web games to (1) identify the design patterns and code smells in web games, (2) investigate the co-occurrence of design patterns and code smells in web games, and (3) explore the impact of co-occurrence on internal quality attributes i.e cohesion, coupling, complexity, inheritance, and size. For this purpose, software quality metrics are extracted, along with detecting code smell and design patterns from the selected web games. Moreover, co-occurrence between code smells and design patterns are also identified. Once the dataset is created, formulation of data is done in which data is divided into training and testing phases. After dividing the data into phases, seven different families of eleven machine learning classifiers are utilized These different families of ML classifiers are discriminant analysis, Naive Bayes, neural network, support vector machine, decision tree, random forest, and KNN. These classifiers are applied to training data in both balancing and without balancing phases. By applying these above-mentioned ML classifiers, different performance measures like precision, accuracy, F-measure, and Kappa value were obtained. From the results, it is evident that random forest is the best classifier with an accuracy of 99.126% and 98.99% in both experimental conditions respectively. In the end, to check the statistical significance of the impact of co-occurrence on internal quality attributes, we applied Wilcoxon rank-sum test to the results obtained. Results indicate that the co-occurrence of DPs and CSs has a significant impact on internal quality attributes when data is balanced. This could help programmers to improve the structural quality of code or game developers to analyze games from a quality perspective because of the growing popularity and increased market demand for games.
"Riva Malik  

Multi-Document Summarization using 
Frequent Subgraph Mining"	Document summarization involves extraction of salient information from text to rep- resent it in a compressed yet comprehensible form Multi-document summariza-tion(MDS) deals with extraction of significant information prevailing among multiple documents. Existing approaches towards MDS utilize deep learning models. These ap-proaches are data hungry and employ the complete search space of input documents for generating summaries. On the other hand, frequent subgraph mining(FSM) can be utilized to reduce the search space where only the frequent subgraphs represent the collection of documents. span is the state of the art FSM algorithm that works on the principle of edge growth for generating frequent subgraphs. The problem with us-ing gSpan for generating subgraphs for summarization is that the resultant subgraphs contain repetitive words which causes redundancy in summary. To cater to this prob- lem we propose an extension of gSpan that mines mine maximal frequent subgraphs. Maximal frequent subgraphs are able to reduce the search space even further. Apart from that they contain diverse words hence resulting in better document coverage for summarization.
"Madiha Umar 

Conflict Identification of Design time
policies with CloudTrail"	"On demand delivery of computing services is provided by many cloud computing or- ganizations. Amazon Web Services being one among them with many cloud services
 provides resources on pay-as-you-go payment method and charges the cloud users for using cloud resources based on the compute services utilized. The permission
system of Amazon Web Services, i.e., Identity and Access Management handles the Authentication and Authorization of users to access the resources. In Amazon Web Services, no user can exist without policies, that is why to every user identity based or resource based policies are attached. To run containerized applications and orchestrate containers, Amazon also provides Elastic Kubernetes Services. The authorization of a user in Elastic Kubernetes Services is done through Kubernetes, where the Kubernetes uses an in-built authorization mechanism that works with Role Based Access Control mechanism. The Amazon’s Elastic Kubernetes Services integrates Identity and Access Management with Kubernetes Role Based Access Control in order to access the Elastic Kubernetes Services, creating a hierarchy of authorization policies that leads towards the policy shadowing. Such security mechanism leads towards policy conflicts between Identity and Access Management and Kubernetes Role Based Access Control mechanism. Work done so far is mainly about the authorization policies of cloud but in Kubernetes is a least explored area in terms of security. This thesis provides a model to identify the policy conflicts between authorization policies of the security mechanisms followed in AWS. The modeled policies are evaluated against RelSAT solver. The policies are provided to the proposed system and rules are applied to evaluate policies. Conflicts are successfully identified by our system. The generated results carry the information regarding the possible conflicts and witness the practicality and scalability of our system."
"Huma Altaf

Conflict Identification of Design time policies with CloudTrail"	"In Amazon Web Services (AWS) the term authorization refers what the user is allowed to do. In AWS access is managed by creating policies and then attaching them to iden-
tity and access management (IAM) service identities such as user, groups or roles. An IAM user is an identity that refers to specified permissions for a person or application.
These permissions in policies helps to determine whether the request is allowed or denied. Policies attached to an identity can cause conflicts when actual request has
been made by the user.AWS Cloudtrail service is used to get information about the requests made by IAM. This research addresses the conflicts of IAM policies with AWS
Cloudtrail that records the user activity and deliver log files. The research identifies the conflict between the policies using Cloudtrail runtime log information. Log file
information makes process simpler and easier by just looking the log file rather than evaluating policies through levels."
"Walia Firdous 

Automated Traditional and Deep Machine 
Learning for Multi-Label Classification"	"Automatic Machine Learning methods and tools [1] are quite popular for traditional machine learning classification problems. However, not too much focus has been given to
deep learning methods for tabular data in specific and multi-label classification problems in general, mainly because of their prohibitive computational requirements and their historically inferior performance to traditional methods on tabular datasets. In this work, we explore automatically learning of traditional and deep learning algorithms, given their recent good performance on tabular datasets [2], for multi-label tabular classification. Our proposed extensions are not only fast to find the best settings for deep learning algorithms but also give superior performance. For instance, our experiments on the multi-label classification datasets shows promising results. Moreover, we do not restrict ourselves to a single algorithm but also explore the option of ensemble by finding the best set of classifiers from the pool of deep learning and traditional algorithms to find the best of both the worlds."
"Zahra Nasir

Trend Prediction of Fully-Vaccinated
people against Covid-19 by using 
Traditional Machine Learning and Deep
Learning Models"	The fatal disease covid-19 has overwhelmed the whole world. Millions of people have lost their lives because of covid-19 pandemic. This disease is not a longer pandemic but due to this pandemic fear is rife all over the world because many people had lost their loved ones. After the development of vaccine against this disease, corona cases are now decreased to minimal level. Two doses of vaccines are important to be fully vaccinated and fight against covid-19. Keeping in view the importance of vaccine, the purpose of this research is to analyse the covid new cases after vaccination and trend prediction of fully vaccinated people against the covid-19 by using traditional machine learning and deep learning models. In this regard, the dataset being used is in time-series format. This dataset contains multiple features. Sentiment analysis is also done on a tweets dataset to find out the positive and negative sentiment scores of tweets. Afterward, it merge into other features of the vaccine dataset for implementation of LSTM model to achieve promising results. Different algorithms are applied in this research including Support Vector Regression (SVR), Random Forest (RF), and Long Short Term Memory (LSTM). It is observed that by addition of sentiment scores LSTM gives the more accurate resuls than without tweets score.
"Muhammad Mubeen

Optimizing the problems by using the
Few Shot Learning Technique"	Machine learning has brought revolution in terms of providing the solution of the problems. But there are also some issues which researchers are facing while using the machine learning techniques. Machine learning or deep learning needs large amount of dataset to train their models which are always computationally costly and consumes a lot of time. That’s why training the model on a very small dataset and then extract the same accuracy can be very beneficial in this field. Few shot learning is working on the same concept where it does not need a large amount of dataset. We can train the model on a small dataset and still we can get same or close accuracy. In this paper, we are going to propose a technique which will help in training the models on the small datasets. There are different datasets available online like MNIST, Fashion MNIST or cfar10 on which researchers have produced really good accuracy by applying the machine learning techniques. I will be using the same datasets and then I will be applying the different deep learning techniques in a way that the model will get trained on a very small dataset. For this purpose, I will only take 0.4 percent of data from training examples. After training, model will be tested on the same testing examples which were used to test the models having training on large datasets. This will help in making the accurate comparison between the two techniques.
"Saad-Ur-Rehman 

Evolving Deep Convolutional Variational
Autoencoders using Evolutionary Algorithm"	Deep Neural Networks (DNNs) have been extremely successful in a wide variety of applications. The architectures of DNNs are critical to their performance and are often created manually with much skill. However, such a design method is labour demand ing owing to the trial-and-error process and also difficult to implement due to the scarcity of practice-based knowledge. Neural Architecture Search (NAS) is a form of technology that is capable of autonomously designing architectures. Among the several ways for implementing NAS, Evolutionary Computation (EC) techniques have lately garnered considerable interest and success. In recent years, VAEs have estab- lished their supremacy in unsupervised learning for image processing. ENAS frame-work will be developed for this purpose, which will automatically design the ideal architecture of VAE for image classification tasks under resource restrictions, hence reducing processing power to a certain amount. The resource limits in this scenario are the amount of arguments and the ability to skip connections. MNIST, CIFAR-10, and SVHN will be utilised as training and validation datasets. The purpose of this research is to develop a more efficient architecture for VAE for image classification tasks while also lowering the computational cost. Keywords: Evolutionary Neural Architecture Search (ENAS), Convolutional Variational Autoencoder, Resource Constraints, Genetic Algorithm.
"Shaheema Shakir

Identifying Psychological Impact on
Health Care Workers Due to Covid-19: 
A Machine Learning Approach"	Tireless efforts by health care workers to end COVID-19 have put them under a lot of psychological stress and created hindrance in their work. In recent times, very few researches have been made to study these psychological issues using clustering tech- niques of K-means and classification techniques of decision trees and neural networks without model output interpretation. The present study aimed to identify impact levels of psychological stress of medical workers based on machine learning model of Artificial Neural Network and interpret factors leading to the model output using SHAP model. Data used for this research work was collected through questionnaire survey response of 5108 Chinese medical workers based on Symptom Checklist 90 scale. Cut-off point of GSI T-scores of 63 was used to divide data into high and low risk groups. The preliminary results show prediction accuracy of 98% and F1-score of 91%. Interpretation of the model shows high age group medical workers having less psychological stress and low age group medical workers having more psychological stress. furthermore depression related psychological symptoms were found in those individuals having high psychological issues. This study can help medical workers keep check on their psychological health in future medical crises.
"Shahzeb Khan 

An exploration of machine learning techniques for optimization of selecting pre-eminent crossover and re-population points"	When we speak about evolutionary algorithms, we’re talking about a programme that has no notion where it’s going or how to get there. It improves itself by creating and implementing various solutions. Each population’s best solution is produced, and then crossover between those best solutions is performed to achieve the most optimum solution. For all generations, the crossover requirements are the same, which, in the worst-case situation, might cost us a lot in terms of resources, solution optimization, time, and so on. The major goal of this study is to figure out how to include machine learning methods into the crossover component of the algorithms in order to anticipate the optimal crossover point when it’s needed. It has the potential to open up a new way of dealing with genetic algorithms by transforming a basic genetic algorithm into an adaptive genetic algorithm with machine learning that adjusts its prominent points selection criteria depending on the issue at every critical moment. The concept will be tried on Np-Hard situations such as the problem of the travel salesman(TSP).
"Karar Bukhari 

Lungs Disease Detection Using Deep
Learning"	Lung diseases refer to many disorders affecting lung infections, such as pneumonia, tuberculosis, lung cancer, and many other breathing problems. Due to COPD (chronic obstructive pulmonary diseases), 3 million people die from this disease each year, the third main leading cause of human death worldwide. It is important to detect the disease at an earlier stage for treatment. These diseases can be identify through chest X-rays of the lungs images. Deep learning is the major AI trend in medicine. It is used to diagnose cancer and other chronic diseases. It helps doctors to make more accurate diagnoses about their patient’s health, and suggest better treatments. The problem of lung disease detection is quite challenging and demanding in medical, computer vision, and artificial Intelligence. Suppose we see the chest X-ray images of these three lung diseases through the naked eye visually difficult to detect the disease because they have high similarities. Existing approaches either focus on pneumonia, lung cancer, and TB individually. Their work either focuses on less inter-class or high intra-class variation. The proposed work focuses on improving the recognition accuracy of lung diseases by addressing both less inter and high intraclass variation. In the present work performance of four deep convolutional neural networks (CNN)architectures are considered, namely Resnet-50, Denesenet201, MobileNetV2, and GoogleNet. A comprehensive evaluation of different deep learning architecture is provided using a public chest X-ray dataset with four classes containing a large collection of X-ray images of normal, lung cancer, pneumonia, and tuberculosis. The dataset contains imbalanced data. To overcome this problem, we have performed some image pre-processing techniques like image, transforms, image enhancement, and data augmentation to balance the data. In our final approach, we generated the baseline results by implementing a simple deep learning approach without image pre-processing; then, we used image pre-processing and GAN (generated adversarial etworks) to improve results and get higher accuracy. After fine-adjusting hyperparameters to the ideal level, our final approach to Dense Net 201 and ResNet-50 significantly improved utcomes. We achieved96% and 94% accuracy.
"Ayesha Ehsan 

Detection of Deviated Patterns in the Activity 
of Smart Homes Resident"	Elderly users or patients with critical health conditions like patients of Alzheimer’s or dementia lose their sense of remembering and lose the ability to execute normal daily activities, such as eating, sleeping, or taking medication. For the assistance of these individuals, smart homes are used. Smart homes have sensors and actuators installed in them that recognize and monitor the daily activities of the resident‘s life. The proposed approach recognizes the routine activities performed in a smart home and separates the anomalous instances from the normal activities. Any deviation that does not confide in the normal pattern of activity is considered an anomaly. Activity is the instance of the occurrence of events in a specific manner and sequence. The sequence creates a pattern that is recognized and remembered by the model. The selecting feature, based on which the anomalies should be detected is indeterminate. Thus the proposed approach considers both when detecting anomalies; irregular instances and unusual duration. A classification algorithm is applied to recognize activities and separate them into different activity classes. Machine learning, supervised as well as unsupervised, is applied for anomaly detection. Cross-validation is applied to evaluate the validity of the proposed approach. 3-sigma is considered a base result because no ground truth has been provided. Two publicly available smart home datasets are considered to perform the extensive evaluation. The datasets contain missing values and noisy data. So to neutralize this problem, pre-processing is used. To evaluate the results we have applied cross-validation and compared our proposed approach with the existing approach. The proposed approach achieved higher accuracy when compared with the state-of-the-art approaches.Keywords: Smart Homes, Anomaly Detection, Machine Learning, Supervised Learning, Unsupervised Learning.
"Zain Aamir

Evaluation of estimation techniques for
projecting COVID-19 intensity"	Nowadays, it is becoming a challenge for us to organize the text data before processing and performing analysis, due to the rapid increase of amount of text on internet. The data is represented in structured and unstructured forms. In recent times, a lot of researches have been made to analyze the data using modern big data techniques and methodologies. Before erforming any analysis on the text data, we have to organize the data in some structure. Therefore, in this research, we have focused on managing clustering and aggregating the text content on web which include social media, blogs etc. while streaming from different resources. The problem arises when performing aggregation using extractive approach, word with word matching to summarize entences. Therefore, we have proposed DCS: Document Clustering and Summarizing, a web based a tool, which clusters and processes the streaming text data using Apache Spark. Apache Spark is an effective tool for processing stream data. We are considering the social data of different topics which includes the news and discussion of pandemic situation of COVID-19 between different users within tweets, social posts,websites etc. We develop algorithms to create words-based-graph using the text data and apply compression on graph to summarize our text data. Further, we create effective sentence from he summarize clusters. Our tool, DCS, shows the comparison of summarized words with the original words in the documents and also provides the analysis of words, clusters and the generated sentences. Our proposed approach resolves the problem of aggregating text data while processing the data in streams.
"Nauman Asif 

Constructiveness-Based Product Review
Scoring Using Machine Learning"	To make the internet a more productive environment, it is vital to promote constructive ness in online discussion forums. Customers are regularly offered the chance to share their thoughts and experiences with a product on online marketplaces. Mostly, products have less constructive reviews, and some of those reviews are not even related to the product itself. Most of the existing approaches use the term frequency-inverse document frequency (TF-IDF) technique to solve the constructiveness problem. However, its downside is that it does not work for contextualizing product reviews. In this study, we use graph-based features like average in-degree, out-degree, and clustering coefficient of nodes present in the reviews to model constructiveness in product evaluation to encourage the most informative and reasonable customer reviews. The directed knowledge graph is used for the representation of product reviews and news comments.Also, the graph embedding technique is used to transform the textual representation of data into a low-dimensional numeric vector in order to achieve better results. The topic modeling approach has been used to contextualize the reviews with the appropriate product. Additionally, we employed logistic regression, random forest, Gaussian naive Bayes, support vector machine (SVM), and Gradient Boost ing Machine models trained on Amazon product reviews and constructive news corpus for constructiveness. These ML models outperform the baseline approach, achieving a 91% F1-Score. Keywords: Constructiveness, directed knowledge graph, graph embedding, topic modelling, machine learning models.
"Salman Asad 

Detection of Citrus Fruit and Leaf disease using 
Deep Learning"	As of late, the discipline of deep learning has played a significant part in automatic detection and classification of diseases in fruits and vegetables.[1] The above has eventually helped in the better production and uplift in quality of fruits and vegetables.[2] When it comes to nutritional values and taste, citrus fruits hold prestigious place. They are cultivated all across the globe and known for the major reservoir of Vitamin C. Out there are many diseases that alter the yield and quality of citrus fruits.[1] Under this thesis, we have proposed an advanced approach for detection purpose by using some advanced image processing steps,Image segmentation,Image augmentation,image classification techniques and a new deep learning based technique with more speed, less model size and better accuracy is proposed for citrus disease classification. The citrus dataset is gathered from different resources through internet. A strong preprocessing process followed by applying image processing and UNet-segmentation. GAN was used to balance the images in the dataset to eradicate the imbalance in the data set by leveling of minority image classes to majority image classes. Transfer learning is used by applying pre-trained convolutional neural networks for prediction and for the classification M-SVM is used. Keywords: gmentation,Augmentation,Detection, Deep Learning, Classification.
"Iqra Ali 

Identifying and Forecasting the User
Interests over Time using Social Data"	With the immense growth in population, social data is also growing which is a rich source of confidential information. Social data is playing a primary role in users purchased in personalized marketing. Reasonable literature has been published on personalized marketing using social media. However, most of these approaches identify users’ interests based on their ratings. In our understanding, the contents of reviews are equally important in identifying people interests. Therefore, in this paper we proposed a framework that identified the user’s interest based on the reviews. Based on the analysis of reviews the model profiles the user’s interests and predicts the trends of interests for the future. We used website data in Roman Urdu because Twitter contains noisy data, and reviews aren’t always helpful in determining a user’s interests. People check the reviews before purchasing things since users offer relatable reviews on the website. To the best of our knowledge in the past, very limited research has been carried out in this context using Roman Urdu. As a methodology, for the Topic Model ing, we used Latent Dirichlet Allocation (LDA), Bidirectional Encoder Representations from Transformers (BERT) and Hybrid Approach (LDA plus BERT) models. Due to textual nature of the reviews we applied word2vec model to create word embedding for each word in the reviews and then we applied kmeans clustering to track the user’s interest. Based on the topics we performed user’s interests profiling using unburst Visualization. Finally, we used Long-Short-Term-Memory (LSTM) and Auto-regressive integrated moving average (ARIMA) models to forecast the trends of user’s future in terests. For topic modeling, Hybrid approach out performed to 52% of its coherence score while others got 45% and 47%. In our experiments, we used the topics obtained by topic modelling as input of orecasting models. In forecasting, we obtained RMSE score for ARIMA is equal to 1.43, 2.29, 0.42 and 12.5 for LDA, BERT, Hybrid and LSTM respectively. Finally, we did human-based validation on unseen Roman reviews by comparing the interested topics of users with the model. Keywords: Detected, Analysis, Recommendation, Framework. 
"Adeel Arif 

Cover Photo Generation From Text Story 
Using Layout Guided GAN"	"Generating cover photo from story text is a difficult topic to solve. The semantic complexity of the text story prevents it from being solved using a single image generating
approach. In this research, an approach is developed that splits the problem into following three steps: understanding the semantics of text story, predicting object layout
and then generating cover photo. A semantic link is encoded between story objects using a scene graph and inclusion of object layout model is used for capturing and com-
bining the features of scene graph using Graph Convolution Neural Network. Initially phase-I image is generated using scene graph image generation model and then the
results of phase-I are further enhanced in phase-II where U-Net encoder is employed by passing the generated object layout. We use the custom dataset of text stories using
3 animal categories along with the dataset of COCO to compare our approach perfor mance against the state of the art approaches. Our method generates high resolution
informative cover photo with objects information while preserving image structure with story text."
"Tusbiha Saher 

Customer Retention Using Social Media
Analysis"	Customer retention is recognised as one of the most important problems in any organisation, as customers are the primary source of revenue for the firm. Losing clients not only results in a loss of earnings, but it also puts the entire business organization’s reputation at risk. Organisations must enhance both client acquisition and retention in order to expand their business. As a result, the retention of clients turnover has emerged as one of the most serious concerns, with many organisations investing time and resources to solve it. Social media like Twitter represent the aggregate intellect and opinions of users that can be used as useful feedback for businesses. Our research utilises this information to build a model that analyses the user comments and performs churn analysis. For this purpose, tweets of Pakistan’s top 3 telecommunication companies, PTCL, Nayatel, and Stormfiber, were extracted and sentiment analysis was performed on the dataset using Python’s popular libraries, ”Vader” and ”TextBlob”. After that, we use Support Vector Machine (SVM), Logistic Regression (LR), Extreme Gradient Boost (XGB), Naive Bayes, and Neutral Network for text classification. We also perform user tracking for their retention.
"Farjad Raza 

Saraiki language word prediction and
spell correction"	"Word prediction, spelling error correction and finding similarities between words are useful features in any language. Presently no work has been found for word predic-
tion in the literature for Saraiki Language, one of the popular languages spoken in Pakistan. This paper presents a novel approach by implementing the above features
for the Saraiki language. We used word2vec and Fasttext models to represent words of the Saraiki language into vector form. Variants of word2vec, CBoW has been used
to predict center word and Skipgram has been used to predict the next word in a sentence sequence. Models are trained with different vector sizes and window sizes. Over
two hundred sentences have been used with one missing word at random to measure the accuracy of the word prediction task. For spell correction, character-based Leven-
shtein distance has been used to determine the distance between correct and incorrect word. To calculate the accuracy of spell correction, over a hundred words are randomly
incorrected with spelling errors one to five. Transformer-based Roberta base and distilled models are fine-tuned. Perplexity score is calculated to test the language model.
Our results show that for word prediction task CBoW and Skipgram windows size 3 and vector size 400 has the highest accuracy of 24% in Word2vec and 29% in Fasttext.
Wordsim-353 dataset has been used for correlation calculation. The correlation results show that for word2vec CBoW highest similarity is 35% on window size 3 and vector
size 100; for Skipgram it is 39% on window size 6 and vector size 50. Fasttext CBoW highest similarity is 35% on window size 6 and vector size 400, for Skipgram it is 41%
on window size 3 and vector size 100. For spell correction, our results show that as we increase wrong characters in words, the correction accuracy decreases. For Roberta
models, the perplexity score for the base model is 217.29 and for distilled model score is 234.12. For word prediction task transformer-based model is more accurate with an
accuracy of 63% using the base model and 58% using the distilled model. For a fair comparison, we trained the word2vec and fasttext with the same vector size of 768 as
the dimension of Roberta, accuracy for word2vec is 20% and for fasttext is 18% which is still far lower than Roberta."
"Muhammad Usama 

Multi-Class Skin Lesions Classification
With Feature Reduction"	Skin cancer classification is a complex and time consuming task. Existing approaches used segmentation to improve the accuracy and efficiency but due to different size and shape of lesions segmentation is not a suitable approach. In this research, we propose an improved automated system based on hybrid features and optimal feature selection. Firstly, we balance our dataset by applying three different transformation techniques, which include brightness, sharpening, and contrast enhancement. Secondly, we retrained two CNNs, Darknet53 and Inception V3 using transfer learning. Thirdly, the retrained models are used to extract deep features from the dataset. Lastly, optimal features are selected using moth flame optimization (MFO) to overcome the curse of dimensionality. This helped us improve the efficiency of our model. We achieved 95.9%, 95.0% and 95.8% on cubic SVM, quadratic SVM, and ensemble subspace discriminant respectibely. We compared our technique with the state-of-the-art approach. Keywords: s:skin cancer; feature optimization; moth flame optimization; deep features; feature fusion ; transfer learning.
"Rida Tahir 

Marketing Campaign Optimization
using Social Data"	In today’s digital era where everything is online, people are more concerned in expressing and updating their tastes and preferences on social media platforms like Twitter, Facebook, Instagram etc. These social media platforms particularly twitter, can be extremely effective in extracting information about individuals such as their needs, in terests, and opinions. Our major contribution in this thesis is to identify user interests and desires in the fashion industry, particularly of people from Pakistan. Since, people in Pakistan mostly write tweets in Roman Urdu, dataset we focus in this research is comprised of Roman Urdu Tweets and English reviews. From the literature, we observed that not much effort has been done on Roman Urdu Language because of it being a low resource language. In terms of methodology, we apply LDA, LSA and BERT for topic modeling, Vadar combined with TextBlob, and DistillBert for sentiment analysis, and K-Means lustering for the desires classification. At the end, we per- formed user tracking and evaluated and validated our approach using Cohen’s Kappa score. We have used 20000 reviews for valuation and validated our approach. We believe our research will have a strong positive impact in the fashion retail industry. Keywords: Marketing campaigns, Targeted Advertising, Machine learning, NLP, Sentiment Analysis, LDA, BERT, K-Means.
"Bilal Younas 

Early Risk Identification in Software Projects"	When an event occurs that has the potential to have a negative influence on a software project, we refer to it as a risk. Identifying possible risks in a software development project is always a daunting task, primarily because of the nature of software requirements (volatility, vagueness, incompleteness, etc.). Identifying risks is even a greater challenge during the initiation and lanning phases. On the other hand, benefits associated with early identification of software risk cannot be ignored. Much work has been done in identifying and detecting risks in software rojects. owever, none of them caters for the need to identify risks in the initiation and planning phases. In this study, we propose an early risk identification technique that predicts the type of risks that may occur in a software project based on the quantification of its scope. The proposed approach is focused on Android and Web-based projects. The research extends the scope finition SPSRI [1] elements, risk factors and train multiple Machine Learning models on them – which will identify risks at pre-planning phase. The catered results will be then compared and model ith highest accuracy will be considered. The findings of the evaluation show that the proposed method is effective not only in identifying risks in pre-planning phase, but also as a guide for ractitioners in determining specific areas that need to be considered further. Keywords: Software Risk, Risk Identification, Early Risk Identification, Risk Prediction, Risk identification at pre-planning phase
"Abdul Rehman 

Plant Disease classification using deep learning"	The problem of plants diseases is present since we started agriculture, till now classifying different plants diseases is very hard, To reduce the spread of the disease early detection of disease is very important, This work is mainly focused on improving the classification accuracy by addressing the inter and intra class variations in different plant diseases. We used different image eprocessing techniques in this research and for handing minority classes we used a deep learning-based techniquecfor data augmentation known as DCGAN. For the feature extraction and classification CNN model was implemented due to its success in classification of images, DenseNet gave the best accuracy for the classification of different diseases is DenseNet121 with 97.2% and F1 score of 0.97. Keywords: Convolutional neural network, Deep Learning, Deep convolutional gen- erative adversarial network.
"Muhammad Haris

An automated testing approach for IoT systems"	Internet of Things (IoT) is a network of interconnected devices having sensors that communicate over the internet or other communication networks to send and receive data [1]. Over the past decade, IoT has seen a huge surge due to ubiquitous computing [2]. With many diverse implementations of IoT including smart homes, smart cities, healthcare, education, agriculture, ransportation, supply chain, energy etc. [2], there is an ever increasing need for testing such systems for their efficient working especially in security critical systems. Most of the testing approaches for IoT are focused on generating test scripts for performance testing, integration testing, and conformance testing [3]. These testing approaches are based on a vast variety of techniques ranging from Model Based Testing (MBT), Patterns Based Testing, Fault Tree Analysis (FTA), and Artificial Intelligence (Neural networks, deep learning) approaches among others. Most of the testing techniques are based on software in the loop (SIL), hardware in the loop (HIL), model in the loop (MIL), hardware and virtual test beds, and distributed systems to test across variety of devices and protocols [3]. These existing testing approaches available in literature face a challenge of exhaustive testing because of the need of human involvement in some capacity. Even in case of MBT using state diagrams issue of state space explosion occurs [4]. Any given IoT system can only be comprehensively tested if enough scenarios are tested, which is not possible with available approaches in literature. Poor configurations can transition an IoT system into bad state [5], for this purpose it is necessary to generate system level test scenarios so as to test the configurations comprehensively which can ensure system functionality to its optimum. This thesis aims to comprehensively test IoT systems by generating system level test cenarios for a particular configuration of devices. This thesis will contribute a meta-heuristic approach to generate test scenarios through a search based algorithm which will have a fitness function to evaluate each test scenario and then generate scenarios based on its fitness. Finally the generated test scenarios will be run on a simulator, and evaluated.
"Hina Shoaib

An Automated Approach for Detection of Code
Smells of Mobile Applications Enhance 
Performance"	Mobile applications are highly dependent on performance. Performance has become an important aspect on which the quality of applications relies. Detection of problematic code is a way to remove the code smells which automatically improves the performance of the application. If the source code contains bad smells and anti-patterns the performance of the application is mpromised. Code smells can directly impact memory, power consumption, and CPU usage. It is identified that the existing literature does not detect 2- 3 code smells like “String oncatenation” and Static Views” in android applications. There is also a need to investigate the effect of code smell on performance in mobile applications. Moreover, there is a need to verify empirically that detection has benefits in improving the performance of mobile applications. In this study, we propose an automated approach for the Detection of Code smells in Mobile Applications to nhance Performance. The proposed approach ensures to provide detected code smell with an instance where the smell is detected. Our approach detected the code smell “string concatenation” from the android applications experiment to show the validity of the approach and the impact of the code smell used. The result of the experiment shows a clear difference in improved processing time without using string concatenation. We also use 3 open-source applications to detect the smell and the results show the smell exists in the application. It indicates the instances where the smell was detected. Keywords: Android code smell, Detection Tool, Static Code Analysis.
"Gohar Nasir 

Identification of web elements in dynamic
web applications"	During past few decades web applications are evolving at an incredible rate, and their architecture is becoming increasingly complex. Such diverse and complex web applications make web testing a crucial task. Web applications that are highly interactive are vital in today's culture, therefore they must be dependable, maintainable, and secure. Unfortunately, the complexity of current web applications is expanding, posing significant hurdles to their dependability. While static analysis of client and server code of web applications can provide valuable insight in their dependability, it is essential to use dynamic analysis due to the dynamic behavior of application’s client side. Modern web applications follow certain frameworks for e.g., AngularJS, React JS. These frameworks are event-driven in nature, this particular characteristic of such app makes them highly dynamic. There are various event listeners attached to a webpage that execute synchronously and change the application’s state. They can change the Document Object Model (DOM) at run time. As the use of such frameworks positively affects user-friendliness and interactivity of web applications but these applications are notoriously error-prone due to, their statebased, event-based and asynchronous nature. Modern web application testingtechniques ostly rely on the automated exploration of their state space by triggering events that simulate user interactions. However, identifying interactable html elements in modern web applications is not as easy task. In this work we present a methodology based on DOM features to improve the effectiveness of modern web applications state space. Our approach will be implemented in a tool which utilizes Machine learning techniques. The model will be trained on numerous html elements extracted from a set of random real-world websites to predict interactable elements on a particular web page.
"Saad Tariq

An Automated Approach for Identification of 
Breaking Changes in REST APIs"	REST APIs are defined as interfaces which are used to connect a client to the server over the web. As complexity of modern-day applications is increasing by day, APIs are also becoming larger in terms of lines of code. This requires a vigorous testing regime in order to make sure the program is free of bugs. One of the most commonly faced problems is the breaking of ommunication between the client-server due to the presence of regressions in the APIs after updates. There is insufficient literature currently available on regression testing of REST APIs. Majority of the available approaches target two types of problems. First is black box testing of REST APIs in which the API specification file is used to test and validate the operations of the API by sending a request from the client and analyzing the response from the server. The second is white box testing in which a set of coverage criteria are proposed and test cases are written in order to aximize the code coverage of REST APIs. We propose an approach to test the API for regressions by first identifying the types of breaking changes in REST APIs, and then using these changes to create a framework that shall compare two versions of the same API to automatically detect breaking changes present, along with providing suggestions on how to fix the reaking change. Most of the currently available testing approaches for REST APIs require Dynamic testing, in which the application is run, test cases and senecios are executed, and the results are verified. In our approach, Static testing strategy shall be used which does not require the API to be executed, and is more cost effective and less time consuming.
"Mahnoor Ahmad

Activity recognition of Multi residents
in smart homes"	Activity recognition system in smart homes is highly beneficial for the continuous health of the patients and elderly people who are living independently. It plays an important role in healthcare by maintaining the well-being of the elderly and patients by monitoring their daily life 24/7. Smart devices made us capable of monitoring human activities in a way that we cannot breach human privacy. Most of the research has been focused on single resident activity recognition. However, in real life, the living environment is based on one than more people. Multi Resident activity recognition is a challenging task: recognize the dependencies of the activities as there is no correlation between sensor data values and resident activities. We proposed an approach to recognize the multi-resident activities, in which we combine the machine learning approach SVM and the deep learning model LSTM and train this model on ARAS dataset to improve the performance. The proposed work demonstrates the improved recognition accuracy and F1 score for smart homes residents’ daily activities. The proposed technique tested on the ARAS publicly available smart home dataset.Keywords: Deep learning, Activity Recognition.
"Fatima Farooq 

Transformer based Automatic Urdu Speech 
Recognition (TAUSR)"	Building an automated speech recognition system for Urdu is a challenging task given the lack of publicly available data resources. Urdu is a low resource language and very limited work has been done in the Urdu automated speech recognition domain. An automated speech recognition for Urdu also has to support different dialects as Urdu is spoken by more than 100 million people around the world, with many accents. The text is generated after speech recognition process that identify words and convert them into text or transcription. So far speech recognition has been implemented for higher resource languages like English, Chinese etc. It requires huge amount of data in the form of audio and text. Urdu does not have sufficient data for training. The number of resources available to build a speech recognition in Urdu are also limited. We have proposed methods to improve transcription accuracy for Urdu by expanding the resources vailable for Urdu through data augmentation techniques and using transfer learning techniques; and provide a much-improved Urdu Speech recognition model that can be used as a baseline for future work in this domain. In this work, we present a transformer based model for transliteration of Urdu speech. The speech recognition model developed for Urdu can be further fine-tuned with more data. Keeping in view the challenges with Urdu language, recently transformer has shown promising results in this field and they perform better than recurrent neural networks (RNN). Transformer based models are efficient in capturing and recording content as a global audio sequences. To capture local dependencies of an audio sequence, we have appended components from convolution neural networks(CNN) with transformers for achieving end-to-end Automatic Urdu Speech Recognition (AUSR).Our Model TAUSR has given 32 percent Accuracy on the wav2Vec2 model with the influence additive entity which is a good number as compared to the last entity on the leaderboard wav2vec2-xlsr-300m having the WER of 39.82 percent.
"Saif Ur Rehman 

Automatic Information Retrieval For Threat
Intelligence Platform From Unstructured Data"	"In the cyber security domain, manually extracting the information from the unstructured cyber forensic reports, published on the open web, is time consuming and least efficient. Automatic information extraction by integrating the Deep learning with NLP can help to reduce the cyber attack rate with improved efficiency. Specifically talking about the unstructred data for the cyber security domain, the nature of the data is multi-modal and multifaceted which is a huge hurdle to develop an efficient system that will deal with this challenge. A lot of research has been done in this domain however they have tried to tackle this problem using sentence level information extraction which cannot extract the information correctly from the multifaceted data. The solution to this problem is document level information extraction. Our proposed method is based on document level extraction. To the best of our knowledge, no published work has considered document level information retrieval to extract the information from cyber articles. We have developed state of the art document level attention based Bi-Directional LSTM integrated with CRF layer. We have attached a vector with the attention layer to capture the document level context. The dataset contains cyber threat intelligence reports having annotated entity tags like ip, hash, malware etc. Our proposed model produced 91.36% precision, 84.5% recall and 87.73% F1-Score. Keywords: Document level NER, cyber security, Deep learning, multimodal multifaceted
data, unstructured text data ."
"Nasir Zafar 

Specific Ideology and Style based Text
Generation using NLP"	Text generation tasks have gotten the attention of researchers in the last few years because of their applications on a large scale. Transformers are the latest model used in natural language understanding and natural language generation. In the past, many researchers focused on task-based text generations, e.g., generating weather reports from given structured data. A lot of work is done on generating text based on the ground reality of the world by converting the ground truths of the world into a graph and generating the text. When some initial text is given, the model has to complete it. Our research focuses on text generation based on the ideology and style of a specific author, and text generation on a topic that was not written by the same author in the past. Our trained model requires an input prompt containing initial few words of text to produce a few paragraphs of text based on the ideology and style of the author on which the model is trained. Our methodology to accomplish this task is based on LSTM. The LSTM model is used to make predictions at the character level, during the training corpus of a specific author is used along with the ground truth corpus. A pretrained model is used to identify the sentences of ground truth having contradiction with the author’s corpus. These identified sentences are excluded during training because the goal is to generate a language model inclined towards the ideology and style of the author. The NLTK dictionary is used to extract missed word in training corpura, to traing model on these missed words text chunks are taken from NLTK book.During training, we have achieved a perplexity score of 2.23 at the character level.The experiments show a perplexity score of around 3 over the test dataset. Keywords: Text generation, Language understanding, Language Generation, Language Model, Transformers, NLTK, Perplexity .
"Saeed Ur Rehman 

Recency Based Temporal Feature
Weight Generation for ERecruitment
(RBTFW-G)"	Globalization, improved networking, and modern communication systems have resulted in a tenfold increase in the available data, resulting in a significant increase in the number of resumes. It is extremely time-consuming to conduct the recruitment process, and a great deal of successful research has been done to streamline the process to a certain extent. As a result, automation has gone from being considered a luxury to being considered a necessity. Multiple Criteria Decision Making (MCDM) techniques such as AHP [1], TOPSIS, VIKOR [2], and their optimized variants such as SlashRank [3]consider a variety of factors and then rank the results in accordance with those considerations. Although human intervention occurs at some stages, such as explicit manual feature priority input or a Saaty’s rating scale [4], this results in bias and a decentralized method of hiring candidates in the long run. In this study, we investigate the hortcomings of previous techniques that have been identified and propose a methodology that addresses the manual feature priority input. On the temporal aspect of feature priority trends, we discuss how the trend changes in the market. Furthermore, a technique is proposed that builds upon the importance of including recency into feature priority generation in order to replicate real-world recruitment feature priority fluctuations. Additionally, we prune candidates for the highest priority featureto improve the algorithm’s accuracy and consider only the top-k ranked candidates as shortlisted candidates. Finally, we evaluate the ranked results using Normalized Discounted Cumulative Gain (NDCG) and got an average (NDCG) score of 0.82.
"Abdul Hanan 

SlashRank: An Efficient Algorithm for Ranking Candidates in
E-Recruitment System"	E-Recruitment is a valuable step in the automated world, where cost-effectiveness is crucial. E-recruitment systems have reduced the resources used to hire professionals in terms of time, effort, and cost. The ranking module of the e-recruitment system involves the ranking of the candidates according to the job description. Existing ranking approaches include learning-to-rank (L2R), semantic-based, and multi-criteria-decision-making (MCDM). MCDM approaches provide promising but unscalable results due to exhaustive pairwise comparisons between the candidates. In this research, we propose an efficient and accurate ranking approach, SlashRank. It avoids comparison with unqualified candidates and prunes them using a rule-based pruning technique. Our approach provides an effective technique for matrix sorting and compression that reduces the complexity of candidate comparison matrix computations against every feature. SlashRank also considers the candidate’s temporal information embedded in the resumes for better ranking results. To evaluate the efficiency and accuracy of SlashRank, multiple experiments were conducted using three distinct datasets: Real-World, DBLP, and POKEC datasets. We also compare our proposed SlashRank approach with a state-of-the-art MCDM-based AHP algorithm and achieved better results in terms of time and memory used under various experimental conditions.
"Asfand Yar 

Multi-Organ Plant Classification Using
Deep Learning"	Organ classification of plants is a common practice these days but the Multi-Organ approach is very challenging. The flexibility and variability in the shape and appearance of plant organs increase the level of complexity. The existing approaches were mainly focused on generic features of plants while features representing plant organs were completely ignored. In my approach, I will be using a Convolutional Neural network (CNN) which takes organ and generic information and combines them using a new feature fusion scheme for species classification. Furthermore, due to the imbalance of the number of images in the respective organs category, I will be using Generative Adversarial Networks(GANs) to generate synthetic images and balance the dataset which will surely increase the accuracy and other evaluation measures of the models 
"Arslan Ijaz 

IoT-based Mobility Estimation"	Honey bees play a very significant role in the ecosystem. The honey bee is one of the best pollinators among insect species. Honey bee products are used as food and medicine. In recent years, honey bees numbers are decreasing due to climate change, habitat loss, parasites, and excessive use of pesticides. Swarming can also be potential threat to beehive if not detected on time. warming is the process in which an old queen bee leaves a beehive with half of the worker bees. Swarming is a huge worry for apiculturists, if not timely detected. It can lead to colony collapse disorder and increase the production cost of honey. Swarming behavior shows variations with changes in geographical regions and with different species of domesticated honey bees. Thus, problem demands a local solution instead of a global one. The audio data is collected from apiaries situated in Pakistan. This research aims to build an end-to-end swarm detection system using the audio of honey bees with the help of a machine learning and deep learning algorithms. Artificial Neural Network, Support Vector Machines, K-nearest Neighbor, and Logistic egression techniques are used for swarm detection. The proposed solution has detected the swarming with 99% accuracy.
"Waleed Anjum

Censoring Broadcasting media Data in accordance
with Censorship Rules using NLP"	Hate speech and offensive language have become a major issue on electronic media. In Pakistan PEMRA’s duty is to keep an eye on such content. PEMRA has identified many censorship rules in 2015 which must be fulfilled by all electronic media sources. This research focused on electronic media content which is against the integrity, security and defence of Pakistan hit any eligion, sect, cast or any specific community and has aspersions against the judiciary and armed forces. This content may create anarchy between different areas, ages, departments and religions people. PEMRA is mostly checking the electronic media content for these rules manually which is a very tedious, time taking and laborious task. This research covers this gap by introducing a model that helps to check these rules automatically using NLP techniques. This reduces the cost, time and effort. A self-annotated dataset is used to train the model on the censorship rules. The Dataset is categorized into total of 8 Labelled classes. BERT, RoBERTa and Bi-GRU are implemented and trained on BERT and Word2Vec embeddings for this problem. These models perform well against baseline models on the dataset. BERT with BERT-embeddings outperforms all the three proposed models with an F1-Score of 0.66. Keywords: Censorship, Censoring Rules, PEMRA, NLP, BERT, Bi-GRU, RoBERTa.
"Muhammad Hamza 

Explainable AI for Oncology"	This research work aims to develop an explainable TTF prediction model using NLP techniques and deep learning approaches. We are utilizing clinical notes alongside tabular data for Time to Failure prediction for cancer patients. We aim to investigate traditional NLP techniques for text preprocessing e.g. Topic Modeling and utilize statistical Machine Learning as they are easy to nterpret. But due to accuracy wise superiority of deep learning based solution for prediction purpose, RNN preserve time series element hidden in data. So in order to get accurate model, our priority and main focus in this research would be to entertain deep learning based model and their explanation. Layer-wise relevance propagation has been widely used for achieving plainability of Deep Learning based models. We will explore state of art techniques to achieve explainability of RNN-based models to process clinical textual notes and predict TTF for cancer patient.
"Sabahat ali

Metamorphic Testing of Machine Learning 
Applications"	Machine learning (ML) is a branch of artificial intelligence (AI) and is used in several application domains such as bioinformatics, computer linguistics, and other scientific program.ML application testing is a key aspect before launching it in the working environment. ML applications are considered non-testable programs because such program lacks a “test oracle” a procedure for detecting correct and incorrect behavior of the program. A testing technique called metamorphic testing is used to overcome the oracle problem by generating multiple inputs of the single program based on metamorphic properties called Metamorphic Relations (MRs) and follow-up test cases are constructed against these properties. This paper focuses on detecting the faults of Text classification programs residing under the domain of Natural Language Processing. Metamorphic relations are constructed for the KNN and Naive Bayes algorithms. Metamorphic testing successfully indicates faults and ensures the deviation of the algorithm from the expected output.
"Sahifa Alam

Distributing revenue amongst Crowd: A Shapley 
value based Cooperative Game"	Crowdsourcing uses the intelligence of crowd in order to solve the problem. Considering the emergence of crowdsourcing and its perceived promise, both crowdsourcer and crowd expect a greater reward. All the participants become part of the crowd to maximize their reward. However, not everyone is eager to take part in collaborative tasks. Collaborative crowdsourcing tasks allow two or more crowd workers to solve problems that they could not handle alone. Revenue sharing is very important part of collaborative tasks. Existing revenue sharing models’ non-game theoretic models such as Fuzzy approach, BOCR frame work method, Grey rational analysis, equity theory and many others are used to address such problems. The existing non-game theoretic models such as Fuzzy approach, BOCR frame work method, Grey rational analysis, equity theory and many others had biasness towards one of the participating parties in the crowd. While game theoretic models such as Nash Bargaining and Stackelberg game are known to give out optimal solution, they are not always fair. The Shapley value is known for the fair division of revenue but it doesn’t make assumption about the effort that a crowd worker expends when contributing to the surplus or when the task is collaborative. However, this model works only on only two stages of effort i-e “working” and “not-working”. In practice, people usually have a wider range of effort levels to select from. In this study, an extended version of Shapley value is used to a broader context in which each individual can select a different amount of effort from a finite ordered collection of possibilities. Subsequently, the extended version of Shapley value distribute revenue corresponding to the effort exerted by the crowd. Lastly simulation results prove that the extended version of Shapley value guarantees that it takes in account the marginal contribution of the players so as to allocate revenue on its bases and also it holds the axioms of additivity, symmetry and efficiency.
"Safa Abdul Karim 

An Automated Bug Prioritization Approach using
CNN based Deep Learning Algorithm"	Software bug prioritization is one of the most difficult tasks of bug resolution process. Wrong priority assignment to these bugs may result in inefficient utilization of organization’s resources which include time, cost and efforts used to fix unimportant bugs. Traditionally bug prioritization process is usually performed manually which makes it error-prone and requires intensive human effort. In recent years, bug prioritization related issues gained increasing attention both academically and industrially. So, bug prioritization is critical area and of major concern that need consideration to efficiently prioritize bugs, overcome the load of developer and avoid over budgeting. Therefore here is a need to develop an automated technique that can prioritize bugs by taking into account the overall organizational objectives and eliminate subjectivity and biasness in decision making process for selecting bugs that need urgent resolution. A CNN-based deep learning model has been proposed to predict the priority of bug reports. CNN models are used for the textual sentiment analysis by transforming the representation extracted from the formation that is used for training of model. Factors that are considered in bug prioritization are title, description, priority and severity. Data is pre-processed and converted into vector as CNN-model accepts vector as an input. Convolution is performed in corresponding layer. The feature vector is improved by each filter and generates a map for next layer. Firstly, the CNN model is trained using training data of Eclipse and Mozilla open-source repository. Secondly, the testing data is used to evaluate the performance of proposed model. Performance of model is evaluated using accuracy, precision, recall and f-measure. This study aims to gain insight on the state-of-the-art techniques used in the context of software bug prioritization, to design and develop a novel approach using deep Learning Algorithms to prioritize bugs and to evaluate the performance of proposed approach.
"Ali Shahbaz 

Automated Bugs Identification Through Early 
Access Game Review (EAGR) Analytics On 
Game Distribution Platforms"	User reviews are considered one of the most important source of information about an app and game. The classification and analysis of reviews in order to extract information has proven to be a considerable difficulty. Game applications receive user input in the form of reviews, which can assist developers in selecting games with improved functionality and extracting relevant nformation such as user feedback, problems, and descriptions of user experiences linked with existing features. Because of the enormous user base and potential benefits of automated feature and bug extraction, game application review analysis has lately arisen as an active topic of research in software engineering. Recently, several research studies have been conducted to mine and categorize user-reviews into actionable software maintenance requests, including feature requests and bug reports. However, existing literature have mostly focused on mining functional aspects and analysis of use. Several studies have recently been carried out to mine and categorize user evaluations into actionable software maintenance requests, such as feature requests and bug reports. reviews for positive and negative feedback. To achieve user satisfaction and to survive in the app market, addressing these bugs reports to developers is necessary. Therefore, in this research we formulate this problem as a Multi-label classification problem and propose a bug classification model using CNN (convolutional neural network). Representative features are used to train a model for bug classification. Use of feature extraction methods to train a classification model may lead to divergent results, which implies the need for a careful selection of these methods. Several recent studies have emphasized that basic state-of-the-art taxonomies for bug classifications into different categories. Therefore, this research employs these taxonomies to provide a tools which takes a user reviews dataset and then identify bugs form them and after identification it will classify the bug into their related bug categories using CNN (convolutional neural network). We are taking GAME STEAM ENGINE as a case study to scrap gaming reviews and train model on that reviews for bugs classification.
"Tamseel Abbas 

Securing Electronic Identity on Mobile Device
 using TrustZone"	Electronic identity is system generated identity by which a person can prove his identity online to gain access to third-party services. It is more like our physical identity card, driving license, or passport. Electronic Identity is similar to identity certificates used for online authentication purposes, if a malicious person has access to another person’s electronic identity, then he can access all the services associated with the identity of that person, and an attacker will be able to access bank account, hospital data, and vehicle information. In the electronic world, we cannot rely on security-provided by software for sensitive applications, neither operating system nor user application. There is always a security flaw, sometimes it’s intentional sometimes it’s a developer mistake. oAuth which is adopted by all major corporates provides a solution by which the client device does not hold the identity certificate on his device but rather a centralized system such as the identity provider holds it. Third party application will receive identity of the user once the user is successfully authenticated to the identity provider. If the user’s device is compromised and the user is authenticating to the identity provider there is a chance that malware can steal oAuth access token and use it later for malicious purposes. It is possible that malware deceives the user by showing a fake consent screen and forcing him to click on allow button. We must protect the whole process of oAuth on the user device in a trusted execution environment such that even a compromised operating system could not interfere. To protect electronic identity, we have proposed a TrustZone based solution, TrustZone provides a separate secure world to android application so that even malware with root access cannot in terfere with application running in TrustZone. In our work we have used open-source Android version (AOSP) and open-source Trusty OS (TEE). By running sensitive part of our oAuth application in TrustZone (Trusty OS) we have successfully secured critical component of application. For the protection of credentials and access token received from IDP we have encrypted them with keys generated by TrustZone. We have eval- uated our solution using malware injected in root android device and malware was unable to read access token and profile data because every thing was encrypted with TrustZone cryptographic keys.
"Shozib Hussain 

Protecting National Digital IDs using Intel SGX
enabled Trusted Execution Environment
"	National electronic identification is used to analyze the authenticity and authorization of the individuals accessing online services. Digital Identity can be used for the banking system, health are, digital on-boarding,  online identification, and online document signing. Assuming that some of the users are compromised and an attacker has access to the administrator account of the user’s system. National IDs are the ones we cannot change on regular basis, so to protect eIDs we need a mechanism that even if an attacker has access to the system, he cannot manipulate our critical applications. OAuth 2.0 and cryptographic modules are secure until the users’ system is safe from hackers. In this paper, we propose a solution to secure critical applications using isting protocols like OAuth 2.0 and cryptographic algorithms. Intel Software Guard Extension (SGX) enabled Trusted execution environment (TEE) will run the application in a secure zone and provide a zero-trust environment. SGXIO provides the I/O security and SGX provides a secure execution environment. Each identity card has a chip that contains a user-specific certificate. The certificate will be stored inside the SGX and encrypts the password at the user’s request. The cipher will be shared with the IDP then IDP will decrypt the cipher and compare the user’s assword. Users need to provide only the password and run the application. We also analyzed the performance overhead which is only 2% which is acceptable and evaluated new security ulnerabilities which might come up with this method and we found that this is a secure development process. We also tried to install keyloggers and screen spoofer to access the application but it is prevented by the SGXIO. This way, the OAuth protocol will remain the same, we have just taken a few measures to secure the process.
"Urooj Ghani 

Protecting the Vehicle Soft Integrity in
Shared Mobility using Blockchain"	Shared mobility is increasing day by day with the rapid development in the automo tive industry. The trend of mobility is changing from individual mobility to shared mobility. Shared mobility means that many different people can easily use and access vehicle that is not owned by them. As the vehicle can be used and accessed by different people its security and safety are a major concern. An attacker can easily rent a vehicle and tamper the software running in the vehicle because he/she has complete physical access of the vehicle. Tampering the vehicle’s software results in a catastrophic consequence for the people who will use the vehicle after the attacker. The vehicle owner can easily identify and detect the physical damages done by the user of the vehicle but changes in the software of the vehicle are difficult to identify and detect. There must be a mechanism that easily detects tampering in the software and stores vehicle and user information securely in a database. For this purpose, we are using blockchain to store the vehicle data from the central gateway of the vehicle signed by the Trusted Platform Module (TPM) and user data from an application after every possession of the vehicle, the software integrity is checked by comparing it with the information present in the blockchain. This paper also provides implementation of the proposed system, demon- stration of android application and performance, attack, and security analysis to show the feasibility of the proposed approach. Keywords: Shared Mobility, Blockchain, Vehicle Soft integrity, Vehicle Safety, Vehicle Security.
"Muhammad Usman Ghani 

Traffic Sign Recognition for Autonomous 
Vehicles"	Traffic Sign Recognition (TSR) has been dominant application area for object recognition/Detection for some time. Different solution of object detection and recognition tasks are being developed with quite good accuracy. However when it comes to conditions and other challenges there is still room for improvement. In this work aim is to achieve efficient results for TSR using CNN and SVM classification algorithms. Feature extraction techniques are also used with Random Forest classifier. There techniques are HOG and SIFT. Dataset taken is in quite large number of images for each class. Ideally number of classes used are 25 and these models are also tested on all 43 classes of traffic signs. Dataset used is cropped and augmented which also has positive impacted on results. Results are analyzed and compared.
"Asim Suleman 

Analysis of Potential Research Areas and
Authors Area of Focus Determination
using DBLP dataset"	Given that a research has to be unique and relevant. With the abundance of research publications being published every year, selecting a field of research and identifying a unique problem for a new researcher has become a very challenging task. For this purpose traditionally a review paper is used to identify the gap. Our research paper proposes a new approach to identifying potential research areas by analyzing the DBLP Computer Science Bibliography publications datasets to identify and predict the trends in foreseeable future. Proposed solution uses XGBoost and Long- Short Term Memory (LSTM) model approach to predict the trends based on focus of research  (FOR) for given titles. For evaluations metrics we used Root mean square average (RMSE) on est dataset to achieve 65% accuracy. Moreover this research lays a foundation for topic identification of different FORs based on the title of research paper. Keywords: Focus of Research (FOR), Root mean square average (RMSE),XGBoost , Long-Short Term Memory (LSTM), DBLP Computer Science Bibliography (DBLP)
"Hamza Javed 

A Secure IoT-Based Health Monitoring
System"	IOT based remote health monitoring is a promising technology to support patients who are unable to travel to medical facilities. Due to the high sensitivity of health data and large number of users and technologies involved, it is important to secure the user health data at all stages. While a great deal of work has been done for securing various stages of this pipeline from IoT devices to health records, insider attacks remain a significant challenge. Malicious administrators may tamper, steal or remove patients’ health data. To overcome this problem, audit logs are used on servers that manage health data to inspect user actions. However, administrators with access to logs can erase, manipulate or forge logged data,thus giving rise to the need for a secure, mmutable log file. In this thesis, we propose a Cloud Access Security Broker (CASB) model for securing access to health records that integrates a private blockchain with the CASB. The urpose is to securely log all the activity perform by all modules of the system on a private blockchain, for non-repudiation, immutability and integrity protection of logs. This will serve to iscourage insider attacks as all actions of administrators will also be logged and cannot be manipulated. Moreover, we piratically implemented the Cloud Access Security Broker (CASB) that integrates a private blockchain and measure performance of our proposed system on the basis of different evaluation parameters like time and size of log data.
"Muhammad Aamir 

Improving Open-CL Scheduling Algorithm on a Heterogeneous Hardware using Machine Learning Techniques"	In the past decade or so, the software industry has seen a major paradigm shift. Where the focus has been shifted from a “single core” processing to “multi-core” processing. Compute intensive tasks, especially scientific computing applications have started to increasingly rely upon “Graphic Processing Units” (GPUs). This is mainly because GPUs provide hundreds of thousands ghtweight computing cores. This heterogeneous computing environment also presents an interesting load-balancing and scheduling challenge. Because generally the programmer is not aware about which hardware device “CPU, GPU or other accelerator” is more appropriate for a given task. In addition to this, programmers certainly cannot be burdened with the task of loadalancing as this is dynamic problem. When it comes to Open-CL kernel scheduling, the Open-CL framework and the operating system does not provide any smart scheduling solutions. Therefore, various algorithms have been proposed to resolve this problem. Many of them rely upon offline and online job profiling, and the use of machine learning based techniques to effectively load-balance and schedule Open-CL kernels on a given device. However, these approaches do not collectively address the problem of load-balancing, concurrent kernel execution, kernel fusion. In this paper, we propose a new Open-CL kernel job scheduler called HASH-CL. We will address the said problems in a single framework, along with some novel additions to speed up the erformance of the over- all framework. These novel additions are the use of cache mechanisms to work with alongside machine learning algorithms, the ability for the programmer to rioritizecertain jobs over other, the framework will also be able to be scaled up from a single node machine to a cluster. 
"Ali Naqvi

Object Detection and Recognition for Autonomous
 Vehicles in Adverse Weather Conditions"	When a child is born, he cannot write anything, he cannot read anything, he cannot speak any word, but what he can do is listen and see things in his surroundings. He observes the things through his eyes. Our eyes are best object detection. Object detection is very much essential for autonomous vehicles. Without a proper object detection, a self-driving car will be like the blind man driving a vehicle. Who cannot infer what objects are on the road, what are their shapes and sizes? He will hit with miscellaneous objects immediately. For last few decades, a numerous research has been conducted to bring intelligent vehicles on road. There are many scenarios which need to be explored in driverless vehicles, object detection is one of them. Object detection can be performed with handcrafted features such as Histogram of Oriented Gradients (HOG), but deep learning has restructured every field. Object detection with deep learning is much more accurate than the traditional approaches. There are many deep learning model for object detection. For instance, Yolo, Single Shot multi-box Detector (SSD), Mask R-CNN, EfficientDet, transformers, and liquid neural network. Performance of these algorithm is not equivalent to human visual system. Researchers are working to improve these model. Extensive amount of work has been done regarding object detection in driverless vehicles. These models cannot perform better in severe weather conditions such as fog, snow, rain, and storm etc. We need to optimize these models so that they can perform more efficiently and accurately in harsh weather conditions. Our approach is based upon image processing and deep learning techniques. We will perform data augmentation techniques to make our model robust. Image processing techniques will remove these filters rain, fog, and snow, then a clear and smooth image will be sent to the neural network for object detection.
"Zain Asif 

Inflation Forecasting with Convolutional 
Recurrent Models"	Forecasting inflation is one of the core exercises at central banks. Based on which monetary policies are formed; which further determine the economic output of the country. As in other fields, machine learning can also play a vital role in forecasting the inflation rate to help policymakers in decision making. There are existing statistical techniques for forecasting but the research hows that the neural networks outperform the traditional forecasting techniques like the linear autoregressive model (AR), the random walk model (RW), seasonal autoregressive model (SARIMA) and Markov switching model (MS-AR). Among neural networks, RNNs or more specifically LSTMs are popular models for inflation forecasting. LSTMs clearly outperform other models and its performance is best when trained on year-on-year monthly inflation but when we trained the multivariate model by adding additional features, its performance degraded. LSTMs have emory cells which are great for handling short-term long-term dependencies, so LSTMs can handle temporal information. CNNs are known for extracting useful information from the data and can learn the deep features. Research shows that adding CNN layers to LSTM greatly enhances its performance. In our research, we implemented hybrid CNN_LSTM based models, trained them on the inflation data for Pakistan and compared their performance with LSTMs for both univariate and multivariate data. We performed a series of experiments on datasets of akistan, China, India, Canada and Srilanka to assess the performance of these models. For univariate, we trained the models on year-on-year monthly inflation and for multivariate we used CPI derived eatures. Our results showed that the CNN-LSTM models showed a significant improvement over the baseline LSTM models for both Univariate and Multivariate scenarios. Univariate CNN-LSTM showed the overall best results outperforming other models.
"Haris Younas

Exploratory Study on Rome Laboratory
Model using System Dynamic Modeling"	The acceptance and failure of software device is determined by reliability. If software meets our expectations and does not get failed for the specified time it is considered a reliable software. mong all the techniques, to determine software reliability, prediction models are most widely used. It evaluates the system to predict or estimate its failure rate. The best phase to use the rediction is at design stage, however it can be use at any product lifecycle phase. Using it at the design stage enables to address issues or errors before developing the product. Moreover, identifying these issues at an early stage also means that it will be cost effective, as the cost of fixing an issue increases exponentially the later it is discovered in a product’s lifecycle. Prediction also evaluates the software’s ability to satisfy operational requirements. In other words, prediction helps software to pre-resolve its failure[1, 2]. There is another model to measure system eliability which is growth model. These models are applicable once the product is in use, they use the data generated to determine the occurrence of the next failure. This research focuses on rediction models and how they can be made more easy to use and effective instead of growth models. Prediction models are used to detect the future behavior of the software using some asurable characteristic f the software. These measurable characteristics are defined as software metrics. There is an extensive list of these metrics that have been used by researchers and at times it is difficult to determine which of these metrics are most useful to predict software reliability in a given context. In addition to this, several metrics have been developed for the goal of redicting software faults but they are not suitable for such prediction. Certain prediction models predict faults based on their size and complexity, while others depend on testing data, the quality of a specific development process,or even a multivariate strategy. One of the most used model to predict software reliability is Rome Laboratory Model which has a wide variety of metrics to determine software reliability. This model contains some metrics which might not be pertinent for majority of software products. The objective of this project is to identify and evaluate the metrics which can be used to measure software reliability and propose enhancements in this model.
"Zain Ul Haq

Distributed Frequent Pattern Mining Using Spark
for Big Data"	Big Data is one the most enormous and attention-gainer factors of recent years. Data is one of the key factors of today’s innovations rather it’s related to the technical field or the other field data is present in every application that’s why it increasing day by day. In the era of innovations, we have to deal with many types of problems but identifying the data most useful to solve that roblem is the real challenge and when the problems deal with the big data then it became a nightmare as analyzing the bulk of data in one of the most challenging things. Many Data mining techniques including various pattern mining techniques have been proposed to identify the patterns hidden within the data. These patterns are the major source to answering those certain questions which are difficult to answer in a particular scenario. In this study, we have used different frequent pattern mining algorithms belonging to different classes such as Association Role Pining, Sequential, and Periodic Pattern mining on streaming data coming from different sources handled by a tool, known as Kafka. From the streaming data to the Frequent pattern mining algorithms in the environment of Spark to satisfy the big data we, obtained the results from which we can detect the pattern mining algorithm which can be applied to a given form of data.
"Yasmeen Afzal

Efficient Aggregation of Heterogeneous Data
for Threat Intelligence Platforms"	"With increased dependency on computers the threat of cyber-attacks become more prevalent. Cyber-attacks continue to incorporate exploitation of various vulnerabilities and thus are becoming more sophisticated by the day. Cyber threat intelligence deals with the gathering of reports from the previous threats and thus enable us to identify potential future attacks. Therefore, fifteen heterogeneous threat intelligence sources have been explored systematically. The correlation between these threat feeds and their sophisticated relationships are further enriched by evidence provided by other sources. These derived situational aware evidence build firm grounds for detection and prevention of cyber threats. The challenge faced in the threat intelligence is to have overloaded threat feeds from millions of sources with heterogeneity in reporting formats. Currently all threat intelligence feeds create data in a heterogeneous format with different data identifiers. For any threat intelligent system to incorporate multiple feeds result in a huge processing overload requiring more time and resources. However, the heterogeneity in threat
intelligence sharing platform need to be addressed. In this work, a robust architecture has been proposed for data aggregation from heterogeneous sources. The architecture is composed of semi-automatic and fully automatic mapper. A
three tier semi-automatic model that maps the heterogeneous sources’ feeds into target Threat Intelligence Platform (TIP) model as per the broker defined mapping of sources. In the model each layer has its own set of jobs and works in a step-by- step fashion the output of one layer might be input to another layer. Fully automatic Machine learning based mapper has been proposed that automatically maps the
threat feed into target TIP model. The objective is to have a mechanism that can transform data from heterogeneous sources into an integrated form that can assist the TIP for data mapping."
"Muhammad Kashif

Machine Learning for Beamforming in Millimeter Wave
 Massive MIMO System"	"The growth of connected devices, mobile users, and an enormous increase in data traffic volume demands the bandwidth of millimeter-wave frequencies. Performance remains a challenge in this bandwidth of frequencies due to its path loss and penetration loss. To compensate for the performance degradation, beamforming is one of the most important techniques in the millimeter-wave massive multiple-input multiple-output (MIMO) system. Fully digital beamforming is not feasible in commercial communication systems due to its power consumption and hardware limitation. On the other
hand, analog beamforming is an energy-efficient architecture, but due to the single RF chain, it only transmits a single stream of data which lowers the system’s spectral efficiency. Therefore, hybrid beamforming has been investigated to achieve the performance and cost of digital and analog beamforming. In this work, we propose a deep learning approach to efficiently compute the resultant hybrid beamformer and to reduce the complexity issue without losing performance. The network takes the channel matrix as input and gives a hybrid beamformer as output. We train the network with many noisy channels with different realizations to achieve the best performance. Our results show that the proposed approach provides better spectral efficiency and less complex than the conventional techniques."
"Muhammad Faran

Remote Monitoring for Controlled Mobility"	Honeybees plays an important role in the life preservation and health of an environ_x0002_ment. Bees not only provide pollination services but beekeepers also use them for the production of honey, beeswax and royal jelly. Decline of bee colonies is a global prob_x0002_lem and significantly affect the profitability of the beekeepers. Currently the beekeep_x0002_ers are manually monitoring the hives and it is not possible for a human to monitor all the hives during the day and night and as a result many events in bee colonies go unnoticed. This research aims to automate the work of beekeepers by presenting an intelligent bee monitoring system that keeps track of the activity of bees inside the hives. The monitoring is carried out with the help of temperature and humidity sen_x0002_sors. These sensors are used to get temperature and relative humidity readings inside the hive as well as of the surrounding. The data of sensors is transferred to cloud platform with the help of Raspberry Pi. The events inside the hive have been captured with the help of data from the sensors. The proposed monitoring system has a great potential and has ability to monitor the beehives in real time
"Taimoor Arshad

Improving Restaurant Management using 
AI"	The food and beverages business is part of a rapidly changing industry. A single decision can be a differentiator between success and failure and restaurant owners and managers need to make these decisions at the right time to stay in the competition. Most of the time these decisions are not obvious and even years of experience also cannot guarantee the right decisions. Fortunately, data science and data mining techniques have made considerable progress in the past few years. Now we can extract and analyze patterns from large amounts of data which was not possible before. In this thesis, we have focused on a particular use case of frequent pattern mining. We have used five different frequent pattern mining algorithms to identify interesting patterns from the sales data of a restaurant. Using these patterns we try to answer business-specific questions for our scenario. From the results obtained we are able to address mainly five categories of business questions which are based on product placement, sequence of purchases, bundling products, discounts, and product partnerships
"Asad Rahman

Protection of Control Plane in SDN
against False Traffic"	Software Defined Network (SDN) introduced a tremendous change in traditional net_x0002_work architecture through decoupling control plane and data plane. Such architecture does provide flexible topology as well as manageable controlled environment. Now a day, SDN architecture is usable in almost all of the network environments. What so ever, due to its centralized and controlled environment various part of the architecture does face a degradation and compatibility issues. Various vulnerabilities present in the network architecture of SDN especially within Open-flow protocol increase the chances of threats into the network. Such threat contains false packet injection attack, that leads to contaminate the resources of the controller by spreading false information in the net_x0002_work. To prevent such threats multiple proposals have been introduced in the industry which are fool-proof and may either lead to denial of services on part of switches or controllers thereby compromising network availability. Therefore, to counter such attack a mechanism must be introduced to identify and manage every unknown up_x0002_coming packet. Thus, the packet-in message must be authenticated or verified whether it’s a spoofed packet or generated by a legitimate user. The evaluation and result in_x0002_dicates that the proposed method successfully mitigate the False Packet injection by authenticating the packet-in message and provide 20 % better results as compared to the previous approaches
"Muhammad Ali

Detection of DDoS attacks in IoT using
an efficient Machine Learning based
approach"	Computer networks have rapidly grown in size as the Internet of Things (IoT) has grown in popularity. While the Internet of Things benefits many parts of life, it also introduces security threats in the form of vulnerabilities, providing hackers with bil_x0002_lions of new targets to attack. Botnets, for example, have taken advantage of common IoT device security weaknesses to obtain illegal control of hundreds of thousands of hosts, which they then use to launch hugely disruptive distributed denial of service (DDoS) assaults. In the Internet of Things, DDoS assaults are becoming a major is_x0002_sue. Rouge devices are introduced to launch such attacks and then exploiting them, along with other hacked devices, to aid DDoS attacks by producing continuous traffic. Machine learning techniques are capable of identifying DDoS attacks, but also pro_x0002_vides prevention. Static and dynamic machine learning techniques are used to select most adaptive (correlated) features. Static attributes selection techniques are suitable in the dynamic nature of incoming traffic. Therefore, a dynamic attribute selection tech_x0002_niques is required to reduce the training time. The dataset that is used in the research is CICIDS2017. The proposed machine learning DDoS classification technique is cate_x0002_gorized into three modules. One is pre-processing in which features of the dataset are selected and normalized. In the second module, most important features of the dataset. This technique reduces the number of features from 79 to 30. In the last module, Five different classifier are used to classify DDoS and normal traffic. The classifiers that are used to classify the normal and attack traffic are: Random Forest (RF), Gaussian, Logistic Regression, K-nearest Neighbor (KNN), and Decision Tree (DT) classifiers are employed. The Logistic regression had the most improved results from the base paper with the accuracy of 0.92 percent and CPU time of 5.7 seconds
"Muhammad Shahid

An Efficient Trust based Mechanism for
OnOff Attack in IOT"	The Internet of Things (IoT) is emerging technology in current era. The IoT makes networks of homogeneous and heterogeneous devices. These devices are providing different services for number of applications. IoT nodes collect data from the envi_x0002_ronment and process it. Due to the less computing resources these devices are less secure and can not execute complex algorithms. These types of networks could be compromised by various internal or external attacks. ON-OFF is one of the enormous attack, that compromised device forwards data when in OFF state and drops data when in ON state, to detect ON-OFF attack various researchers proposed solutions including Dynamic distributed trust management scheme. Latest solution of DDTMS detects malicious node successfully using dynamic trust calculation methods. The goal of this study is to identify the malicious nodes in fewer instructions as comparable to the previous solution. Effective detection of ON-OFF attacks are key to the uninter_x0002_rupted operation of IoT. This proposed approach will achieve Trust and explore these solutions for efficient detection of ON-OFF attack by changing existing formula for the reward and punishment calculation. The thesis shows 30% efficient results compared to DDTMS. It detects malicious nodes with minimum number of interactions.
"Muhammad Abu Zar Qasim

Impact Analysis of Batch Refactoring on
Quality Attributes in Open Source Systems"	Refactoring is a maintenance activity that involves applying different transformations to the source code to achieve the desired goal. The goal could be removing code smells, improving internal or external quality attributes. However, a single code transformation is not enough to achieve the desired goals in practice. Most of the time, Batch Refactoring has to be applied. In practice, more than 60% of refactoring transformations constitute of batches. Nevertheless, the existing empirical work on batch refactoring is minimal. The current work is either focused on its applications or on its automation, without knowing what impact batch refactoring has on the software’s quality. Also, majority of the work regarding impact analysis relies on characteristics that constitute of single code transformation type. To overcome this gap, we investigated the impact of batch refactoring on five internal quality attributes i.e. Cohesion, Coupling, Complexity, Inheritance, and Size, that have received much attention in this field. The impact on the aforementioned quality attributes was measured using 19 different structural metrics that have been used in literature. Furthermore, we also explored how the impact of individual refactoring differs from the impact of batch refactoring on software quality in open-source software systems. For this purpose, we selected five open source projects consisting a total of 79,527 commits and 3,10,401 individual refactoring operations. From which, we identified 20,173 batches using range-based batch heuristics. We collected the structural metrics for each file before and after a batch was applied using the UNDERSTAND tool to measure the impact. Upon carefully analyzing the results, it was observed that batch refactoring negatively impacted all the five quality attributes. However, this negative impact was not statistically significant for all the metrics. Also, for the purpose of comparing the impact of individual refactoring’s with batch refactoring, we selected studies from the literature that studied the impact of individual refactorings using the same software metrics and research design (almost) as ours to have a common ground for the comparison. Our results of batch refactoring differ from the results of studies studying the impact of individual refactoring’s, on a number of metrics i.e. CBO, FANIN, FANOUT, LCOM, CC, WMC, RFC, Evg, NPATH, Nesting, CLOC, CDL, NIV, NIM and DIT. Despite of these differences, we also shared commonalities; for example, in our case RFC, NOC, IFANIN, LOC, and STMTC exhibited negative impact after batch refactoring, as these metrics exhibited in study studying the impact of individual refactorings. Furthermore, it was also observed that a large number of batches we identified were composed of individual refactoring’s that were observed to have a negative impact on software quality by previous studies
"Hira Sajid

An Efficient Data Enriched Resume
Information Extraction Approach for
E-Recruitment"	Modern approaches to improve networking and communication have given ways to the advancement of recruitment process through the development of e-recruitment recom_x0002_mender systems. The increasing expansion of internet-based recruiting has resulted in a large number of resumes being stored in recruitment systems. Most resumes are prepared in a variety of styles to attract the attention of recruiters, including different font sizes, font colors, and table formats. However, data mining operations such as resume information extraction, automatic profile matching, and applicant ranking are immensely affected by the variety of formats. Rule-based methods, supervised meth_x0002_ods and semantics-based methods have been introduced to extract facts from resume accurately, however, these methods heavily depend on large amounts of annotated data that is usually difficult to collect. Furthermore, these techniques are time-intensive and bear knowledge incompleteness that strongly affect the accuracy of resume parser. In this research, we present a resume parsing framework that handles the limitations faced in the previous techniques. At first, the raw text is extracted from resumes and blocks are separated using text block classification. Furthermore, the entities are extracted using named entity recognition and enriched using ontology. In addition, bloom filter is introduced in this study to optimize the lookup complexity of data en_x0002_richment module of resume parser. The proposed resume parser accurately extracts information from resumes that directly contributes towards the selection of best candi_x0002_date.
"Sarah Kiyani

Optimizing CV Artifacts Extraction
via Maximum Degrees Identification
for Ranking in E-recruitment
"	Currently, technological breakthroughs of electronic recruitment tools have gained much recognition due to their increasing popularity among recruiters. Many methods like Learn_x0002_ing to Rank (LTR) and Multi-Criteria Decision making (MCDM) have been employed inside these tools to enhance the process. The ranking module is one of its most im_x0002_portant modules on which these methods and techniques are applied. While the MCDM methods can be used efficiently to rank the candidates, they require much interference from recruiters for the data preparation process before starting the actual ranking process. This research work aims to automate the data preparation phase for MCDM input and optimize the process so that decision makers’ intervention is reduced to a minimal and accurate rankings are obtained within less time. This research work uses the problem of kMCV in hidden bipartite graphs to propose CSOE algorithm which automates inputs for any MCDM method
"Maha Kaiser

Evaluating and managing heart failure disease 
progression"	The heightened morbidity and mortality associated with Heart Failure is a major cause of concern around the globe due to its delayed diagnosis, and scarcity of effective treatment options. Heart Failure, being one of the types of cardiovascular diseases, is associated with its specific clinical risk factors and remedies. Exploring the domain of Heart Failure in terms of supervised learning approaches becomes even more crucial in terms of feature extraction and their ranking with respect to the target in prediction. Recent work of Davide Chicco and Giuseppe Jurman (2020) identified serum creatinine and ejection fraction as the two most relevant features in terms of association with the target of Heart Failure patient survival. The authors utilized the Heart Failure Clinical Records Dataset from Allied Hospital, Faisalabad and applied traditional biostatistical techniques and a combination of different machine learning classifiers. The current study, therefore, not only aims to validate the findings of the base paper, but also performs Heart Failure progression prediction with respect to ejection fraction and serum creatinine as the targets through correlation and regression analysis. Tree-based classification techniques of Iterative Dichotomiser 3, C4.5, and Classification And Regression Trees were also applied on the same dataset. Besides, classification rules obtained using One Rule and CN2 algorithms with focus on rule quality in terms of coverage and accuracy were identified. A priori algorithm was also implemented to identify the association rules and their relevant attribute metrics including the support and confidence of the rules. Based on the results obtained, a general conclusion drawn is that Diabetes, Anemia, and Gender has a key role to play in progression of HF when assessed with respect to both ejection fraction and serum creatinine, collectively. In this regard, a better representation is obtained through classification rules and the decision tree implementation that caters to both continuous and dichotomous features at once through CN2, C4.5 and CART, respectively. The prediction performance results also indicate higher accuracy obtained for CART followed by C4.5, and hence, can be effectively utilized to identify relevant features when it comes to HF progression. Based on these results, ID3, C4.5 and CART were also implemented on Z-Alizadeh Sani dataset to identify additional demographic features. The highest rank was obtained by Diabetes Mellitus, followed by Obesity, Family History, Hypertension, and Dyslipidemia. Keywords: Heart failure, data mining, rules mining, machine learning, classification, feature ranking
"Touqeer Nasir

Evaluating Erosion between Planned and Implemented
 Architecture: An Empirical Approach"	"Architecture erosion occurs due to unintentional and intentional changes that create deviation from intended architecture. Numerous research studies have identified causes that leads to software erosion such as Architectural style violation, Technical Debt, Re-requirements Changes etc. Technical Debt and Requirement change are two key issues of architectural erosion. Technical debt (TD) consists of implementation or design constructs
that are used to achieve short-term goals, but it makes future changes more expensive and almost impossible. The bad impact of TD is much severe, it unintentionally introduces erosion that effects in the long run of software development. Technical debt prioritization is a best way to determine which technical debt item to repaid first and which items are delayed until release. Prioritization of TD is difficult to handle and manage in software industry which helps to reduce erosion in software system. Relationship between technical Interest and Principal can help practitioners in prioritization of TD items. These two factors help to reduce erosion in software system while prioritizing TD Items. In this thesis we proposed a model for relating TD Interests and Principal. Our proposed model and implemented factors managed in the available data set are evaluated as erosion. We have also compared results obtained from our model with the results generated in the study [1]. We find out that size is most contributing aspect of TD that influences the erosion. We have also explored variance between aspects of TD interest and our results show that Coupling, Cohesion, and size have a similar strength of relation with TD Principal. These relations help to prioritize TD to reduce erosion in software system. We also explored that
Clumsy aspect of TD principle is most detected issues in all projects.

Keywords: Technical debt, architectural erosion, SDLC, Statistical analysis and eval-
uation, Planned architecture ."
"Naveen Khan

A Framework for Gathering and Classifying the Advanced Persistent
Threat from open source platforms"	In the era of modern technology, cyber attacks have evolved to advanced threads. These attacks are dynamic in nature and can easily bypass the traditional security systems. Advanced persistent threats usually target high-value data such as enter_x0002_prises, industries and governments. We should keep the firms acquainted with the risk of Advanced Persistent Threats. Open Source intelligence platforms, such as ahnlab, anomali, blog 360, checkpoint, crowdstrike, cybereason, dark-reading fireeye_x0002_apt-groups, fireeye-blogs, kaspersky, microsoft, mitre-attack, ncsc, palo-alto, recorded_x0002_future, sans, secureworks, talos, thales, threatrecon, trend-micro, are able to aggregate a large amount of security related information. To process the thread related informa_x0002_tion we needed an intelligence based system that could identify and squeeze out the related information about advanced persistent threats(APT). Existing researchers have worked on cyber threat intelligence by collecting and classifying the threat related data from different numbers of sources. We propose a framework that classifies and gathers the advanced threat information from open source platforms. Drawed out particulars of Advanced Persistent Threat can then be used in cyber threat intelligence solutions. Our framework has used a transfer learning approach, BERT to process the Advanced threats data. In the first step, the BERT classifier identifies the text that includes the APT related information. After that, the BERT named entity recognition(NER) model extracts the information related to APT from the relevant text. The proposed approach has achieved 99.73% accuracy and F1-score for classification task and average F1-score of 93.03% for NER task. Keywords: Advanced Persistent Threats, Advanced Persistent Threat Classifi_x0002_cation and Information Extraction, Cyber Threat Intelligence, BERT, Classification, Name Entity Recognition(NER
"Hunzlah Bin Saghir Lone

Self-supervised Exploration using Intrinsic
Motivation"	Reinforcement learning algorithms depend on the careful crafting of rewards that are extrinsic to the RL agent. Crafting hand-designed dense rewards for each environment is not possible. This motivates the need for developing a generic reward function that will be intrinsic to the agent. Intrinsic reward helps the agent to better explore the environment and accomplish the main objective specified by sparse rewards. Curiosity is referred to as intrinsic reward which uses prediction error to create dense rewards. This allows the agent to create intrinsic rewards for itself. These rewards bridge the gap between sparse extrinsic rewards and learning becomes much more stable. This kind of curious behavior is also found in animals where interaction with something novel could be rewarded as a bonus. The intrinsic bonus adds up to real sparse reward objective which makes it possible for RL agents to learn. We introduce a method which uses an ensemble of forward networks to calculate the intrinsic reward. Multiple intrinsic rewards are then normalized and averaged out to get the final bonus and finally provided to agent to improve policy. This will allow us to overcome the procrastinating agent issue faced in prior work.
"Tooba Tehreem

Chronic Kidney Disease Diagnosis using Image 
Recognition"	Chronic Kidney Disease (CKD) is a vital worldwide health threat. According to recent medical reports, over 697 million people are diagnosed with Chronic Kidney Disease (CKD) worldwide. In addition, the diseases that eventually turn into kidney cancer are the 10 most common cancers that occur in humans worldwide. Pakistan ranks eighth, affecting 12.5% of the population and 20,000 deaths annually due to kidney diseases. The existing tests and procedures for detecting Chronic Kidney Disease (CKD) are time-consuming and invasive that causes the spread of other diseases and not good for the patients. Traditional approaches use testing and diagnosis mechanisms available to us take a minimum of 24 hours to give results and are uncomfortable for the patient. Moreover, there is always a chance of error in them. The advancement in Artificial Intelligence (AI) has significantly substituted the method to explore and usage of the data. This can be leveraged in the medical industry, helping and facilitating the lives of many human beings. In medicine, Artificial Intelligence (AI) uses digital techniques to treat, diagnose and predict the results. In this paper, we will focus on using deep learning approach UNet model to segment kidney as well as tumor. In this study, we will implement a UNetmodel to extract features of Nibabel images to classify and predict chronic kidney diseases. Dataset publicly available for research purposes is used. We will target the dataset given to us in the KiTS19 Challenge Data where a library of multi phase CT imaging, segmentation masks, and broad ranging clinical end results of 300 patients is collected
"Atika Shahid 

Similar Feature Classification in Chronic
Kidney Disease Diagnosis using Machine
Learning Algorithms"	"Chronic Kidney Disease (CKD) is a long-term illness in which the kidneys fail to function properly. It means your kidneys filter wastes and draw liquids from your blood. It is termed ""chronic"" because it damages human kidneys over a long period of time. CKD have many symptoms over the period of time but has no obvious symptoms during the early stage of this disease, this cause the failure in the detection of the disease. Early detection helps timely treatment that can saves human life. This disease is more common is developing countries they have many advance technologies but they unable to detect this disease at early stage. There were many machine learning model that were used to detect this disease at early stage but they have certain limitations. In this study, I use a data contains 400 patients and 24 features a that are related to the diagnosis of CKD. Many research also uses this publicly available dataset to detect CKD. The basic approach of this study is to use similar features that are the main causes of this disease, based on this feature classification I will make groups of those similar features using some techniques of machine learning, after making groups the process is to check which group is at highest ranking, those groups who have highest rank I will be using that for my study. After that I will apply some hybrid machine learning techniques for further experimentations to detect CKD at early stage."
"Muhammad Moiz Ullah Satti 

Semantic Based Customer Review Classification through
 Machine Learning Techniques"	E-commerce business exhibits drastic advancement in modern information technol_x0002_ogy. To improve performance of e-commerce business it is necessary to examine the customer review to understand their opinion about product. The proposed SRrC in_x0002_corporates polarity time series analysis of customer review for realistic rating. The proposed SRrC utilizes polarity time series data for modelling classifier. Those time series polarity are customer review those are incomplete or not able to understand their view about product. Through those review product quality is not able to catego_x0002_rized properly.This research concentrated on semantic based model for classification of negative and positive review. This research aimed to classify positive and negative customer review for realistic data about product. To perform review classification this research proposed a SRrC (Semantic Realistic rating Classifier). The proposed SRrC is examined with five classifiers that are Support Vector Machine (SVM), Random Forest (RF), K Nearest Neighbours (KNN), Logistic Regression (LR) and Multi-Layer Percep_x0002_trons (MLP). With polarity time series data, dataset for classification is processed. The data for analysis considered is collected from Amazon website for appliances. The performance of proposed SRrC is examined for SVM,RF,KNN,LR and MLP classifier for classification of positive and negative review. The proposed SRrC training accuracy measured for proposed with RF is 0.96, precision value of 0.96, Recall value of 0.96 and F1-Score value is observed as 0.96. In case of SVM classifier accuracy is measured as 0.68, precision value of 0.63. recall value of 0.71 and F1-Score as 0.71. The com_x0002_parative analysis expressed that for proposed SRrC provides significant performance with both classifier in training. RF exhibits superior performance. It is concluded that proposed SRrC with RF exhibits significant characteristics for training. The testing accuracy measured for proposed SRrC with RF is 0.70, precision value of 0.69, Recall value of 0.68 and F1-Score value is observed as 0.68. In case of SVM classifier accuracy is measured as 0.68, precision value of 0.63. recall value of 0.71 and F1-Score as 0.71. The comparative analysis expressed that for proposed SRrC perform effectively with both classifier exhibits significant performance in testing. The accuracy and precision measurement of RF is higher than SVM. In case of Recall and F1-Score performance of SVM is higher than that of RF. Keywords- Semantics, Realistic Rating, Classifier, SRrC (Semantics Realistic rating Classifier), Support Vector Machine (SVM), Random Forest (RF)
"Syed Ans Shah

Human Activity Recognition from Streaming Sensor
Data"	Smart Homes are attracting a great deal of attentions recently because of the recent COVID-19 and its promising application in aged care where privacy is the major concern. HAR system provides assistance for elderly people and people with disabilities. Elderly people are not very fond of wearing the smart gadgets or wearable sensor devices to help monitoring. In this research, we have proposed new approach of HAR using ambient sensors placed at different places of smart homes that will assist on monitoring, detection and recognition of elderly resident with real-time support. In this approach. Data streams from sensors will be segmented out based on 4 types of windows, Fixed Sensor, Fixed Time, Sliding Sensor and Sliding time_x0002_based windows segmentation. Then pattern and correlation of these windows is analyzed using K-means and Fuzzy C-Means. In the end, we identify the activity and classify it using deep learning classifiers and find the accuracy. Deep learning classifiers includes Convolutional_x0002_Neural Networks, Recurrent-Neural Networks, MLPs. The proposed methodology is applied two main datasets, CASAS and ARAS. We have achieved 95% accuracy in CASAS and 81.4% in ARAS dataset
"Usman Kaisser Moghal

Interactive Neuroevolution: Human Driven GANs-based
 Data Augmentation using Neuroveolution"	"Generative Adversarial Networks (GAN) have become very popular as of late in various fields, specifically computer vision. Several new methods have been discussed and implemented. However, despite this rapid development, GANs still have some issues. Specifically with regards to training the generator. In this paper, a novel approach into training GANs is discussed utilizing Neuroevolution coupled with human feedback. Neuroevolution is the involvement of a Genetic Algorithm (GA) to improve the training of a GAN. Here, the GA is specifically used for improving the generators training
process. Based off of recent studies, introducing a human observer to interact with and accommodate the training process of neural networks, has shown to produce positive results. In this paper, we intend to use a similar method for improving the training process of the discriminator. One of the potential methods is the Two-Alternative Forced Choice (2AFC). The idea is essentially to inject human interaction into the training process of the discriminator. In certain domains, a human’s ability to discern is greater than typical AI, and adding this to a GANs training process can greatly skew the
results towards higher accuracies. Within a network, certain weights influence the results more than others. Within this paper, these weights (“Golden Indices”) are calculated and exploited. The resultant framework of combining neuroevolution and human interaction with a GAN, while utilizing “Golden Indices” should produce a better solution for most domains, with regards to improving the networks training process, particularly with small or bad datasets. Moreover, such an approach would be generic."
"Muhammad Hamzah Mushtaq

Patient Re-admission prediction based
on Discharge Summary text sentiment using Machine
 Learning"	Patients unplanned hospital re-admission leads to waste of hospital financial and med_x0002_ical resources. With the advent of Machine Learning, various methods have been im_x0002_plemented in order to reduce patient re-admissions for the better good of patients as well as hospital itself. Medical documents like Discharge summaries (DS) hold crucial medical data about patient stay in hospital. e.g. data regarding patient’s diagnosis, pro_x0002_cedures, encounters, lab tests and results, each recorded during the stay of the patient in hospital for treatment. This unstructured data can be utilized to study the patient health trends. Predicting whether patient will be readmitted within the next 30 days is an informative process which would help reduce medical cost and hospital work. Classifying the DS text based on sentiment polarity can help us determine the medical status of that patient. Sentiment analysis and text classification have progressed too, but a little focus is put on work with medical data.This research proposes a new ap_x0002_proach that (1)collects sentiment polarity of each section within Discharge summary in order to gain individual importance, (2) on the basis of collected sentiment polarity predicts patient re-admission within 30 days
"Muhammad Adnan Ejaz

Deep Learning based Advance Stages
Classification of Diabetic Retinopathy & Diabetic 
Macular Edema"	Diabetic retinopathy (DR) is one of the major reasons for blindness and blurred vision in patients with diabetes. Due to high blood sugar levels, it develops slowly in the retinal area of the eye with no prior symptoms. DR damages the retinal vessels due to which these vessels become abnormal and start to leak the blood in the retina. As a result, diabetic macular edema (DME) develops as blood or leaked fluid damages the macula which is the part of the retina and is responsible for the vision. A person has a high chance to lose vision if the macula gets damaged. Complete stage wise classification of DR and DME based on their severity level is a difficult process due to the complex vessels and retina structure. Many techniques have been proposed that involve machine learning, image processing, and deep learning but there are limita_x0002_tions of these techniques as some techniques just focus on either one of the above two mentioned complications. Some methods used a very small size of datasets using deep learning algorithms. While some researchers have just worked either on the detection or the classification of DR and DME. But almost none of them considered both DR and DME to investigate their relationship, detection, and stage-wise complete classifi_x0002_cation. To address these problems, I have proposed a technique that uses three deep learning network models including VGG16, Inception ResNetV2, and ResNet-152 to investigate the co-relationship of DR and DME and complete stage wise classification of both DR and DME using annotated datasets. This technique involved the steps of fundus images data acquisition, preprocessing of the images, data augmentation, fea_x0002_tures extraction of both DR and DME using convolution neural network. After that, network model is trained and classification is done. Four datasets including IDRiD challenge dataset, Messidor-2, Kaggle DR dataset, and Kaggle DR detection competi_x0002_tion resized images dataset have been used here. Accuracy has been used here as an evaluation metric. VGG16, Inception ResNetV2 and ResNet-152 achieved an accuracy of 74.04%, 73.05% and 74.18% respectively which is better than results gained by pre_x0002_vious study in this domain 65.1%. All abnormal signs have been considered here for the accurate severity level based classification and also new fundus images based data has been collected in this study which will be used in future studies in this domain.
"Mahnoor Aftab

Evaluating the Impact of Gamified Quranic
Learning Mobile Apps forChildren"	In this era, the use of technology is increasing day by day as it is helping in daily life issues in lesser time. In an educational context, the technology helps in gaining the information and sorting out the issues easily and with authentic and correct information. The kids these days prefer using technology more than any other medium of learning as it attracts them and allow them to access things according to their desire. The games attract the users with their unique features which motivates them to play more and feel great by achieving victory in the games. Many researchers have incorporated gamification in educational application to enhance the value of such applications and to attract students to use the application which in turn enhance their learning performance. Researches have targeted different age group and subjects in different applications by using gamification to attract students and make it useful for them. This research focuses on kids learning Qaida applications which involve gamification so that kids can have more attraction and interest in learning the most important Islamic religious book Quran. The comparison of different game elements which impact the learning performance in m- learning applications can help in making a prototype of Gamified Quran application which will comprise of such elements which enhance the learningperformance of a student
"Mirza Danial Masood

Skin Cancer Detection using Deep Learning"	Skin Cancer now becomes a challenge in the field of medical science and computer vision. Now, most of the medical specialist is depended on the computer and artificial intelligence for detection and treatment of the disease in the human body. Melanoma is one of the major skin cancer and cause of most death in recent years. Day by day, cancer mutates itself by changing its structure and becoming more dangerous. This mutation also crating the lack of large datasets and other resources which make the detection and classification purpose more difficult and challengeable. In this research, we have proposed an advanced approach for detection purpose by using some advanced image processing steps and image classification techniques. The HAM10000 dataset, a large collection of dermatoscopic or skin cancer images were used for detection purposes. A strong preprocessing process followed by applying hair removal image processing and UNet-segmentation. GAN was used to balance the images in the dataset to kill the imbalance in the dataset by leveling of minority image classes to majority image classes. Transfer learning applied by using five state-of-art pre-trained convolutional neural networks for prediction. Keywords: Deep Learning,detection
"Sara Irfan

Identification of Fake Tweets using Deep Learning 
Techniques"	"Social platforms exchange information by people living in various places. Twitter data is mostly used for the largest micro-blogging platforms, research, political, and business platforms. The malicious information is spreading among the users and to overcome this issue, a large number of tweets have been carried out. The main focus of the research is to gather the tweets related to different universities of Pakistan and identify the fake or non-fake tweets because there were a lot of tweets against different universities of Pakistan during the pandemic situation of Covid-19. The analysis has been performed on real-time data for detecting fake tweets by deep learning techniques. Automated classification of its detection is a challenging task. We explored variant textual properties that can be used to distinguish fake tweets and we worked on Twitter identifying Twitter users. Previously used algorithms like Synthetic Minority Oversampling Technique as SMOTE, SVM-NN, CNN, Naive Bayes, and BERT model have been used in finding fake accounts. The data have been scrapped from Twitter using a hybrid approach taking into account the TWINT library and TWEEPY so that the entire information of a person can be attained which helps identify whether the tweets are fake or not. The collected data-set was pre-processed with the seed features. The features have been used with comments of a person on the tweet, sources, average replies, average retweet, average tweets per day with the unique hashtags. Then data has been encoded and decoded to exclude the emotions and other useless symbols. The sentiment analysis has been performed with VADER without using target labels and generated subjectivity and polarity with a type of sentiment. These generated sentiment types have been used in BERT and Fast-Text embeddings, SVM and Naive Bayes have also been implemented. The BERT-HAN model has been implemented with improved 95% accuracy, The results have shown that the BERT-HAN has performed much better than other results.
Keywords: Deep Learning, EDA, Twint Library, Tweepy Library, BERT-HAN state
of art"
"Muhammad Waleed Usman

Medicine Side Effects Identification Using Twitter"	"Before introducing a drug in the marked significant amount of trials are being per- formed, Yet it is difficult to discover all the side effects for any approved drugs. With the growing development of social networks like Twitter have resulted in the booming of the massive public data. Recent research has shown that Twitter data analytics can have broad implications on public health research. However, this created a problem with reliability and credibility of the information being spread to the masses.In this proposed work, an effective computation approach is proposed, which uses simple
drug-related classification to extract side effects of drugs by focusing on the user re- views. Our approach involves the use of machine learning techniques and state-of-the- art natural language models to determine side effects of medicines from social media information. We collected raw tweets for these medicines, Then these tweets were re- fined using pre-processing and normalization techniques. These cleaned tweets were further selected smartly using sentiment analysis. As our problem has more concern with negative or neutral tweets. After having the refined tweets features were extracted using more than one technique among which Enhanced TF-IDF gave the best results. These Enhanced TF-IDF features were further refined by using pretrained BiLSTM. Using these features we trained more than one model to get the best results we could, where FastText Model provided the best results. All of these models were trained, tested and validated using others Datasets as well, such as SIDER Database and Aska- patient Database. We calculated precision, recall and accuracy for all three models among which FastText provided Accuracy of 91%. Keywords: medicine side effects, text mining, health social media analytics, machine learning, deep learning, Fasttext, Name entity Recognition(NER), adverse drug reac-
tions"
"Alyshai Nadeem

A Machine Learning-Based Game Recommendation 
System"	In today’s age of information and technology, it has become increasingly difficult to manage large amounts of data and information. However, such systems exist that can help filter the data, analyze it and generate useful results. Commonly called Recommendation Systems, they can be termed as a subclass of information filtering systems, which are often used for commercial purposes. Recommender Systems assist users with the decision-making process. Such systems have been utilized by various media giants, e-commerce platforms, and social media websites. Recommender systems work by saving the preferences of users to generate useful information that can be utilized. The past few years have seen an increase in the sales of Indie Games, where such games have blossomed without large budgets and support from renowned studios or publishers. Indie or independent games are typically developed without financial or technical assistance from large publishers. Current recommender systems mostly focus on popular or mainstream games. Moreover, such a system also does not consider cold-start users. The following research proposes such a recommendation system that utilizes existing ma_x0002_chine learning-based approaches, combining them to create recommendations based on user preferences, demographics and other common variables. Such a system will help users find games that suit their preferences, allowing Indie developers to gain exposure by helping them target their games to the correct demographic. Moreover, the proposed recommender system aims to solve the problem of cold-start users and create a machine learning-based approach to handle this issue. The system will filter information, generate viable results and produce valuable recommendations for the users based on existing games and promote new releases
"Syed Muhammad Jawad Ul Haque

Video Game AI: An Intelligent and Interactive Learning 
for AI Agents"	"Reinforcement learning is a good approach for enabling the AI agent for autonomous gameplay in the video game environment, which is one of the major focus in the current research era. An agent performs an action in a certain state, and most games have tokens or something similar that can be used to generate a reward signal for that action performed in that state. This kind of technique is referred to as SARSA (State Action State Reward Action). A SARSA agent communicates with the environment to understand the policy as a result of the actions done; this is referred to as on-policy learning. A state-Q action’s value is updated by an error, which is modified by that of the learning rate alpha. Q values reflect the potential reward obtained in the subsequent time step for doing action an in state s, as well as the future reward gained from the subsequent state-activity observation. In SARSA, an agent in a given state performs an action and then that action is evaluated on the basis of the reward defined for it. Then on the basis of the reward gained, the agent chooses it action to perform better or to continue its game play. Normally the behaviour of Non-player characters (NPCs) is not something the game developers focus on. Q-learning is a reinforcement learning technique that is used to determine the worth of an action in a given condition. It does not need a model of the environment (thus the term ""model-free""), and it is capable of dealing with challenges involving probabilistic shifts and rewards without the need for adaptations. Reinforcement learning is comprised of an agent, a collection of states S, and an action set A for each state. The agent changes from one state to another by completing action A. Performing an action in a certain state rewards the agent (a numerical score). The agent’s objective is to maximise its overall benefit. This is accomplished by adding the maximum benefit that may be obtained from upcoming states to the reward for attaining the present state, essentially impacting the current action via the possible future reward. This potential reward is an average of the predicted values of all subsequent steps beginning from the present condition. We propose a reinforcement learning based framework that helps in learning agent and interaction with the environment to improve the performance. We have chosen the PacMan for this purpose in which we will train the PacMan for autonomous gameplay. And then, this behaviour can be mapped to NPCs for making their behaviour better. We have experimented on Pacman that generated Q values, rewards and exact timing with location of taking power pill to fight against the enemy. Along with this, the model captures the behaviour of NPCs automatically at a particular time when they strongly needed to be added in power play. The proposed deep Q learning based framework outperformed the CNN based approaches by achieving significantly better accuracy rate in terms of autonomous gameplay."
"Muhammad Shahab Mujahid

Optimal Virtual Machine Selection with Energy 
Efficiency using Swarm Intelligence"	With the expanded usage of cloud computing, cloud service providers constructing large data centers in order to get benefit from its services. An immense increase in energy consumption arises simultaneously with increased cost of operating systems and cooling servers. Optimal VM selection is considered as one of the most quality so_x0002_lution to manage energy efficient VMs. During optimal VM selection minimum energy consumption, with reduced makespan and resource utilization is a critical issue which needs to be addressed. This paper proposes a new idea of Optimal VM selection using swarm intelligence approach known as Hybrid Particle Swarm Optimization (HPSO) which operates in a cloud computing environment. We compute three parameters in order to find optimal VM i.e. Efficient energy consumption, reduced makespan and high resource utilization. Many experiments have been performed to analyze the results generated using our proposed algorithm HPSO. The results shows that our approach outperforms in terms of efficient energy consumption which is reduced in comparison to other algorithms. Also, the execution time is reduced with the higher number of resource utilization
"Ayesha Kamran Ul Haq

Information Extraction and Story Representation
 from Stories"	The data in its original form is utterly worthless because it contains no useful in_x0002_formation. It is critical to comprehend narratives in many advanced fields, such as business, law enforcement, and many other applications. A story is also a type of text data that follow a sequence of events which contain entities like characters and their relationships. we proposed a system where information extraction from any form of unstructured story is now available without any heavy training. It utilize our resources as we used already pre-trained models to sum up the extraction process. After infor_x0002_mation extraction, it is representing it in the form of graph. Graph structure assists in visualizing the text for any lay man. We used fairy tale for demonstration purpose. The main contribution of our proposed system is evaluation metric of the graphs con_x0002_structed from unstructured story by extraction all important components from it. For evaluation, we translate the graph into text, which might be identical to the original or semantically comparable. We do the process using pre-trained transformer model (T5) and matches the contextual similarity using ROUGH and BLEU score. We use 4 variations of built-in transformer models that is ”k2t Mode”, ”k2t-new” ,”k2t-base” and ”T5-BASE-FINETUNE-COMMON GEN”. T5-BASE-FINETUNE-COMMON GEN gives the high BLEU score of 85%. and k2t-base models gives the 60% precision.
"Waqar Ur Rehman 

Opinion Mining for Electoral Mandate Support"	The prevalence of micro-blogging and social media has generated huge amounts of data in recent years. With more than two billion people using social media and micro-blogging websites it is hard to comprehend the amount of data being generated on daily basis. Most of this data is typically personal opinions, emotions, activities and comments. This provides an opportunity to better understand how people think and behave over a certain event. Understanding opinions is rather important for a certain group of people such as politicians, business owners, service providers and a few others. We have seen that a lot of work has already been done in the field of opinion mining using various datasets. In this research we aim to perform opinion mining for political mandate design. Our main focus will be to identify the major impact factors that can help political parties, running governments and political candidates to design their mandates as to help the general population. We have used techniques of rule-based analysis with TextBlob, Vader and SWN analysis. We came up with a conclusion that these techniques gives good results on raw data
"Shah Saood Khan

Detection and Classification of Alzheimer Disease 
Using Deep Learning"	Neurological disorders are a set of disorders in which the brain and human nervous system are affected and thus it results in a wide range of symptoms. One such neurological disorder is Alzheimer’s disease (AD). With the progression of this disorder, the affected person loses concentration and thinking capability and leads to dementia. The most common and gen_x0002_eral form of dementia is considered to be AD. When an individual reaches a moderate stage then the detection of AD is accurate. To detect, diagnose and categorize Alzheimer’s disease (AD) in the initial stages is vital to prevent its progression and make sure its treatment. The early-stage diagnosing of AD is a tough task. There have been various studies to detect AD which include methods like machine learning (ML) and advanced methods like deep learn_x0002_ing (DL). With the increasing demand and growth of deep learning approaches, it is possible to classify, extract high-level features. Thus in turn it gives us the advantage to accurately di_x0002_agnose AD patients within a short period. Deep learning approaches, frameworks, and meth_x0002_ods with high prediction accuracy based on various covariates and classes such as CN, MCI, EMCI, LMCI, and AD, demented and Non-demented, etc. need to be included to provide a more personalized experience for patients, specifically AD. The following research will focus on creating a recommendation framework and method based on deep learning principles and techniques that provide detection, categorization of AD early to patients. The approach will be catered towards AD subjects and will take into account multiple factors that may implicitly or explicitly influence AD subjects
"Muhammad Fahad Saleem

Detection of Covid-19 pneumonia and Non-Covid-19
pneumonia using Deep Learning"	Covid-19 is a new kind of coronavirus that has emerged in 2019. It started spread_x0002_ing worldwide, pushing healthcare institutions to the brink of collapse, with the World Health Organization designating the outbreak as a pandemic on 11 March 2020. Severe Acute Respiratory Syndrome Coronavirus 2(SARS-CoV-2), known as Covid-19, infects the lungs causing respiratory problems and pneumonia. Covid-19 spreads rapidly, so it is crucial to detect it quickly and accurately using less time taking techniques. Arti_x0002_ficial intelligence (AI) has earlier proven beneficial in biomedical research. AI models use radiology images acquired from medical imaging to detect Covid-19. Numerous research organizations are working on detecting Covid-19 and have proposed various machine learning and deep learning methods. However, the research works had false_x0002_positive cases of Covid-19 pneumonia, where Non-Covid-19 pneumonia cases were wrongly diagnosed as Covid-19 pneumonia and vice versa. Our research aims to effi_x0002_ciently and effectively diagnose people with covid-19, viral and bacterial pneumonia. Chest X-ray images of patients contain unique features that can determine whether Covid-19 pneumonia and Non-Covid pneumonia are present in them. Our proposed architecture initially aggregated the dataset from three different sources and then ap_x0002_plied pre-processing steps to clean the data. The scarcity of chest x-ray images of viral, bacterial, and covid-19 pneumonia resulted in imbalanced datasets, so we have done data augmentation to balance the images in all dataset classes. We have gener_x0002_ated synthetic CXR images to cope with the data imbalance problem. We have then segmented the parts of chest x-ray images incorporating lungs. The segmented im_x0002_ages were fed to the state of the art deep learning classification models to diagnose the disease. We have applied efficient and appropriate deep learning algorithms on the aggregated chest X-ray image dataset, out of which DenseNet201 gave 93 percent accuracy delivering promising results compared to related approaches. Keywords: Covid-19, Pneumonia, Artificial Intelligence, Augmentation, Segmentation, Deep Learning, Chest X-ra
"Aamna Mohsin 

Detection of Autism Spectrum Disorder using Deep
 Learning and fMRI Data"	Autism is a brain disorder that impacts the person’s ability to interact, communicate, behave and learn. People suffering from ASD are mostly not physically disabled but they have slow learning capacity as compared to others. For detecting autism, doctors look at the child’s behavior or ask parents to fill a questionnaire about their child’s development which may require prolonged diagnosis time and have increased medical cost. There is no such cure of ASD but researches show that early intervention can boost a child’s overall development. Researchers have widely employed machine learning algorithms based on brain imaging data like functional Magnetic Resonance Imaging (fMRI) to diagnose Autism. Many approaches have been presented to detect ASD using DL algorithms with different biomarkers and datasets but these researches were limited as in most of the studies data of participants under 4 to 5 years’ age is not included therefore these studies do not involve the early intervention of Autism. Therefore, the basic aim of this study is to detect Autism at an early age of 18 to 24 months using combined MRI scans and phenotypic data to bring some positive change in the lives of children suffering with Autism and their parents. The proposed approach includes three steps; the first step includes creating a functional connectivity matrix between ROI pairs of brains. The second step will include incorporation of phenotypic data with fMRI information and feeding it to a classification model. In the third step ASD patients will be classified from control subjects using proposed architecture.
"Sumayya Rahman

Security Verification of Smart Contracts"	The smart contract is a set of promises and protocols that are executed in our computer systems through which the parties perform the other promises. Smart contracts are used in different domains such as the internet of things, healthcare, finance, and so on. Smart contracts can execute the business using rules, coding, and algorithms in different domains. The advantages of the smart contract exist; however, they came on price. Safe and secure smart contracts are difficult to write due to the diversity in the business logic, human errors, and vulnerabilities in platforms and languages. Every language is prone to vulnerabilities in the code, which is one of the biggest reasons that arise the security issues in smart contracts. Various vulnerabilities exist in the smart contract like reentrancy, mishandling exception, missing return statements, and so on. Various vulnerabilities launch attacks in the smart contracts which include decentralized autonomous organization, parity wallet multisig, and parity wallet freeze attack. One of the major features of the smart contract is that it is decentralized which means it is stored and executed by all the peers due to which the risk is launched at a larger scale. We can’t patch the contracts when it is deployed in Ethereum due to which after deployment we cannot remove the risk that is caused by the contracts. The most widely used language for smart contracts is solidity which includes functions, states, events, addresses, and values. The emission of the events is dependent on the state change of variables and variables setting that is represented as temporal properties. When the state is changed single or multiple times, can cause the emission of events and if it is not properly examined it can cause serious consequences. The processing of events is not thoroughly explored in the contracts. To address the issues in the smart contracts; we design an approach that is based on formal logic, that is used for the verification of the events. We have developed a tool that automates the verification of smart contracts. Our tool mapped events and variables into the Event Calculus model, invoke a DECReasoner, and based on the results the developers can verify the event emission. We represent the model based on the use case like ERC20 token and Ballot event. We have designed different test cases for the evaluation of Event Calculus models. The test cases check the scalability, effectiveness, and practicality of our approach. We evaluate the test case for the verification of events when the variable is changed in the smart contract. We consider 25 events with each containing 2 variables. The graph concludes that the solution and encoded time are increased with the increase in the number of events. The larger number of events is the depiction of the larger problem set that is addressed in the smart contract. We conclude that our model is effective in evaluating the single or multiple emission of events
"Aneeqa Tariq

Formal Approach to Identify Redundant Authorization 
Policies in Cloud"	Cloud Computing is the distribution of different services including networking, database, servers, data storage, and software. The Cloud provided the services like Storage, Computation, and Communication. The most widely used Cloud Providers are Microsoft Azure, AWS, IBM, and Google Cloud Platform. One of the critical issues in the adoption of the Cloud is security which becomes the most prominent challenge as it is difficult to enforce security principles. Different Cloud providers are using multiple advanced security mechanisms to implement security principles; one of them is policy. A lot of research work is done on authentication in the Cloud but authorization needs to be more explored, that’s why it is very important to address the issues related to authorization policies. All the major Cloud providers have authorization policies for access controls but still, security breaches occur which can lead to the loss of trust revenue as well. Authorization policies exist in the Cloud and the conflicts between these authorization policies also exist. However, not all conflicts are addressed in the Cloud, redundancy is one of them. We have presented the formal approach to identify the redundant authorization policies in AWS. We have developed a tool that automatically designs a model of Event Calculus and runs on a reasoner for the detection of redundant policies. The DECReasoner provides the results that are analyzed to check the redundant authorization policies. For the evaluation of Event Calculus models, we have created different test cases to check the practicality of the proposed solution. We evaluate two different test cases to analyze the performance evaluation of redundant policies. From the graph results, we conclude that the performance evaluation is acceptable when we consider maximum policies. We detect redundancy in both the test case scenarios. In the first test case scenario, we detect the redundancy with 2 policies whereas, in the second test case scenario, we detect the redundancy with a maximum of 5 policies
"Maria Tariq

Identification of Micro-services using Business Processes"	Monolithic systems become difficult to maintain over the time as they are one single unit with highly coupled and interdependent components. Migration of large monolithic systems to “Microservices” architecture is a growing trend as it increases maintainability and scalability of software systems. Rather of encapsulating all functional capabilities in a single monolith, microservices design encourages the use of several small-scale and independently deployable microservices. Similarly, decomposition of a monolithic system into a several candidate microservices, which is considered to be an extremely challenging task, plays a crucial and an essential role in the formation of microservice_x0002_based systems. To migrate monolithic systems into microservice-based systems different techniques such as software architecture, interface analysis, and many other tools are used. These approaches work on the basis of code, log races, and many others. Every approach has its own benefits/limitation and require additional efforts of human which could be erroneous. In literature, Business Process Models (BPM) are also used for identification of microservices; Business Processes (BPs) are the rich reservoir which consist of set activities that are performed in a process and explains the details like who does what, when, where, and why. In Business Process Modeling Notation (BPMN), there are several elements that may be used to identify microservices such as Gateways, resources, pools, data objects and many other. Existing literature mainly considers data dependencies and structural dependencies and all BPMs not consist of data objects, so finding data dependencies in every BPM model will be challenging. This paper highlights the microservices by elaborating their automatic identification from a business processes model by taking into consideration resource and structural dependencies among activities. The objective is to breakdown business processes into loosely coupled elements which are called microservices. The suggested approach tool is confirmed through elbow method which are then identified and confirmed from the domain experts. Additionally, accuracy of different approaches for identifying microservices is compared with experts identified microservices. The results demonstrate that the accuracy of proposed approach is equivalent to the expert evaluation approach.
"Sumbal Ilyas

A gamified platform for requirements elicitation"	The requirement analysis phase is one of the most significant phases of the software development lifecycle as a requirement is identified and finalized in this phase. Although different factors influence the quality of requirements, one of the key factors is the involvement of stakeholders. Other than the traditional requirement elicitation techniques various new techniques have been proposed to maximize stakeholder involvement. The requirement elicitation phase requires communication between people as they are from different backgrounds, skills, and statuses. One of the most effective ways to maximize stakeholder involvement is through gamification. Gamification-based requirement elicitation techniques involve and motivate stakeholders resulting in more requirements. However, one of the primary issues with this activity is the lack of communication [1] and coordination amongst various stakeholders. In this research, a web-based gamification platform has been proposed which will focus on communication during the phase of requirement elicitation. A survey on game elements used in gamification of requirements elicitation has been conducted. Existing gamification-based techniques [2]– [8] focused on some specific game elements that are mentioned in Table 3. We propose a gamification approach to elicit requirements by using game elements such as performance graph, unlock content, renovation, immediate feedback, rewards, and discussion forum. To validate the effectiveness of gamification we performed a control experiment and analyzed results.
"Adnan Jelani

Tackling Premature Convergence Of Multi-agent 
Systems In Cooperative Co-evolution"	Cooperative coevolutionary algorithms (CCEAs) and Genetic Algorithms, in general, have the tendency of converging prematurely. The main focus of this research is to find a way to tackle the well-known problem of premature convergence which comes with co-evolution. In literature, basic Novelty search and different variants of the CCEAs are presented. They perform better than the basic CCEAs, However, the focus is more on finding novel solutions which leads to just promoting the individuals who are novel in the behavior space. The exploratory nature of the previous approaches is a good way to find novel areas in the search space but it can also take more time to find the solution, In this research, a framework has been proposed which consists of Novelty Search (NS) using team level behavior characterization and Deep Reinforcement Learning (Deep RL). The best of the solutions from each population is used as a critic in the reward-based system. The remaining individuals learn from the best and the archive of the novelty search is updated accordingly. In the subsequent generations, the archive already has better individuals, which optimizes the search process of finding new and better solutions with more diversity. Extensive testing and simulations have been conducted to assess the performance of the proposed framework. The tasks include two variants of predator prey pursuit, sheep herding, and the cooperative multi-rover task of collecting items. Increasing the diversity within the population and using Deep RL helped the weaker individuals to perform better. Significant improvements have been made in comparison with the state of the art approaches. Keywords: Multi-Agent System, Co-evolution, Heterogeneous Systems, Cooperative co-evolution, Deep Reinforcement Learning
"Usama Ahmed Bin Ashraf 

Traffic Sign Recognition under Challenging Conditions 
with Deep Learning."	Autonomous cars are the future of Transportation, and they are in their developing phase, and there are many challenges they face, i.e., technological challenges and public perception. The challenge of public perception rose because of the possible dangers that autonomous vehicles pose, and the risks posed by these vehicles are dependent on technological challenges. Technological challenges include all the processing that an autonomous car incorporates, including traffic sign recognition, object recognition, road lane detection, pedestrian detection, environment mapping, etc. Traffic sign recognition is an integral part of autonomous cars, which helps the car recognize different instructions, warnings, and directions. Autonomous cars need much assistance in every aspect that humans do effortlessly. One aspect is the detection and recognition of traffic signs. Much work has been done in this field to automate cars’ decision-making based on the symptoms present on roads. However, there is still much room for research in this field, including traffic sign recognition under challenging conditions, i.e., haze, snow, rain, dirty lens, etc. So, this research will be focused on recognition of traffic sign recognition under challenging conditions. The proposed approach includes three steps; the first step will detect traffic signs and the type of challenge, i.e., rain, snow, haze, Gaussian blur, etc. The second step will include a de-noising network. The third step will be to take input from the de-noising network, an image with reduced noise, and detect and identify the sign type
"Sadia Naseem Khan

A Framework for Detecting Toxic Player Behaviour"	The gaming industry has seen a major boom in the last few years. With the advancements in multiplayer online based games we have seen the community get together in numbers never seen before. With this merger of the gaming community on a global scale, comes the drawback of harassment and cyberbullying. While it is relatively easier to ignore or rebuke people in real life, the internet is different. It is very possible for a 10-year-old child to be paired with a 30-year-old adult in a game, engaging in conversation etc. When you multiply this to the sheer scale of online multiplayer games (DOTA2, COD, CS:GO, Fortnite etc.) with hundreds of players per match, animosity does come up. This often leads to cyber bullying in one form or another. Companies have tried to stop this. Some games temporarily or permanently ban players with aggressive behaviour while others have no control of their player base. Our work is focus on targeting these players. Players with “Toxic” or undesirable behaviour. If we can identify them earlier on, we will be able to prevent them from acting out towards other player and ruining their online experience. Our approach will be based on identifying key personality traits of players beforehand. This will be done through sentiment analysis on their chats logs, this will include data gathered in past matches for a said player or even during the span of a match. We will then try to identify what certain markers or key-phrases we must look out for, for a said player, to avoid or even predict toxic behaviour.
"Muzhar Nazik

Recognition of Daily Activities Performed by a Smart 
Home Resident"	Human Activity Recognition has grown important in the assisted living field due to the significant growth in the population of older people. Smart homes enabled remote health monitoring of older people and patients. This work presents the recognition of daily activities performed by a smart home user, using pre-segmented activity data first; deep features are learned and fed into the SVM one vs. one to overcome the chal_x0002_lenge of less inter-class and higher intra-class variations. A Comparison between deep features, Information Gain, and Minimum Redundancy Maximum Relevance shows that the deep features perform better than the handcrafted feature selection methods, which shows the significance of our work. The proposed work demonstrates the im_x0002_proved recognition accuracy and F1-score for smart home inhabitant daily activities. The proposed technique was tested on the CASAS project’s publicly available Aruba and Milan smart home dataset. Keywords: activity recognition, deep features, smart-home
"Khalil Asghar

Secure and increase the Performance of Distributed SDN
Controllers using Blockchain Based Trust mechanism"	As internet size grows with the increase in communicating devices, networks will become more complex and more difficult to manage. Many experts require to efficiently run and manage those networks. SDN is a new emerging technology that facilitate the network ad_x0002_ministrators and manager to manage extremely large networks very easily. SDN consist of data plane and control plane. Data plane is also known as forwarding plane where different communicating devices transfer information according to the flows rules that are defined by the network manager/network programmer. Flow rules are defined at the application plane. At application plane we also define policies and network security procedures. Control plane which is the intelligent part of the network as we can say it is the brain of the network. In the traditional network, we replace routers with SDN controllers. Network programmer can program and define policies for the network traffic using the application plane via north bound APIs. As all the configurations are save in the controller, it control whole network. So, it will also increase the security problems for SDN controller. It is the single point of failure, network congestion and bottleneck, also it will increase the threat vector. So, there is a need to distribute the management functionality of the controllers using distributed multiple controllers. Controllers communicates with other controllers or controllers syn_x0002_chronize using East-West APIs. One possible solution is to decrease the threat vector to use the multiple controllers instead of single controller in a distributed fashion. Distributed controllers secure synchronization is another big challenge. we will secure the communi_x0002_cation of dsitributed SDN controllers using Blockchain. Blokchain consensus alogorithems consumes alot of computing resources it overload the network and consumes alot of band_x0002_width. Heavy consensus algorithems reduced the overall network performance. However, in this study we will discuss in details the implementation of blockchain over distributed SDN controllers without much affecting the performance of the network. we will propose BlocSec4DistNet a lightweight blockchain by calculating the trust of SDN controllers and IoT devices and update flow-rules of forwarding devices which will secure the controllers communicationa and does not consumes too much network resources. BlockSec4Dist aver_x0002_age latency is 0.54% where as BMC SDN and DistBlockNetis average latency is 0.97% and 0.90% respectively which is immproved by 44% from BMC SDN and 40% from DistBlock_x0002_Net at 10Tps(Transactions per second). The throughput of the BlockSec4DistNet at 50Tps is 11.71% where as BMC SDN and DistBlockNet average throughput 10.45% and 10.21% respectively. Which is improved by 12% from BMC SDN and 15% from DistBlockNet. It increase the network perfromance and it is suitable where good performnce of network is required for example in data centers.
"Rizwan Ali

Wg-Storm Scheduler for Stream Processing System"	Today, our world is facing several challenges in dealing with massive amounts of data. Stream Processing Engines (SPEs) allow applications to process a large amount of data in real-time. However, the (SPEs) create several challenges in terms of load balanc_x0002_ing, resource utilization. As the volume of data changes over time which also poses a challenge to predict the resource and job requirements for processing. The most popular stream processing engine is Apache Storm in the industry today. However, Storm uses a static topology strategy, resulting in poor load balancing performance in worker nodes. Apache Storm uses default round-robin scheduling, which ignores the availability and requirements of the resources for tasks may also lead to inefficient resource utilization. Most stream processing engines also ignore the topology, which may minimize throughput during scheduling. In this paper, we proposed a topology_x0002_aware and resource-aware scheduler named as Wg-Storm. Wg-Storm is proposed for Apache storm based on DAG (Directed Acyclic Graph). A scheduler is divided into four phases. First, monitors the connectivity between tasks which makes our sched_x0002_uler topology-aware, the data transfer rate between tasks, and the availability of the resources. In resource monitoring, we consider bandwidth, computing power, mem_x0002_ory, and the physical location of nodes. In theIn the second step, using the above information we obtained from the monitoring step, we construct a weighted graph based on the communication between tasks. Then create a pair and sort them with the highest communication pair first. In the third step, the task is logically grouped using topology DAG which reduces the inter-group communication according to inter-tasks traffic. In the last step, these groups are assigned to the physical nodes. All available nodes are arranged in descending order (most power full node at first). The aim is to improve resource utilization and overall throughput using efficient tasks assignments. Wg-storm is built on Apache Storm (the most popular processing engine). Wg-Storm scheduler runs on the master node (Nimbus) of the Apache storm. Results are gen_x0002_erated using the two linear topologies, and compared with the 5 state-of-art scheulers including the (A3-Storm, Default, Isolation , Multi-tenant and Resource-aware). Ex_x0002_periments results show up-to 25% and 30% throughput improvement compared with A3-Storm and default scheduler, respectively, using minimum resources in heteroge_x0002_neous cluster. Keywords: Resource aware, Bandwidth, Heterogeneous cluster, Stream processing engine
"Maria Jamshed

Identifying Covid-19 Affectees Using Twitter Data For
Better Resource Planning"	Coronavirus, recognized as a pandemic, is a global menace which has disrupted the world beyond health and well-being. Pakistan has also become a victim of this virus with a drastic impact on economy and the healthcare sector as hospitals across the country became saturated with Covid-19 patients. A number of Covid-19 suspects, however, are not captured in the nationwide statistics, causing notable difference in the actual and reported cases. Social media has gained critical importance during the pandemic as people have resorted to stay-at-home lifestyle with increased person to person and social interaction using social media platforms. The trends gathered from these platforms have made social media as the most effective information and trend observation medium. Twitter stands out as a popular social networking channel which has taken a center stage for reporting of health updates during pandemic which can be analyzed for improving the accuracy of Covid-19 trends. This study has targeted the suspected covid cases in Pakistan at a city level to identify the trend of the unaccounted for suspected covid cases. These suspects aid to improve the accuracy of the recorded percentage of cases reported and provide a medium to enhance the accuracy of the recorded cases. The data was balanced and classification has been performed using logistic regression, decision trees and support vector machine and the most accurate F1 score achieved was by SVM of 0.985. The location frequency of suspects identified enables to gain a preview of the covid trend with the top five cities as Karachi, Islamabad, Lahore, Peshawar and Rawalpindi. This location trend turn not only helps in making the statistics more precise, but also helps to identify localities that have become a target of this pandemic or expected to hit the danger zone. These numbers help in optimizing the distribution and allocation of health facilities and services so high-risk regions are well-resourced and capable to respond to health emergencies promptly
"Muhammad Ahmed Bilal

Customer Preference Based Load Shedding In 
Streaming Data LATEX"	Businesses are growing rapidly or emerging day by day. They need up to date/latest data to make their decisions. Data warehouse play a key role in making their decisions. To make warehouse real time, we need to feed data online to warehouse. It means ETL layer needs to be enhanced. In ETL, the most crucial part is transformation where we join incoming stream of transaction with disk based master data. Now there is a big challenge in this join because one input is stream and other In semi-stream join algorithms, we are dealing with a high rate incoming stream tuples that need to be joined with low speed disk-based relation, under the constraint of limited memory. Caching technique allows highly preferred tuples to process at high rate. However, still such situations can arise easily where the join algorithm fails to cope up with the stream arrival rate due to limited available resources. In this case we need to shed extra part of stream on the disk and process them later. Presently all the proposed approaches sheds this extra part either randomly or on count frequency basis. Customer preference plays a big role in business intelligence. In other words, cus_x0002_tomer’s preferred products have more importance compared with frequency of prod_x0002_ucts. A lot of people are buying butter, bread and sugar but there is a customer who buys very little but when he comes he buys such expensive things that he gives more profit than others. This means that there are some items which have less sales but whenever they are sold, their margins are very high. So who are the most important customers? In base paper, product’s frequency is more important. The theory behind this is that quantity matters in revenue. But In our case it should be customer’s prefer_x0002_ence that matters most in revenue. From here we had built our idea of load shedding with reference to customer’s preference. During pek hours, If we shed customer’s pre_x0002_ferred data and process it in off-peak hours then that will not contribute in our real time analysis. If 20 percent of data stream is to be sheded then only least customer’s preferred data will be selected for shedding. We proposed a method in which cache is populated on the basis of customer’s preference. A new feature is added in already proposed semi-stream join algorithm CMESHJOIN. Social choice theory aggregates individual preference into collective output/outputs. We discussed how borda method helps in aggregating individual preferences into col_x0002_lective social preference profile by considering transactions’ data of a shopping cart. The final top-preferred list of products is used to build front-page cache. To cope up with high stream rate, load shedding technique is applied in such a way so that only least customer preferred tuples will be discarded if required
"Saba Liaqat

Explaining the Training of Convolutional
Deep Learning Models through InteractiveVisualizations"	Due to the success and popularity of Deep Learning models, these models have been applied in a wide range of applications and tasks. Consequently, there is significant interest in understanding the inner working of these models, details of their training protocols as well as understanding the pitfalls which restrict a model from achieving its training objective. For this purpose, several visual tools were developed in recent years. In these tools, the working of neural networks is represented through the interactive visual interfaces which help to provide Explainability of the underlying model. Examples of these tools are TensorFlow Playground, TF Meter, CNN Explainer, GAN Lab, etc. The performance of a deep model is dependent upon its structure and weights. Recent studies have found that different weights have an unequal contribution towards the network/model training. The primary goal of this work is to analyze the changes undergone by the weights during network training. In addition, since it is documented that only a small subset of the weights is responsible for the network performance. Therefore, we also explored interactive interventions in the weights through a control randomization approach where we replaced the least dominant weights with the most dominant weights. We provide the user with a tool to visualize the weights for different filters of the various convolution layers in the deep network. We have tested the tool for LeNet and AlexNet architectures and tested it against multiple sets of parameters and epochs. Our tool also provides the users with the functionality to save the generated results as text files after the users have edited them according to their requirement i.e. the user can save the zoomed result of some specific filter at a particular iteration or epoch. Finally, we also performed an evaluation of the tool through an expert study which included multiple participants from the deep learning and data visualization domain. The purpose of the evaluation was to grade the tool on the basis of factors such as its effectiveness and ease of use
"Osama Javed

Interspeech 2021 Automatic Speech Recognition for
 Non-Native Children’s Speech"	Automatic speech recognition becomes very popular in today’s era. It emerges almost in every field of life. We addressed an automatic speech recognition system for those children who speak other languages then their native one, because they speak less accurate than adults. Here we present an end-to-end base neural network model on which we train English and German language for Italian speaking children. By implementing end-to-end base model our word error rate is reduced as compared to other existing approaches
"Haris Ramzan

Future Sales Prediction of Products using Ensemble 
Learning Technique"	Now a days, Ensemble learning is playing very important and effective role in many fields to enhance the predictive capability of the financial systems and enhancing the underlying infrastructure of existing machine learning models. It has gained more popularity in the recent time where multiple base learners are combined in heterogenous and homogenous way to produce the optimal prediction with respect to single learner. Many industries are trying to make their system more effective in terms of decision making and predictive power to comply with the competitors effectively. For this purpose, ensemble learners are widely used to increase the predictive power of the system. Similarly, like other domain there is a huge space to use this idea of combined models in the field of product retail systems. A lot of work has been done already but there is huge room to improve the prediction accuracy by trying different models and come up with a better ensemble learner performing better in the specific domain. There are multiple ways by which ensemble learners are formed to produce better results such as majority voting, averaging, max averaging, stacking, bagging and boosting etc. According to some studies bagging technique performs much better than the boosting techniques and widely used to create effective ensembles. To tackle with the time_x0002_series data ARIMA model will also be incorporated to the ensemble model to acquire the effective results. In the most recent research based on Kaggle competition related to price prediction of products XGBoost and LSTM have been used which have given good results but there are also some factors involved in terms of bias and variance which needs to be taken care off. In the first step of solution initial analysis on the data will be carried out and multiple feature extraction techniques are used to find the best relevant features related to the problem. LSTM will be modified in terms on hyperparameter tuning and width of the network and trained on the dataset to achieve best accuracy. Later on, the modified LSTM is used to form the ensemble learner with other two models named as ARIMA and XGBoost. To achieve the primary objective, I am planning to create a customized ensemble learner based on the above models and potentially with addition of neural network to decrease bias and variance.
"Reda Fatima

A Dynamic Model for Risk Assessment of Software 
Projects"	Risk is one of the key determinants of the success or failure of a software project. Risk management includes identification, analysis and prioritization of risk factors. Risk assessment helps in identifying most critical, high impact risks thus efforts can be made to handle them in their order of priority. Risk can have static or dynamic nature. Literature mainly focuses on the static risk assessment. In real world scenario, risk has dynamic nature i.e. the risk values keep on changing continuously as a result of certain event. Very few papers have addressed the dynamic risks in software domain resulting in limited approaches to dynamic risk assessment. But, it is need of hour to look for approaches that may consider realistic dynamic values of risks. This paper proposes a model for dynamic risk assessment of misunderstanding requirements. A survey was conducted on industry experts to identify the risk factors that resulted in project success, failure or challenge. Also, the events during software project management lifecycle were identified that impacted the software risk factors. The main factors causing misunderstanding requirements include: unclear system vision, conflicting views of stakeholders and changing requirements. The research modeled the impact of software project management activities on factors responsible for misunderstanding requirements. It was observed that each event effected the risk factors differently, resulting in different state of project after an event occurred. The model was evaluated by academic experts using survey method who considered the model as a new area of research and testbed for future researchers. The proposed model will help future researchers in having new dimension of study
"Ahmer Shafeeq

Accessibility Evaluator: WCAG 2.2"	According to a survey in 2021, 2.2 billion people are suffering from visually impair_x0002_ment. Due to exponential growth of visually impaired people in our society, this has become a challenging task to facilitate visually impaired people in our routine tasks which are based on web and mobile applications. W3C has introduced a set of guide_x0002_lines called as Web Content Accessibility Guidelines(WCAG) for web and mobile ap_x0002_plications UI so that visually impaired needs can be addressed. To test websites and mobile apps against accessibility guidelines, different tools are developed but these do not cover all of the guidelines. Existing tools are dependent upon v2.1 and next version WCAG 2.2 exposes new guidelines available on W3C website, This provides a gap and need for a tool which assess websites on the basis of new guidelines added in WCAG 2.2. To fulfil this need, this study aims to make the fol_x0002_lowing contributions: 1) To explore and analyze new added guidelines in WCAG 2.2 version 2) To devise a method for tool development which can adopt maximum guide_x0002_lines provided in WCAG 2.2 3) To formulate automated test cases on the basis of new guidelines 4) Evaluation of tool architecture and test cases on most renowned websites of multiple categories i.e. Facebook, Coursera, Paypal and American medical associa_x0002_tion website. We conducted an analysis on the draft of WCAG 2.2 guidelines to understand the automate-able guidelines, acceptance criteria and test methods. 9 Test cases were de_x0002_rived from new provided guidelines. To attain these test cases into a accessibility tool, a method is proposed where chrome extension is used with selenium on server-side automated evaluation of websites in a generic way. We implemented these test cases into proposed method and then different websites are tested with the aid of tool to measure the efficiency of tool in identifying issues. Each test case is executed against each website. Results shows that each of the test case is able to identify issues in websites according to the provided guidelines. This tool identified the issues in most renowned websites i.e Facebook violates the success criterion where focus indicator should meet the contrast of 3:1 with its background color. Similarly Coursera website contains 122 elements which do not meet with the standard size devised by WCAG 2.2
"Haseeb Ahmad

Hybrid Approach for Document Image Classification & Segmentation"	"Document image classification is especially important these days. In modern business communities such as health care systems, educational systems, insurance companies, utility bills etc need to classify documents containing useful information. This includes the classification of unknown sample documents along with the classification of known samples. After classification, useful specific information is extracted from the documents. Researchers have done a lot of work in classification, but limited work has been done when we talk about document classification. The reason for that is the various challenges faced in document classification. One of the major challenges of document image analysis arises from the fact that within each document type, there exists a wide range of visual variability. No two documents share the exact same similar arrangement of header, footer, date, name, amount, address, body, and signature; some documents even remove these components completely. For our research, we have selected an open set document classification problem. In open set document classification problems, the main problem arises due to the existence of unlimited unknown samples alongside limited known ones and primarily in classification, we need a balanced dataset for each class. So the probability of classifying an unknown sample as known is highly probable due to the level of intra-class variability that renders spatial layout analysis difficult, and rigid template matching impossible. Another issue is that documents of different categories often have substantial visual similarities. The main goal of our work is to classify unknown documents alongside known ones and extract the specified information from the known document. A single stage approach is used using ResNet50 architecture to achieve accuracy on unknown samples. The problem arises when an unknown sample is fed to the classification model, as it will in turn give us a predicted class from one of our labelled classes. To prevent this, we are using a lightweight detection model to help us in identifying unknown samples. Labeled dataset of medical documents is available. We’ve trained the model on this dataset and for the efficiency (accuracy) measurement we’ve tested this on the real dataset of given documents.
"
"Shehr Bano

Interpretable mispronounciation detection model for tajweed of Quran Verses"	This work aims to present a model that provides Quranic reciter appropriate feedback of verse mispronunciation. The model takes ordinary Muslims' recitation, as the melody of voice may create differences between audios. Previously, SVM (support vector machine), KNN (k-nearest neighbor), ANN (artificial neural network) and some feature-based techniques have been deployed for classification problems in Quranic and Arabic Contexts. The techniques achieved a higher accuracy rate without being explainable about the prediction result. Some have focused on selected Tajweed rules such as EdgamMeem” (one rule), “EkhfaaMeem” (one rule), “Ahkam Lam” in ‘Allah’ Term (two rules) and “Edgam Noon” (four rules). For dataset compilation, audios of selected chapters or audio of selected Qirah have been focused on. Tajweed is basically the way to recite the Quran by applying specific rules to each word/letter. Each rule plays an important role as; a verse can contain maybe many of them. To cover most of them a model has deployment which takes verse audio recitation input and converts it into spectrogram png formats. The input audio spectrogram and correct label audio verse spectrogram are then fed to a similarity generator, that gives a similarity score. We have set a threshold of 70% for misclassification verse as correct or incorrect recited. The spectrogram was further processed and given to a feedback generator model, where it drew bounding boxes around the detected differences. The highlighted areas termed bounding boxes are the additional feedback for the recitation learner to figure out their own recite verse mistakes. Our main focus is on Quranic verses for appropriate feedback generation of mistakes because connected words take an important part in some Tajweed rules formation. We have justified the prediction results of this model using the three buckets format for approach 1. For testing the first bucket contain 100 correct label audios that are compared with the same correct audio samples and generate a 100% similarity score. The second bucket has 100 audio samples with the correct label which is then compared with other correct label samples of the same verse audios, it generates a similarity score between 65%-85%. The third bucket contains 100 audio samples with correct labels compared with incorrect label audio samples contain mispronounced words and verses, which generate 20% to 45% accuracy. For approach 2 and 3 we have selected FALSE labelled audios of Tarteel that is almost 1690 records and randomly test those audio’s and got almost 70% accuracy in approach 3.
"Maryam Chaudhary

Authorization in Kubernetes: A Step Towards Secure System Development Using Kubernetes"	Kubernetes Offers an automated platform for the containerized environment. It is open-source, portable, and provides support on all cloud services like GCP and Azure. Google provides the services of Kubernetes. As Kubernetes provides automation, so it the most popular amongst all containerized environments. It runs multiple applications on a single cluster. An application developer can build, test and deploy the application in a parallel manner. One of the critical areas in Kubernetes is Secure system configuration. In Kubernetes the there are different elements of Security that are Authentication, Authorization, and admission controller. When the API server (gateway) gets the valid request then it goes through these three elements before it is either allowed or denied. There are different mechanisms available for the authentication in Kubernetes but Authorization is not well defined in the Kubernetes as policies are created through YAML. When a request reach at admission controller then all authorities regarding access control pass to it. This security process raises the risk of policy conflict in Kubernetes. There are different authorization policies exist in the Clouds and conflict between policies are also exist. However, authorization policies also exist in Kubernetes. Yet no work has been done on authorization policies and their conflicts. In this report, we identify the redundancy between authorization policies and address the issues related to the management of authorization policies. We have provided the core model to detect the redundancy in the authorization policies for different modes of authorization (ABAC and RBAC). The fetched authorization policies pass through our proposed core. Policies are extracting through the cluster (API server) in Kubernetes. Then finally the results are analyzed to check the scalability, efficiency, and practicality of our proposed model.
"Saba Akram

Identification of Authorization Conflicts in Hyper Ledger"	"The blockchain is evolved from cryptocurrency and used widely across different fields such as healthcare, business, supply chain, and many more. The blockchain enables P2P (i.e. peer to peer) transfer of digital assets without including intermediaries. The hyperledger is a type of blockchain that is permission-based. The reason behind adopting Hyperledger is its features such as transparency, modularity, scalability, chain code, privacy, efficiency, security, authentication, and authorization. The hyperledger provides authentication by default as every peer has a unique identity. Hyperledger does identity verification through digital certificates. While authorization in Hyperledger requires identity and policy where the policy defines the conditions that need to be fulfilled to access that particular resource. Hyperledger implements the Attribute Based Access Control(ABAC) and Role Based Access Control(RBAC) for authorization, the policies for authorization exists in the hierarchy.; where, at the bottom level, there exists an access control list that contains policies of authorization for resources. While accessing some resources there can be conflict in policies that can result in accessing a resource to an unauthorized user. These conflicts can cause severe problems from a security perspective. The existing work shows that the conflicts between the authorization policies exist in different domains such as cloud. However, the existing approaches cannot be directly applied to identify conflicts because policies of hyperledger fabric are quite different from cloud. Therefore, we need to have a formal approach that can identify the conflicts between the authorization policies in Hyperledger fabric. This research proposes a solution for the detection of vulnerabilities and conflicts in yperledger authorization policies using a formal logic approach and Event calculus. In our proposed solution, we fetch policies from the Hyperledger fabric cluster. This cluster contains hierarchical policies, where, rules exist at the top level,the signature policies exist at next level, it contain the rules with different combination of ""AND"",""OR"" and ""NOutOf"". ImplicitMeta policies comes after the signature policies, as meta policies acquire the signature policies to be true; further, there exist the ACL policies that combine the resource with some Implicit meta or signature policy. After fetching those policies from the cluster, we model the policies and the conflict detection algorithm in event calculus, after that, we apply the DECReasoner to evaluate our models. If there is policy that is permitted for some resource, and inapplicable for another resource while both resource has some relation, it causes the inconsistency. Moreover, hyperledger allows access of multiple resources to a single user, if that user is enrolled as different roles, which can result in information leakage of hyperledger network. The event calculus models detects the inconsistent and over permissive authorization policies. At the end, we analyze the results by considering multiple test cases. The performance results for our event calculus model shows that our approach is scalable, efficient and practical."
"Shahid Hussain

Predicting Bipolar Disorder Via Social Media Content"	Social media data has been widely adopted by researchers for detecting many diseases and mental disorders including depression, anxiety, suicidal thoughts, and many other disorders. While much interest has been taken in detecting depressive symptoms from social media data, very few studies consider the detection of the characteristics or patterns of bipolar disorder. Bipolar mental disorder is caused by the cycles of happy and sad mood swings throughout the time, and has different subtypes based on different intensity levels of its mood swings. In this study, we transformed the characteristics of bipolar disorder in order to find their patterns in social media data. We defined polarity distribution for each of the sad and happy mood swing of bipolar disorder depending on mood’s intensity levels, and classified twitter text on this polarity distribution. Then we introduced a novel scheme for detecting the patterns of happy and sad mood swings in twitter data, and classified those patterns on different subtypes of bipolar disorder based on previously defined polarity distribution. Our proposed scheme includes different solutions for bipolar detection problem, including mood duration based classification, polarity based classification and text based classification. In first approach which is mood duration based classification, we considered bipolar mood swings with their persisting durations, in second approach which is polarity based classification, polarity distribution of tweet text is made the basis for classifying tweets on bipolar subtypes, and in third approach we used actual tweet text of bipolar user to classify it on any of the bipolar subtypes. Our proposed methodology outperforms previously defined methods of bipolar classification in social media text.
"Amna Binte Kamran

A Novel Ontology Based Measure for Functional Semantic Similarity of Genes"	The Gene Ontology (GO) is a controlled vocabulary that captures the semantics or context of an entity based on its functional or biological role. Biomedical entities, such as proteins, are frequently compared to each other to find similarities to help in data annotation and knowledge transfer. Several approaches have been proposed for measuring the semantic similarity between the gene products annotated with the GO Terms. However, these generally depend on external gene annotation corpora, or fail to fully utilize the characteristics of the ontology to best capture the semantics of the gene ontology terms. In this study, we propose GOntoSim, a novel method to determine the functional similarity between genes. GOntoSim quantifies the similarity between pairs of GO terms, by taking the graph structure and the information content (IC) of nodes into onsideration. Our measure quantifies the similarity between the ancestors of the GO terms accurately. It also takes into account the common children of the terms being ompared. GOntoSim is extensively evaluated using the entire Enzyme Dataset containing 10,890 proteins and 97,544 GO term annotations. The enzymes are clustered and compared with the Gold Standard EC numbers. At level 1 of the EC Numbers for Molecular Function, GOntoSim achieves a purity score of 0.75 as compared to 0.51 and 0.47 for measures by Wang and GOGO. GOntoSim can handle IEA annotations as well as the noise added by them. We achieve a purity score of 0.94 in contrast to 0.48 for both Wang and GOGO at level 1 of the EC Numbers with IEA annotations. GOntoSim can be freely accessed at (http://www.cbrlab.org/GOntoSim.html) or downloaded from (https://github.com/cbrl-nuces/GOntoSim)
"Hashim Ayub

DeepQ Reinforcement Learning (DQRL) Framework for Multi-Agent Systems in Dynamic Environment"	Multi-Agent System (MAS) consists of multiple agents interacting to solve complex and dynamic problems. Reinforcement learning has been used alongside meme-inspired algorithms to make agents learn better in a complex environment. An agent performs certain actions in an environment and then is rewarded with feedback. Delay in feedback could hinder agent performance and result in slow learning. In literature, The Fusion Architecture for Learning, Cognition, and Navigation (FALCON) is presented in the MAS system, which is an expansion of the self-organizing neural network; it exhibited quick and stable constant learning capacities. However, learning of FALCON depends on the positive reward from the environment, which may not be consistently accessible in some complex and dynamic real-world applications as the reinforcement FALCON agent faces difficulty to become familiar with the appropriate information to adjust to the given jobs rapidly. So this research aims to focus on achieving mmediate positive rewards in a complex and dynamic environment in MAS. The proposed approach includes a meme-inspired evolutionary algorithm and a side deep q reinforcement transfer learning approach for learning in a complex and dynamic nvironment. The memetic algorithm is used for self-learning and social learning and is the backbone of the proposed framework. DeepQ Reinforcement Learning (DQRL) has been used to approximate q values under complex search spaces to tackle the availability of immediate positive rewards. To prove the effectiveness of the proposed approach, comprehensive experiments have been conducted on Minefield Navigation Task (MNT). The presented framework performed well and achieved significant improvement in success against the state of the art approaches mentioned in the literature. Keywords: Multi-Agent System (MAS), DeepQ Reinforcement Learning, Transfer Learning, Immediate Reward, Memetic Algorithm, FALCON.
"Abdul Azeem Sikander

Imitating Player Behavior in Games using Evolutionary Computation"	Artificial Intelligence (AI) is a big umbrella under which Machine Learning (ML) and Evolutionary Computation (EC) are placed. EC uses ML to deal with solving ptimization problems which are based on the survival of fittest candidates from 1st generation up till n. Most of the work has been done on heterogeneous multi-robot systems in which physical robots cooperate to evolve in a dynamic real-world environment. Lesswork is done for building an agent working in a coevolutionary setup in the domain of games. Focus is made on imitating real-time players behavior in competitive evolutionary environment rather than winning or losing statistics.  Limited riggers/actions are used while defining chromosome genetic structure to evolve them which does not involve much learning. Some of them are pre-scripted that perform the same moves, do not learn new actions, and evolve themselves to have new strategies. This work proposes an intelligent agent that will work with a wide range of triggers in a competitive coevolutionary setup. Proposed approach includes optimized reward functions, abnormal behavior of the AI agent is addressed, randomness in AI agent behavior and perform triggers for which increase reward value. The proposed approach is evaluated against the state of the art approach in base paper which involves creating AI agent [1] using genetic programming. Keywords: Evolutionary Computation (EC), Competitive Coevolution, Triggers, AI Agent, A2C Algorithm, Ram Values.
"Hamza Ali

A Hybrid Surrogate Assisted Framework for Solving Many Objective Optimization Problems"	Many-objective optimization problems are a subfield of multi-objective optimization problems. These problems contain more than four objective functions to be optimized. These problems require the simulation of weeks or even months and cause a computational burden. Surrogate models are very popular to sharply reduce this burden by helping evolutionary algorithms in population generation and selection. This study is conducted to propose a novel evolutionary algorithm for solving many-objective optimization problems using surrogate models. Many studies already proposed surrogateassisted evolutionary algorithms to solve many-objective optimization problems. Some previous studies used hybrid approaches to provide solutions to these problems which showed great results as compared to state-of-the-art approaches. Currently, many approaches are available to solve small and medium-scale expensive problems in manyobjective optimization problems. In this study hybrid surrogate assisted evolutionary framework is proposed to solve high-dimensional expensive many-objective optimization problems. To solve these high dimensional expensive problems this proposed study will use a hybrid surrogate assisted evolutionary framework classification-based surrogate model and fusion of evolutionary algorithms which were used previously and showed high accuracy from state-of-the-art algorithms. The proposed algorithm will perform simulations in a parallel way to optimize the results of all the objective functions. The main focus of the proposed approach is to deal with the high dimension of the decision variables, where previous work was done on a limited number of decision variables and objective functions. In this study, six different evolutionary algorithms are used to generate their population using their rules and genetic operators.Then the population will be passed to the utilized surrogate model to classify the best offspring from the population of each algorithm. After classification, the best performing algorithm will be got selected to perform future iterations on the problem.The proposed framework is completely implemented in a Matlab-based framework called PlatEMO. The experimental setup to evaluate the proposed approach is designedaccording to the base paper experimental design. To evaluate the performance of the framework Inverted Generational Distance (IGD) which calculates the Euclideandistance between the reference point and non-dominating solution. The proposed approachperformed well on several instances of the benchmark problem. Well after the good performance of the proposed framework there are still some changes and limitations which are needed to be removed. Like the approach is statically compared with expensive algorithms but the high dimensional algorithms are still need to be compared. In the future the proposed approach can be implemented using machine learning techniques for classification or the selection hyper-heuristics can also be employed for better results.
"Syed Ali Abbas

Improving the Recognition Performance of Activities with less Inter-class Variations and fewer Instances in a Smart Home"	Ambient sensors, such as switch state binary sensors, pressure, and temperature sensors, are deployed to gather the data in a smart home. Each activity instance is represented by the frequency of activation of the sensor. Activities with less discriminating information, such as preparing breakfast and wash dishes, result in incorrect classification. Recognition of activities with less inter-class variations and a limited number of instances is a challenging task. We proposed an activity recognition approach that represents each activity based on its Dissimilarity Scores (DS) from other activities. We used the Generative Adversarial Network (GAN) to improve the representation of minority classes. The obtained dissimilarity scores were provided asinput to the GAN and then applied three machine learning classifiers; Support Vector Machine (SVM1vs1), Naive Bayes (NB), and Multi-layer Perceptron (MLP) for learning.
"Tayyab Iqbal

Pest Recognition Through Feature Extraction Clustering and Classification"	Pests recognition is necessary for crop protection in many areas of the world. Pest destroys crops in the form of many diseases and these diseases affect the production yield of the crops. High interclass similarities make pest recognition a challenging problem because that existing pest recognition accuracies are compromised. Our research is focused on improving the accuracies by learning the fine-grained differences between similar classes of pests. We propose a pest recognition approach. First, we group the different pests with similar appearances, using handcrafted features and traditional clustering methods. Next, The K-means clustering algorithm has been proposed to make clusters based on extracted features than within each cluster and To improve the representation of minority classes within each cluster, we exploit the data balancing methods such as Synthetic Minority Oversampling Technique (SMOTE) to balance the images in the clusters then, we apply SVM for classification and we improve the accuracies according to every feature extraction method on the dataset IP102. Keywords: Synthetic Minority Oversampling Technique (SMOTE), K-means clustering, SVM(Support Vector Machine).
"Umair Nawaz

Evaluation of Android's Anti-Malware Systems"	Android mobile platform is the most popular mobile platform and dominating the mobile phone market. With the increase in the use of Android, Malware developers have become more active in bypassing security by using different obfuscation techniques. Different obfuscation techniques have been used for hiding the malicious code within malware android applications to evade the detection by anti-malware tools. The malicious code involves modifying the code so that anti-malware analysis makes it difficult to analyze whether the application is harmless or malicious. For the protection of Android, different Anti-malware tools are available in the market. Evaluation of some of these tools is important against different obfuscation techniques that are used as alone or combined with other obfuscation techniques. Malware developers can use obfuscation techniques to increase their evasion rate. Most anti-malware tools use signature-based databases to detect malware. Malware developers can easily evade signature detection by obfuscation techniques. Code Obfuscation changes the application code, but the code function remains the same. Different obfuscation techniques that are hybridized with more obfuscation techniques need to evaluate top anti-malwaretools. There is a large number of obfuscation techniques. However, in the past, limited obfuscation techniques have been used. Each of the past works uses different obfuscation techniques. Some use obfuscation techniques in an isolated way; some use a ybridized form to evaluate the anti-malware tools. Researchers proved that obfuscation techniques would be more effective when used as a hybridized form. In this work, a state-of-the-art framework for evaluating various anti-malware tools is developed. To assess the consequences of obfuscation techniques on Android applications and anti-malware tools, this work conduct a large-scale empirical study to evaluate the effectiveness of the top anti-malware tools against a large number of obfuscation techniques and strategies. Obfuscation techniques are applied in an isolated way, category-wise and intercategory- wise, to evaluate anti-malware tools. This work aims to check the accuracy of some well-known commercial anti-malware tools against a large number of obfuscation techniques. This work enables anti-malware developers and anti-malware vendors to test their products’ evasion rates against a large number of malware databases. This work use dataset named Drebin. This dataset contains a large number of maliciousAPK samples from a large number of malware families. More than 20 different obfuscation techniques are used with possible combinations. These combinations are applied to the malicious android application. This obfuscated application which has malicious code is then given to various top anti-malware tools. Then on detection accuracy, this work is evaluating the top 10 anti-malware tools. Results show if a malicious application is obfuscated using an inter-category-wise combination, it has less detection rate than the application, obfuscated by a single obfuscation technique.
"Muhammad Junaid Iqbal

Android Ransomware Detection System Using Hybrid Approach"	"In the present decade, the world has become a global village with many technological advancements. The use of the smartphone has become a common practice in almost every field. People are shifting their work to portable smartphone devices because the latest smartphones are more advanced, having user-friendly operating systems like Android. Nowadays, the most high-risk attack in Android through its applications is ransomware. Ransomware is the type of malware and emerging as a high-risk attack through untrusted applications worldwide. The ransomware attack hijacks the user data by encryption of data and asks for ransom for the decryption. The primary source of ransomware threat is the application downloaded from an untrusted source. There is a need to develop a ransomware detection tool to prevent the loss of essential data. It takes proper measurements to protect against them. In this thesis, a novel hybrid system is proposed for the detection of ransomware by analyzing images, text, and code with a set of collected information from an inspected application by threatening text, and afterward working will be done to get rid of these threats as well as for meeting the today’s requirement or for future purpose. Threatening text was an essential characteristic of ransomware for the detection and classification of ransomware attacks appropriately. Ransomware attackers affirm the responsibility of attack by displaying threatening text for ransom such as ""how to pay and where to pay"" the ransom. Hence, it noticed that all ransomware families, such as encryption-based or locking-based ransomware, always display a threatening text. Ransomware developers display a threatening text with popup dialogue that opens directly. Threatening text could be in the form of an image, text, or video. Most of the hybrid techniques for the detection of ransomware had not focused on its main characteristics. Somehow, many techniques focus on threatening text but due to the high rate of errors causing misspelled texts because of lousy resolution images and the intricate font style that machines or old detection systems could not detect. Two different detection procedures have made in this technique firstly a static approach using (permissions and suspicious text) and a dynamic approach to detect ransomware using modern text scanning techniques through screenshots from running application’s in virtual environment. In static analysis, detecting common existing ransomware could be done before it harms the phone containing essential data. The static approach provides competitive results in existing ransomware attacks with essential characteristics, and if obfuscated ransomware bypasses the static approach without detecting any suspiciousness, it can detect by dynamic with modern text scanning techniques. This technique will track the ransomware threatening message or words; a Multi-machine learning classifier would be more efficient in detecting ransomware and its family classifications, such as encryption-based or locking-based ransomware. Our results show that our method successfully classified ransomware with an average accuracy of 92% and has less false negative rate."
"Mayra Ahmad

CALB - Contention Aware Load Balancer Thread Scheduler for Multicore Machines"	The limitations of ultra-large-scale integrated manufacturing technology and consumptionof power have prevented designers from developing large-scale single processors [1]. Instead, multi-core architecture has become a promising solution to address the above limitations and constraints. Today, high-performance multi-core processors implement multi-threading capabilities [2]. Processes running simultaneously on these processors not only continuously compete for shared resources between the cores but also within the cores [3]. To fully realize the potential of heterogeneous multi-core systems, the operating system must adapt to the new system environment[4]. Applications will compete for shared resources, such as the last level cache (LLC) andmain memory bandwidth when running at the same time. This is especially true for the scheduler, as it is critical to overall system performance [5]. Thread schedulers used in operating systems ignore lock contention among multiple threads belonging to an application, and therefore cannot provide high performance for multi-threaded applications [3]. The execution time of multi-threaded applications with high lock contention is very sensitive to the allocation of application threads across multiple processors [6]. Due to the high frequency of lock transmission between sockets, incorrect thread mapping will cause performance degradation and large number of last-level cache misses occurred [3]. Regarding load imbalance, the core should perform a similar workload. Load balancing affects parallel application performance and it has been the topic of considerable research in multi-core architectures [7]. The communication between tasks and load imbalance has been identified as the main challenge for the performance and energy efficiency of parallel applications [8]. A common way to improve communication is to increase its locality, that is, to reduce the distance of data transmission, and use faster and more efficient local interconnection in preference to remote nterconnection [8]. Thread mapping based on affinity has become one of the keys embraces in the multi-core architectures to resolve contention and load imbalance [9]. In many-core Architectures, most of the work is focused on execution time and idle information to schedule decisions [10]. Today’s operating systems are contention unaware [7]. Because there are often, different threads in multi-threaded applications that Show varying degrees of CPU utilization and instruction types cannot measure loadbased on the number of threads alone [11]. Therefore, there is a need of an approach that considers above points to develop a solution. In this, an algorithm is proposed which is contention aware and balances the load among all the available CPU’s. A contention aware load balancing thread scheduler is proposed in this thesis. That is contention aware and balances the load among the cores of multi-core systems. The experiment shows that this technique gives better results than other scheduling schemes. As compared to baseline Linux scheduler, CALB has achieved on average of 31% less execution time and compared with shuffling, jumbler and tumbler techniques, CALB has achieved less execution time of 19%, 6% and 2% respectively.
"Rabbiya Shahid

Credibility Assessment of QoT Based Recommendations in IoT"	"The Internet of Things (IoT) is an emerging paradigm gaining excessive and rapidly growth by using sensors and devices which are connected to the internet.With this
innovation, recommender systems were introduced to solve the problem of decision making but it arose the user concern for the recommendations. The question about
the credibility of recommendations is still an open question for the researchers.In this research work a novel approach for evaluating the credibility of recommendation is
proposed."
"Abdul Rafay

Paraphrasing of Urdu Paragraphs using Natural Language"	Natural language processing is the walk through gate to interact with the computer through the natural languages which are spoken commonly. Paraphrasing of a text is basically the conversion of certain text in such a way that its semantic or meaning doesn’t change. We proposed an approach for paraphrasing of Urdu text which is a low constraint language with less data set and libraries. To deal with this process we divided our task into two sub-tasks which are i) re-ordering of the words in the sentence and ii) Changing the words with their appropriate synonym. Re-ordering of the words is done using the BART model which is a denoising sequence to sequence pre-trained model. We collected our own data set which contains the original and paraphrased Urdu sentences manually typed by the human. The BART model was trained on this data set. Bart is the bidirectional auto encoder which deals with the task of changing the order of the words along with the fill in novel spaces according to the grammar. The output is then passed to synonym replacement model which also have a separate data set which was collected by us. It contains the words with their synonyms and these words are replaced by their particular synonyms. So, we integrated both the models to get the desired result which are the paraphrasing of a Urdu text .The experiment shown that our model performed quite well and the results were as desirable. We evaluated our model on the basis of BLEU score. The BLEU score for the predicted text was ”0.54” when compared to the human paraphrased text. Department.
"Muhammad Hasnain Khan

Scribbling Speech Using Urdu"	"Languages and images are closely related. We explain facts as the spatial constellation and we think in pictures. What if the spoken sentence could be transformed into the visual worlds in real-time? Machine learning, speech analysis, and recurrent neural networks for image generation allow a computer to understand the natural language and also generate a complex imaginary world following the user speech and thus create complex animations controlled by linguistic structures. Generating a story or scene from voice is a unique problem that got a lot of attention in the past few years but to the best of our knowledge literature in this field is very much limited. In this research work, we working on making machines very intelligent so that they can interpret the natural language in such a way that some entities will be extracted from a sentence with context such as one entity is ”above or below” or ”before or after” to another entity. After extracting entities then some generative networks will be used to generate the identified objects according to the context. Our system will be able to generate real-time 3D models to make it more interactive for the user. We are proposing a module approach to solve this problem. We will work on three modules; first module will be a machine learning model to extract the entities from the speech input. Second module will be built for extracting the relations of the identified entities. Third module will be able to generate 3D models of the identified entities with respect to their relation extracted from second module. For speech input, we will be using Google ASR.
Department"
"Umar Farooq

Ensemble BERT for Hierarchical Classification of Disinformation in Urdu"	"Online disinformation has become a threat and in recent years there is a substantial increase in the ratio of disinformation. So, it demands fact-checking and disinformation detection & prevention. Fake news and propaganda are categorized as disinformation and these are special types of controversial content that are a crime and must be blocked. Due to the huge amount of data on social media and the internet, this could not be done manually. In this research work, we explore the automatic classification of  isinformation using the disinformation techniques used in the text. It is a hierarchical classification that has a total of 22 sub-categories. Ensembles have been shown to demonstrate good performance for hierarchical classification. We propose an ensemble BERT architecture- ’Distill-BERT, and xlm-RoBERTa’ over the disinformation dataset and systematically compare the performance of the ensemble with other variants of BERT. We apply and compare ensembles for hierarchical text classification and show that they outperform other neural networks, such as RNNs and LSTMs, and non-neural network architectures such as K-Nearest Neighbours, Random Forests, and Quadratic Discriminant Analysis. For our experiments on the disinformation dataset, we show that our ensemble achieved a weighted F1 of 68.7. This demonstrates the superiority of our ensemble over existing ML/DL approaches. Our results confirm the hypothesis that ensembles are advantageous for highly imbalanced datasets.
Department of Computer Science Faculty of Computing, NUCES-FAST,"
"Sara Durrani

Deep Neural Networks based Urdu Speech Affect Recognition"	Speech Affect Recognition for low resource languages has been an important problem in speech analysis. Here we present a Transfer learning based Speech Affect Recognition approach in which: we pre-train a RESNET34 for high resource language affect recognition task and fine tune the parameters for low resource language using largemargin softmax loss. Here we use standard four data sets to demonstrate that transfer learning can solve the problem of data scarcity for Affect Recognition task. We demonstrate that our approach is efficient by achieving 74.7 percent UAR on RAVDESS as source and Urdu data set as a target. Through an ablation study, we have identified that pre-trained model adds most of the features information, improvement in results and solves data scarcity issues. Using this knowledge, we have also experimented on SAVEE and EMO-DB data set by setting Urdu as target language where only 400 utterances of data is available. Similarly, 84.18 UAR on SAVEE and 87.5 percent UAR onEmo-DB has been achieved which is compared to other existing approaches.
"Sabina Akram

Predicting the performance impact due to student’s eLearning tool acceptability: A hybrid SEM-Neural Networks approach"	The efficient implementation of eLearning systems encounters many challenges, and the most critical of these is the student acceptability towards a particular tool (Blackboard, Zoom, Google meet). During the extraordinary circumstances of the COVID-19 pandemic, eLearning has become an essential and formal mechanism of continuing the educational process. Though, the effective use of the eLearning system depends on recognizing the factors of acceptability among students. Moreover, these factors aggravate when there are hindrances in the acceptance of the specific tool. In prior studies, researchers have mostly emphasized on Technology Acceptance Model (TAM) as the driving framework of eLearning. However, an important research path would be revisiting TAM that is potentially capable of analyzing the performance impact of individuals involved in the eLearning education system. To this end, this research presents a comprehensive review of the predominant factors, experiments, and analyses based on the traditional TAM. We then propose a novel approach by depicting the important factors that impact the student’s acceptability towards an eLearning tool. We also validate our findings with two collected datasets. The paper uses a hybrid analytical method comprising structural equation modeling and a Machine Learning prediction approach to analyze the efficacy of eLearning tools on student academic performance. Finally, results acquired from experimental analysis validate key determinants of performance impact during eLearning. This research is fundamental to understanding the underlying issues for students struggling with online learning.
"Nudrat Zara

Layer-wise Hybrid Approach for Trojan Detection in Android Applications"	"Android users are persistently scared by an growing number of dangerous malicious applications, specifically Trojan applications. Trojan establishes a genuine danger to
user money, privacy, device, and documents integrity. This thesis considers the Trojan characteristics, their activities, and further group them on the basis of their attributes
into classes. Their misbehavior can be characterized by checking the features on various Android levels. This thesis, presents a layer-wise hybrid approach for Trojan
detection in Android devices which at the same time analyzes and correlates features at three levels (e.g application, user, and package level) to distinguish malicious behaviors of Trojan. This research will use both static and dynamic analysis to detect features and Trojan and benign applications that come from comprehensive and huge android malware dataset, named CCCS-CIC-AndMal-2020, Cantagio-Mobile and Virusshare with 13,559 Trojan samples, by the participation of multi-classifiers. The classification algorithm Random Forest, Decision Tree, Support Vector Machine (SVM) and Logistic Regression are used to classify the Android application as Trojan or benign applications. The experimental results shows that SVM algorithm achieved highest accuracy of 96.64%."
"Umbish Sardar

Lightweight authentication in cloud-enabled Unmanned Ariel Vehicles (UAVs)"	"In Internet of Drones (IOD), the use of Unmanned Aerial Vehical (UAV) are increasing rapidly.These systems allow users to execute vital missions quickly and safely without risking human lives. The data captured by the sensors are stored in cloud and also being sent to the ground control station continue sly which causes major privacy and security concerns. Smart cameras used for UAV based video surveillance can be compromised easily, because both active and passive attacks can easily be generated
if proper authentication mechanism is not implemented. Complex cryptographic schemes cannot be implemented on UAVs because of their limited resources. Therefore, this thesis present an approach which cater both outsider and insider attacks efficiently. The proposed algorithm detects DoS attack and secure data and location privacy in cloud from the eavesdropping as well as correlation attacks. Additionally, it secures data from the insider attacks in database. The concept of silent period is introduced along with the two step key generation mechanism. The attacker will not be able to decipher the key with any bruteforce attack. Finally, this thesis calculates and compare the processing time for key generation as well as DoS detection mechanism, which shows that the proposed scheme requires less processing time and energy."
"Raza Ali

Hate Speech Detection on Social Networks using Transfer Learning"	Social Media has become an ultimate driver of social change in the global society. Implications of the events, that take place in one corner of the word, reverberate across the globe in various geographies. This is so because the huge amount of data generated on these platforms, reaches the far corners of the world in the blink of an eye. Developers of these platforms are facing numerous challenges to keep cyber space as inclusive and healthy as possible. However, in recent years, the phenomena of offensive speech and hate speech have risen their ugly heads. Despite manual efforts, the scope of this problem is so immense that it cannot be tackled by using concerted teams. In fact, there is a need that an automated technique is designed that detects and remove offensive and hateful comments before the materialization of their harmful impacts. In this research work, we develop an Urdu language hate lexicon, on the basis of this lexicon we formulate annotated dataset of 10,526 Urdu tweets. Furthermore, as baseline experiments we use various machine learning techniques for hate speech detection. In addition, we use transfer learning to exploit pre-trained FastText urdu word embeddings and multi-lingual BERT embeddings for our task. Finally, we experiment with four different variants of BERT, and we show that BERT, xlm-roberta and distil- Bert are able to achieve encouraging F1-scores of 0.68, 0.68 and 0.69 respectively, on our multi class classification task. All these models exhibited success to varying degree but outperform a number of deep learning and machine learning baseline models.
"Muhammad Haroon Rasheed

Reading Comprehension Question Answering for Urdu"	"Question Answering(QA) is an active research topic for multiple languages in the field of Natural Language Processing (NLP). In different Asian and European languages, information retrieval systems are proposed in the form of supervised, semi-supervised and unsupervised systems. QA system is growing day by day, as exact retrieval of information is the main goal for every language. Recent systems deal with the retrieval of relevant information, instead of exact information retrieval. For other languages, QA-based systems have been proposed for information retrieval but for Urdu, limited work has been done. So, in this research work, we are handling the QA system for Urdu.
To the best of my knowledge, limited work has been done on Urdu, and the QA system for Urdu is also lacking So, there should be a system for Urdu too, which can handle querying from data. In the QA system for Urdu, the main goal is to handle the problem of querying from structured data. In this system, the user will put down his query in natural language (Urdu), then the system would retrieve relevant paragraphs from structured data, after that answers will be retrieved from that paragraph, which is a span of text. At the end most exact answer, the system will retrieve in natural language. To achieve our goal we have used the Transformer models. Department of Computer Science Faculty of Computing, NUCES-FAST."
"Arham Abdullah Malik

Quadrant-based Sequential Filtering Model for Efficient Content Based Image Retrieval"	With recent trends and improvements in CBIR techniques, the efficiency is usually neglected in favor of precision. This creates a work overload on systems with weaken specifications. To counter that, a novel algorithm to reduce time and memory consumption for the feature detection, extraction and matching of both global and local CBIR techniques, Quadrant Based Sequential Filtering (QBSF), is proposed. In this algorithm, query images and sample images in image data-sets are split into equal quadrants with CBIR techniques applied to each quadrant sequentially, with the results of previous quadrant intersected with the results of the current quadrant. After experimentation, it was shown that the technique is effective in time consumption reduction of approximately 30% for global CBIR techniques with color as the main feature and for local CBIR techniques with local feature focal points, points of interest, in the first two quadrants.
"Kinza Rubab

Automatic Multilingual Detection for Local Languages"	"Social media shows the rapid growth of modernity; with time, the amount of data increases over the Internet. The problem of language detection is one of the current challenges in Natural Language Processing (NLP). The goal of similar language detection is to correctly and accurately detect the language of text written. It plays a vital role in several Natural Language Processing (NLP) applications; it is frequently used as preprocessing technique. Multilingual detection is detecting a natural language of a text based on the sentence’s content. Multilingual detection is challenging when the input is noisy data, low resource languages, and languages are highly similar. Similar language detection remains a challenging  task in NLP. In this research work, we discuss sentence collection in a corpus of Pashto, Punjabi, Saraiki, and Urdu languages. We proposed a novel dataset that contains sentences of low resource languages; Our dataset contains 21000 sentences. The corpus of the four languages compiles from newspaper websites. First of all, we performed similar language detection without using machine learning techniques; we detected language by the dictionary-based method. Four dictionaries are extracted for each language using the training dataset. Our dictionaries-based process does not perform effectively because of limited words in dictionaries. Secondly, we extracted Features by TF-IDF vectorizer. To detect the sentence’s language, We use five different classifiers: Decision Tree, K-Nearest Neighbours (KNN), Logistic Regression, Neural Network, Naive Bayes, and Random Forest. Few of the classifiers performed well. Thirdly we extracted word embeddings by the Word2Vec technique, and to detect the language of the sentence, we used machine learning classifiers few of them performed well. Fourthly In our proposed approach, we proposed a deep
learning model with Bidirectional Encoder Representation from Transformers (BERT); we pre-train our multilingual BERT for similar multilingual detection. BERT takes advantage of the mechanism of self-attention to integrate contextual information. We show through our experiments that our proposed approach produces notable performance improvement. Keywords: Automatic Multilingual Detection, Local Languages, Word Embeddings, Highly Similar, Transformers, Classifiers."
"Anoosha Imam Bokhari

Efficient Content Based Routing on Network layer"	"In recent years internet of things (IoT) gained popularity due to rapid deployment in various IoT networked control solutions. For communication within and across data centers efficient publish subscribe middleware is extremely desirable in solutions with content based routing. There is a great need to exploit Software Defined Networks capabilities to perform filtering of event directed to network layer for securing network devices. Achieving optimized path, low end to end latency and throughput are challenging problems in SDN. Limited number of bits areavailable at hardware switches to represent filtering is a major drawback in content-based routing. Due to which expressiveness of content-based routing suffer in terms of false positives. Underlay network are API dependent such as OpenFlow and it is a protocol dependent API. It has fixed header size and do not allow any processing at switches and it is not reconfigurable. The next generation of network devices envisions providing reconfigurable hardware devices by programmable data plane known as p4. P4 protocol is header independent and allows processing at switches and it creates its own API. P4 also have few challenges such as to achieve  expressiveness in term of false positives P4 with SDN that scarifies the key objective of content- based routing that is decoupling of publisher and subscriber. The focus of this thesis is to provide an efficient methodology to achieve expressiveness in content based routing. Expressiveness in terms of false positives that is a subscriber received uninterested content and false negatives such that the subscriber does not receives the desired content. Such expressiveness can be realized
by using spatial indexing technique for content mapping in P4 with SDN which will result in 66.6 percent decrease in the false positives and maintain zero false negative. The latency of thenetwork is negligible."
"Muhammad Yasir Masood

Demand-Side Load Forecasting in the smart grids using Machine Learning Technique"	Electrical load forecasting is still an open challenge due to various factors like temper- ature and weather and hanging the trends day by day. In this age of Big-data, efficient handling of data and getting valuable data from much raw data is necessary. Through IoT devices and smart meters, we can capture data efficiently. In comparison, the raditional methods having the issue in handling the nonlinear data. This research’s primary focus is to take big data with many irrelevant and redundant data using dataining techniques. Firstly, extract the features from many data and then select the meaningful subset through data mining techniques. The proposed solution consists of two levels for forecasting.The selected subsets of data go first into the DCEN network, and then it will provide valid input to the ILFN network. Both networks have issues of overfitting in the existing approaches. We try to cover this issue by using some classic or conventional neural networks. This research work uses the 3-tier architecture, which contains the cloud layer, fog layer, and edge servers. The classical state of art prediction schemes mainly uses the 2-tier architecture with the classical models, resulting in low learning precision and over-fitting issues. In the cloud layer, we have all the extensive data that we get from the smart meters. The network deployed here is the daily consumption electrical network, which will have the all-possible factors regrading to load forecasting. We cannot rely on one forecasting network because a too large estimation\may lead to energy waste, while a too-small value can cause an insufficient supply. We get a valid input for the intra-load forecasting network, mainly used for load forecast- ing in our research work. The model’s overfitting was the main problem we address in the Intra load forecasting network through the data’s subsampling and oversampling. An overfitted network generally has good results at training data, but it misbehaves in real applications. We aim to use a deep neural network for future predictions because the traditional methods had overfitting. Through this technique, we can get a better prediction of the load. In our proposed approach, we have first used more weather features that are not used before to predict the load. We have also included the holiday’s data in our re- search to get a better prediction of load on the holidays as well. We have done many experiments on this and found that the Support vector regression performed well in our case. We have got the 5.055 Mape and the 0.69 RMSE, 0.37 NRMSE, 0.0072 MSLE, and 0.86 R2 score values. It is better than other baseline methods. This study uses a real-world power industry data set with over 1.4 million load records. The experimen- tal findings show that the method is the effect of the proposed method.
"Rana Faisal Hayat

Multilevel DDoS mitigation in IoT using block-chain"	The IoT devices is a current wireless communication technology. IoT devices containsa series of sensors nodes that are arbitrary distributed in a specific part for recogni- tion and monitoring physical phenomena that are hard for humans to monitor, such as pressure, humidity, and temperature. However, the increase in the number of IoT devices also raises the security of IoT devices. The DDoS attack and the botnet at-tack have been observed that create an unacceptable loss of industries that depends on IoT devices. The maximum IoT devices are manufactured off-shore, the identityof IoT devices will be ensuring are a very big challenge. Tempering the IoT devicesand create a bot and then perform the DDoS attack, is a very big challenge. The exist-ing defense mechanism of a DDoS attack prevents the attack from only one side, theattacker creates a bot and compromises the devices, and sends huge information tothe server. Emerging technologies such as distributed blockchain-based mechanisms and smart contracts allowed to share of attack information using different lists in fully distributed ways. In this paper, we have proposed a multilevel DDoS approach (ML-DDoS) to protect the devices and server using blockchain technology. Verification of IoT devices by comparing the unique ID using the blockchain. Hyperledger caliper is selected to implement the blockchain-based framework, and the performance is evalu-ated and analyzed.
"Usama Abdullah Ejaz

Role Inference from Big Datasets."	Big data is ubiquitous to handle and deriving meaningful insights from it is hard. Finding patterns from a complex and huge amount of data is of very importance. For solving complex problems over graphs, representation learning techniques are used to generate low-dimensional embeddings. Representation learning or graph embeddings are low-dimensional vectorized features which can be learned using simple machinelearning classifiers for solving real-world problems i.e., role classification. In the past, deep learning techniques like GNN(Graph Neural Network) and GCN(graph Convo- lutional Network) were the most optimal solutions we were having for learning graph representations. This thesis employs a novel method for learning graph representa-tions, for which we proposed IEER, or Inferring Embedded Email Roles, that provide low-dimensional vectorized features by acquiring local structural information for eachnode. Despite other techniques that have focused on node embeddings only, we have tried two different techniques to improve the performance of the base framework EM-BER, , or EMBedding Email-based Roles (which also generates graph embeddings forrole inference) and reported their failures and achievements. One of which is introduc-ing edge embeddings with node embeddings to make the graph more feature-rich and the second one is understanding different embedding techniques and their nature of generating representations to replace the EMBER’s technique with the one which best  fits with the nature of the problem. For Edge attributed graph for generating embed- dings, we first construct a behavior graph. Using the behavior graph, we easily obtain  the embeddings of the edges same in the way as for nodes. These rich low-dimensional features of both nodes and edges fuse together to  create  more  feature- rich embeddings.   But unfortunately, this  technique didn’t leverage the  classifier  to outperform EMBER contrary to our expectations. Then, we move towards the methods behind the gener- tion of embeddings. There we come to know that the property of generating embed-ding techniques varies and is dependent upon the nature of the problem. From recent literature, we identified another embedding technique that significantly improves theperformance of EMBER. Using the identified technique named Characteristic Function Sampling, IEER achieved a significant improvement of 94% accuracy.
"Usman Arif

Detection of Malware Using Machine Learning"	"In recent years, Cyber-attacks subjected to diversed range of cyber threats at different scenarios. At present, the zero-day attack causes a drastic range of security threat
environments since its impact on software performance. To reduce cyberattacks security algorithm is implemented. However, the existing cybersecurity algorithm exhibits
a higher FP value which impacts performance accuracy. In this research proposed a SCIV based machine learning algorithm for attack classification. The analysis is based
on the consideration of the Kaggle dataset. The proposed Stacked Classifier Integrated Voting (SCIV) utilizes a voting mechanism for the classification of attacks. The analysis
expressed that the proposed SCIV exhibits improved attack classification performance.The proposed SCIV exhibits effective performance in terms of FP value. The analysis
expressed that the proposed SCIV classifier provides higher TP and FP values. In thecase of FN and TN decision tree provides significant performance, The analysis of FN
and TN values stated that the performance of the decision tree is higher. The FN value measured for the decision tree is a minimal value of 756, where AdaBoost, ANN, pro-
posed SCIV and SVM provide 1109, 1304, 1596, and 2555 respectively. The TN analysis stated that the decision tree provides a higher TN value of 21871 which is significantly higher than AdaBoost, ANN, proposed SCIV, and SVM. Through analysis, it is concluded that the proposed SCIV exhibits superior performance for positive prediction with the proposed SCIV classifier and negative prediction with a decision tree. Further, the analysis expressed that with proposed SCIV proposed SCIV classifier significantly reduces FP value. The estimation of ROC proposed SCIV with all classifiers lies within the range of 0.8 - 1. This implies that the proposed SCIV exhibits significant perfor mance for the classification of attack. The analysis of F1-Score and precision value also implies that proposed SCIV achieves higher F1-Score and precision value of 0.95 and 0.99 respectively. Through analysis it is concluded that proposed SCIV method is effective for zero-day and polymorphic attack."
"Sadia Farooq

Adverse Drug Reactions Prediction with Genomics Data"	Adverse Drug Reactions (ADRs) are undesirable, uncomfortable, and harmful effects of drugs. These ADRs are harmful to human health and can also lead to financial and economic loss. The LINCS L1000 provides the gene expression data that measured gene expression changes before and after human cells were treated with over 20,000 small molecule compounds, including most FDA-approved drugs. We present an approach using the integration of Gene Expression, Chemical Structure, and Gene Ontology term Enrichment Analysis to predict the time-dependent adverse reactions of drugs. We applied several machine learning techniques to multi-label classification problem and to predict the adverse reaction of drugs. We reported Hamming Loss, F1-Score as the evaluation metric for applied models. Mechanism of action of drugs, ATC classification, Target interactions of drugs is observed for downstream analysis. The drugs giving more side effects at 24 hours’ time point have more target associations results in more side effects. 
"Tooba Nadeem

Safe drug combination prediction using GCNN on PPI Network"	Using multiple drugs in combination to treat complex diseases has proven to have multiple advantages over monotherapy. Drug combinations are widely used to treat complex diseases and overcome drug-resistance. Safe drug combinations prediction is a very complex problem because it is difficult to analyze and validate thousands of drug combinations for thousands of diseases experimentally. To reduce extensive clinical testing, drug combinations are being predicted using computational approaches. Several machine learning approaches have been implemented to predict safe drug combinations. Among them are network-based protein-protein interactome approach, network-based drug-drug interaction etc. These methodologies have achieved some success in predicting drug combinations. However, little work has been done using Graph Convolutional Neural Networks (GCNNs) for the prediction of safe drug combinations. We propose applying GCNNs on PPI network. The representations learned by Graph convolutions are used to get protein functional clusters. Safe drug combinations are then predicted on the basis of distance between drug targets in clusters. The results obtained show that the drugs whose drug targets have smaller distances from the root are safe to take in combination, while those with greater distances are mostly unsafe drug combinations.
"Anabia Alam

Quantification of Cancer Through Smartphone Captured Histopathology Images"	Digital Pathology (DP) has paved the way for early cancer prognosis, reducing on cancer mortality rate. However, recent developments in DP have been done by use of Whole Slide Scanner which is quite costly to be installed at local hospitals of developing countries. Such economic setbacks create disparity for research and growth in the health sector of developing countries and the rest of the world. To overcome this obstacle, one  of  the  possible alternatives could be to use smart phone to capture images instead of whole slide scanners. Smartphones are fixed at the eye piece of the microscope through which the image is taken. In this work, we assess the possibility of using cell phone images instead of Whole Slide Images (WSI) to perform deep learning infused quantification. Our pipeline digitizes two of the manual assessment tasks on slides, cancer classification, and mitotic cell count. While working with local visual features obtained from patches, we performed binary classification followed by regression to predict mitotic count. Our results looked promising with EfficientNet B4 achieving 0.78 AUC-ROC and regression on mitotic count scored loss of 0.21 at validation data. These findings indicate that smart phone captured images can be researched and explored further to be used as cost-effective solution for Artificial Intelligence-based cancer prognosis in place of WSI scanners.
"Muhammad Uzair

Identify Infected Areas During Pandemic"	Many patients have been reported with infectious and viral diseases back in December 2019, which now, is known as Covid-19. As of 11 June 2021, more than 175 million  cases have been reported nearly in 222 countries and territories, resulting in more than 3.7 million deaths. Covid-19 was declared as a global pandemic by the World Health  Organization (WHO) and for the governments all over the world, public health emergency was declared as one of the top concerns. Still, the condition is not a s  good  as it  should be because there is no sign of disease being under control in many regions around the globe even after the of its vaccine. In this paper, the study intends to help the government and people by identifying infected areas. For this, we proposed to  use data from two different and independent domains, which are social network (cyber world)  and Real-world Facts, for information about location and other aspects and establish a relationship between them, in such a way, that they will identify the  Infected  areas. The  purpose is to identify the infected area so that transmission of the diseases can be minimized, as the disease is mainly transmitting through physical contact. We extracted the data from a different medium of social network and from the  different  official website which are publicly accessible. Based on these, we use the GCN for the prediction of  hotspots by establishing an efficient relationship between the two domains using the. As compared to the other method our method has achieved very good performance and we expect that our work will be a contribution in the battle of controlling the spread of Covid-19.
"Maryam Baig

Semantic Minhashing"	Measuring the similarity between words, sentences, paragraphs and documents is an important component in various Natural Language Processing tasks such as infor- mation retrieval, document clustering, word-sense disambiguation, machine transla-tions and text summarizations etc. Recent approaches, Bert, Elmo, Roberta use neuralnetwork in order to obtain embedddings. These models require tremendous amount of data and training time to produce state of the art results. Other semantic similarity measures exploit the knowledge bases such as WordNet to perform their estimationsusing different approaches like shortest path, measuring syntactial similarity of the information content etc between words or short phrases but not longer sentences. In computer science and data mining, min-hashing is a technique for quickly approximat-ing the Jaccard Similarity Score between two sets. This approach has been widely used in computing lexical similarity of the documents. Our aim is to use min-hashing to capture the emantic score of  the extended vectors enriched with information obtained from the WordNet in the original word vectors depending upon different relationships like synonyms, antonyms, hyponyms and hypernyms such that the lexical similarity is increased on thebasis of semantic information. These enriched vectors are passed to min-hash algorithm to compute  the small representational signatures of the vectors, reducing the curse of dimensionality. The similarity of these signatures is equivalent to the semantic score between the two  documents. Our approach gives 64% accuracy on a low resource machine on MRPC and SICK dataset.
"Ali Akbar Asif

Graph Based Text Data Summerization"	In this new era, where huge information is accessible on the internet, so quick mechanism is required to summarize large text data. It is very difficult for human beings to  understand large information in short time. It is nearly impossible to manually extract a summary from the large text. To reduce human effort automatic summarization is very  necessary. Text summarization is the process of shortening a set of text data that provide concise information and reduce reading time. There are two types of text summarization  one is extractive and the other is abstractive. The extractive approach selects important sentences from a given document. The abstractive approach understands text semantically  and then converts it to shorten summary of that text. In the extractive approach, redundancy issues occur, and the final summary not semantically consistent. In abstractive approach ignores the main context of the text. In our proposed solution I can enhance the both extractive and abstractive summarization approach in one framework. An extractive  approach (NLP) model is used to extract high-level hidden features [5]. In the abstractive approach, use attention-based encoder-decoder recurrent neural networks to achieve the sequence of sentences. The extractive-based model provides the highest salient score of important sentences and the abstractive-based model provides a semantic analysis of sentences. The system provides a concise and consistent summary of text data on the basis of Semantic analysis and salient score. Our proposed approach eliminates the limitations of both extractive and abstractive text summarization approaches.
"Nauman Akhtar

Aggregating Diverse Text Data Using Apache Spark"	Nowadays, it is becoming a challenge for us to organize the text data before processing and performing analysis, due to the rapid increase of amount of text on internet. The data is represented in structured and unstructured forms. In recent times, a lot of researches have been made to analyze the data using modern big data techniques and metho -dologies. Before performing any analysis on the text data, we have to organize the data in some structure. Therefore, in this research, we have focused on managing clustering  and aggregating the text content on web which include social media, blogs etc. while streaming from different resources. The problem arises when performing aggregation using  extractive approach, word with word matching to summarize sentences. Therefore, we have proposed DCS: Document Clustering and Summarizing, a web based a tool, which  clusters and processes the streaming text data using Apache Spark. Apache Spark is an effective tool for processing stream data. We are considering the social data of different  topics which includes the news and discussion of pandemic situation of COVID-19 between different users within tweets, social posts, websites etc. We develop algorithms to  create words-based-graph using the text data and apply compression on graph to summarize our text data. Further, we create effective sentence from the summarize clusters. Our tool, DCS, shows the comparison of summarized words with the original words in the documents and also provides the analysis of words, clusters and the generated sentences. Our proposed approach resolves the problem of aggregating text data while processing the data in streams.
"Humera Sabir

Estimating Physiological parameters using Photoplethysmography (PPG) signals for Health Care"	Hemoglobin is the iron containing protein in red blood cells which carries oxygen from lungs to the tissues of rest of the body. Hemoglobin measurement is necessary for the diagnosis of anemia, a condition caused by l ack  of r ed  blood  cells  to  carry Oxygen.Hemoglobin estimation is a key step to be performed before the blood transfusion of thalassemia patients.Hemoglobin tests are performed to assess the response of iron supplement treatments. Clinically adopted methods for Hemoglobin estimation are mostly invasive and typically involve blood draw of about 3ml.There are some medical devices like Masimo Pronto for non-invasive measurement of the hemoglobin level.Noninvasive methods for Hemoglobin estimation are based on photoplethysmog-raphy (PPG) based techniques. photoplethysmography (PPG) is an optical method to measure blood volume changes in successive heart beats. PPG signals can be obtained from fingertip videos using smartphone sensors.Smartphone offers the possibility of  affordable and portable point of care tool using photoplethysmography (PPG) technol-ogy. The ubiquitous use of smartphones make them an excellent choice to use as an alternative to non-invasive photoplethysmography (PPG) based medical devices how-ever signals obtained from smartphone camera is often noisy and are susceptible tomotion  artifacts ans light conditioning.Processing of video data obtained from smart-phone camera is significant and important step for efficient features selection from PPG characteristics features. In this study, we investigate the feasibility of smartphone PPG based noninvasive es-timation of Hemoglobin using a deep learning based algorithm which eliminates the need of manual feature extraction and selection process used in existing smartphone PPG based hemoglobin estimation systems.We collected data from more than 200 sub-jects with age ranging from 6 months to 57 years having a diverse range of Hemoglobin (4.3 gm/dL - 17.1 gm/dL). The proposed approach estimates hemoglobin level with an accuracy of 1.90 when compared with Complete Blood Count(CBC) test a gold standard laboratory method for hemoglobin estimation.Our system enables patients toestimate their blood hemoglobin level at anytime using only a smartphone.
"Mehran Khan

Scalable Mining of Connected Data"	In this era of modern technology, different new techniques are being introduced in order to make many processes scalable. Recruitment of employees in a company or an organization is one of those tedious tasks where digital transformation is much needed. One of the prime purposes of a company is to make this piece of work cost-effective and time-efficient. This task can be done using minimum time through the electronic recruitment process, making it easier for the employers to hire candidates for a job. It actually involves the process of automating the hiring of candidates and efficiently ranking them according to the specific job description (JD). The objective is to find the best suitable candidate for any particular job.This paper aims to use Localitysensitive hashing (LSH) for automating the process of ranking in e-recruitment. LSHis a technique that hashes identical input items with high probability into the same buckets. To present a set-based job-resume matching, we avoid similarity computations that are explicit and identify the required sets directly via Dynamic Weighted Locality Sensitive Hashing (DWLSH). As there are dynamic weights for each section of the resume, we introduce the concept of labels instead of actual weights to cope up with the mechanism of resume filtering for the same job description but with different weightsin  each search. The proposed approach can rank the resumes according to the given job description, thus making the hiring process faster. Furthermore, this technique results in the ranking of resumes in sub-linear time avoiding the pairwise comparison of features of resume and job description.
"Muhammad Yasir Rehman

User personalised taste profiling using social media analysis"	"In recent years the social interaction between the users has grown exponentially. So, overloaded information about the users and their preferences depicts rapid changes in behavior and daily life requirements. The researchers need to develop a system to nalyze user preferences and help service providers or product owners to present their products or services to the targeted  audience.  However,  Twitter  is  a  platform  that  provides user’s multiple interests. Most people read and write content on short text  micro-blog platforms based on their interests. So, The focus of our research is to find the multiple interests of users by using short text micro-blogging and create a cluster of those users who has similar interests. Furthermore, we will analyze user’s tweets for context building approach and find multi interests in a tweet. Along with, We target  specific tweets that are targeted interest of product owner and put these users in topic wise clusters. These clusters can be used for the  product  owners  to  market  their products. Our framework processes short text content that is posted on different social media forums we make user interest-based data analysis. Hence, the development of our methodology, will integrate multiple neural network approaches of user tweeter data with some of the common state-of-the-art models like LDA, LSA, and NMF. After training our mentioned models on our corpus We measured the performance of our proposed method by using an accuracy matrix for the model and validate this accuracy
with Kappa Scores by human validation."
"Muhammad Rizwan

A Two-Stage Cache-Based MeshJoin For Semi Stream Data"	Real-time data warehousing(RDWH) is gaining popularity in the field of business analytic.Business owners and organizations increasingly adopt real-time data warehousing (RDWH) due to its capability of analyzing and processing fast data stream in near online fashion.An Offline data-warehouse (DW) technique has not streamlined to the recent business needs. In real-time DW, all updates are instantly reflected to the (DW) and integrated in real-time method. Building a RDWH, requires processing of user’s transnational streaming data along with master data. Processing of streaming data requires to be processed with minimal latency so that business owners can analyze their business situations in near real-time. Semi-stream is a process which joins incoming fast data streams with master record stored on disk. In semi-stream join algorithms, we are dealing with a high rate of incoming stream tuples that need to be combine with low-speed disk-data, under the restriction of limited memory. Currently in all the semi -stream join algorithms like MeshJoin, RMeshJoin, Hybrid-join, and CacheJoin, all the optimization efforts have been done according to a single table from master data. The challenge becomes more complex when a stream is re-quired to consolidate with multiple objects in master data. In this research, we are working on a new feature of disk -based two-table join with a streaming data using the state-of-the-art Two-Stage Cache-Based MeshJoin(TSCM). For this, we are extending CMESHJoin which is the most up-to-date semi stream algorithm proposed in streamprocessing.
"Nayab Mishal

Product Demand Forecasting Using Online Customer Review Data"	Demand Forecasting refers to the future prediction of product popularity. Product popularity is extracted by analyzing customer behavior and reviews for the product. From extensive literature study it is cleared that customer review data have more po-tential to generate accurate demand forecasting results as compared to social media,news articles, and google trends data. Existing research work has not employed the customer reviews with time stamped feature for demand forecasting so far. Research studies in e-commerce domain have mostly targeted the needs of customer. However, with the increasing growth of e-commerce market, retailer need to stay updated with the customer behavior to control demand amplification. Demand forecasting helps the customers and retailers both in making better decisions timely.This study aims to forecast the demand for online retail products using time series cus-tomer reviews data. A framework is proposed to achieve the desire results. Proposed framework consist of five phases, each phase plays a crucial part in accomplishing the final results. Series of phases involves, e.g data extraction from a website, data pre-processing, exploratory data analysis using lexicon mining, popularity analysis using Latent Dirichlet Allocation (LDA) and lastly using Autoregressive Integrated Moving Average (ARIMA) model for demand forecasting. The ARIMA model is chosen for de-mand forecasting after comparing their performance it three other forecasting models.Other forecasting models include Moving Average (MA), Random Forest and Long Short Term Memory (LSTM). To evaluate the performance of all models, Root Mean Square Error (RMSE) is used. ARIMA with least prediction error is selected for de-mand forecasting. We have tested our proposed framework on customer reviews of electronic mobile device of different brands. The mobile phone product is chosen, because of its short shelf life and sudden changes in demand. The demand forecasting results of different product found to have a promising accuracy. It is examined that demand forecast is an absolute need for the retailers to stay updated with the product popularity. In this way it help the retailers in dealing with critical shorta -ges and costly overstock situation of products. It is found by different model comparison that the machine learning model ARIMA is more appropriate for demand forecasting.  In future, the demand forecasting results for a particular product can be used to validate the price forecasting results.
"Mohammad Bilal Aamer

Extending Meta Heuristic Algorithm for Data Clustering"	Data clustering has been studied for many decades but still it is far from a trivial and solved problem. Some of the challenges in document clustering are selection of appropriate clustering methods, assessment of the quality of the clusters and associate meaningful labels to each final cluster. There are in general two broad categories of clustering algorithms; (I)partition (ii) hierarchical. In the partition category, existing approaches have used K-mean, which is linear in the number of objects to cluster. One of the main drawbacks in the k-Mean algorithm is that it traps into local optimal solutions. Previous approaches proposed a global optimal solution by embedding a k-Mean solution to Black Hole Algorithm. This approach utilizes the global optimal state of Black Hole algorithm as it is a Meta Heuristic algorithm. So, the retrieval of documents is fast and optimal by implementing K-mean and Black Hole respectively. The challenges in the black hole algorithms include the input data type. For now, the algorithm just only supports textual data. Another issue with Black Hole algorithm is that it does not decide the K cluster to make and the centroids are selected randomly. In this thesis we have proposed an enhanced Black Hole algorithm which tackles the problem of cluster determination and optimizes the algorithm.
"Saad Naeem

STRATA: Word Boundaries & Phoneme Recognition From Continuous Urdu Speech using Transfer Learning, Attention, & Data Augmentation"	Phoneme recognition a largely unsolved problem in NLP especially for low resourced languages like Urdu. The systems that try to extract the phonemes from audio speech require hand labeled phonetic transcriptions. This requires expert linguists to annotate speech data with its relevant phonetic representation that is both an expensive and a tedious task. In this paper we propose STRATA, a framework for supervised phoneme recognition that overcomes the data scarcity issue for low resource languages using aseq2seq neural architecture integrated with transfer learning, attention mechanism, and data augmentation. STRATA employs transfer learning to reduce the network loss in half. It uses attention mechanism for word boundaries and frame alignment detection which further reduces the network loss by 4% and is able to identify the word bound aries with 92.2% accuracy. STRATA uses various data augmentation techniques to further reduce the loss by 1.5% and is more robust towards new signals both in terms of generalization and accuracy. STRATA is able to achieve a Phoneme Error Rate of 16.5% and improves upon the state of the art by 1.1% for TIMIT dataset (English) and 11.5% for CSaLT dataset (Urdu). Finally we use k-means clustering to cluster all the honemes into 63 clusters (Number of phonemes in Urdu) in an unsupervised fashion and label these clusters using STRATA network to generate more labeled data with an accuracy of 63.5% (k-means) which surpasses the performance of unsupervised and semi-supervised techniques in the same category.
"Majid Iqbal

Transfer learning for speech Recignition in Urdu Continuous in Urdu "	Speech is the most basic means of adult human communication. As technology advances and increasingly sophisticated tools become available to use with speech signals, scientists can study these sounds more effectively, and invent new ways of applying them for the benefit of humankind. Speech signals are converted into text and the processis known as speech recognition. It requires huge amount of data in form of audio and text. High level languages usually contain such data in abundance and can train their models easily. The dataset and resources for a low resource language like Urdu are scarce. Speech recognition is the ability of a machine to identify words and phrases in spoken language and convert them into plain text. So far speech recognition has been implemented for higher resource languages like English, Chinese etc. These languages have more training data ranging up to several thousand hours. Furthermore, high level resources are used to train these languages. Urdu being a low resource language does  not contain sufficient training data. The number of resources available to build a speech recognition in Urdu are also fewer. We are working on transfer learning to develop speech recognition for low resource language Urdu. Transfer learning from languages like English, Chinese, French etc. can significantly boost the accuracy for under -resourced Automatic Speech Recognition (ASR) systems. We have developed an ASR for Urdu using transfer learning. We applied transfer learning to pre-trained models of English and Chinese. This technique reduced training time by up to 50% while requiring less amount of data and lower GPU memory requirements. We were able to achieve a 23% Word Error Rate (WER) with transfer learning which would not have been possible without transfer learning (87% WER).
"Usama Khalid

Language Model for Roman Urdu Trnsfer Learning"	Neural Language Modeling (NLM) is the current state-of-the-art technique to address numerous NLP tasks such as sentiment analysis, Machine Translation (MT), text summarization, spelling correction, natural language generation etc. NLMs can also be used in chatbot and speech recognition systems to considerably improve their performance. Roman Urdu is a very popular language on social media platforms and chat apps. However state-of-the-art NLP techniques cannot be applied to Roman Urdu, because it is an extremely low resource language. Previous research in Roman Urdu mainly aims to solve very specific problems mostly based on transliteration and sentiment analysis. However none of the works till date has focused on generalizing techniques to address a wide a variety of NLP tasks.In this thesis we will use the code-switching property of Roman Urdu and learned rep- resentations from a high resource language like English to show that cross-lingual transfer can be enabled for any low resource language given that it shares lexical similarity with a high resource language. To enable this cross-lingual transfer learning we introduce two novel techniques namely, vocabulary augmentation and vocabulary extension. To enable pretraining of the models we propose a novel corpora of 3M sentences for Roman Urdu scraped mainly from social networking sites such as twitter. To evaluate performances of models on downstream NLP tasks we also propose a novel GLUE benchmark for Roman Urdu. We train and evaluate monolingual, multilingual and bilingual models of Roman Urdu on various NLP tasks and achieve up to 20% improvements in F1 score compared to previous techniques.
"Aizaz Hussain

SiameTron: Speech synthesis for low resource language Urdu with few shot learning"	Deep learning approaches, despite good results, are data-hungry. Good perfor- mance for text to speech synthesis can be achieved for high resource languages, how ever, for low resource languages, these techniques fail to give good results due to the quantity and quality of data. Tacotron 2 architecture has remained the state of the art model for text to speech synthesis for many languages because its attention-based seq-2-seq architecture enables it to learn co articulation and duration properties directly from text and speech. In this research we proposed a novel approach to apply metric-learning of the few-shot learning for tacotron 2 architecture using the Siamese network. The proposed technique is trained on low data settings hence providing high fidelity speech for low resource languages. The evaluation results show that the proposed approach with the adaptation of a system coupled with a WaveGlow vocoder outperforms the conventional deep neural networks for text to speech synthesis. A Mean Opinion Score of 4.1 was achieved for 10 hrs of training data and 3.5 for 5 hrs of training data with 95% confidence.
"Tayyaba Arshad

Medical Image Generation using Deep Learning and Generative Adversarial Networks (GANs)"	"Deep neural networks have gained significant importance in the last few years due to their remarkable performance in many fields like speech recognition and computer vision. Also in recent years deep networks have gained popularity in analysis of med-ical images. Because, they help in extracting the relevant information from different types of medical images, and use this information for the diagnosis and prognosis of different pathologies. However, large annotated medical data is not available due to the legal concern regarding the patient privacy issues, this factor has limited the per-formance of many deep learning models in medical image analysis. Moreover, deep networks require more annotated datasets to avoid the overfitting issues. Annotation is typically manual expensive, therefore, the need of generating the medical images have gained the attention of many researchers which helps in term of diagnosis of diseases, which needed computer aided system to understand image related structure and to extract the meaning. So the objective of generating the synthetic medical images in view of real data is much more appealing. The application of image augmentation methods based on generative adversarial network has shown to be a better frame-work for generating synthetic realistic images than many other traditional approaches of augmentation. Furthermore, generative adversarial networks comparatively gener-ate more realistic synthetic medical images equivalent to annotations. Our objective was to generate more realistic synthetic medical images using generative adversarial networks, with focus on looking into data specific distribution instead or random distribution to get the desire output image, along with modification in objective function of GANs. Finally, we have evaluated our model in term of qualitative and quantitative
analysis."
"Parisa Salma

Multi-Domain Constrained Image Registration Using Deep Learning"	In this thesis, we work on medical images to detect deformities in humans. To detect tumors in the brain, physicians take multiple images of patients taken from different angles and then detect the deformations by aligning images using naked eyes. Image registration is a technique used to align two images automatically. There are two types of image registration, one is image unimodal image registration, and the other is multimodal image registration. We work on multi-domain along with multimodal egistration, in which our goal is to align two images based on different modalities. Multimodal Image registration is challenging because different modalities in images do not have the same characteristics due to variations in the tissues. Many researchers have already worked on it before. Some researchers have used conventional approaches for image registration, which are time consuming and are not too effective. Other researchers have used deep learning techniques which have performed relatively better. Currently, Generative Adversarial Networks (GANs) have given state of art performance on image registration tasks. However, most of the work has been done on uni-modal and multimodal image registration only. Existing researchers have not worked on multi-domain image registration. In this thesis, we try to generate synthesized registered image and use GANs to do multi-domain image registration. We propose a new loss function to achieve this goal. Our generator is trying to generate registered image of input image such that it belongs to given output domainlabel. The image registration dataset is not publicly available so, we have prepared our dataset from RIRE dataset slices. We have prepared 20,000 dataset of multidomain images. Our mse loss on test set loss for multidomain image registration is 0.1315 which is currently state of art because no one has worked on this task before.
"Sheikh Abdul Saboor Uz Zaman

Predicting Citation Gain Pattern Using Network Embedding"	In this modern academic world, predicting the citation counts of academic papers is of considerable significance for scientific evaluation and of great importance in guiding funding allocations, recruitment decisions, and rewards. With the growing number of published scientific papers worldwide, the need to evaluate and assess the quality of research papers is increasing. Scientific fields such as scientometrics and bibliometrics establish quantified analysis methods and measurements for evaluating  scientific papers. In this regard, one of the most important metrics to evaluate the paper is the number of citations. Existing studies have mainly focused on predicting the citations count. Previous studies show the effectiveness of machine learning algorithms  and generative models to observed citation patterns in scientometrics. In scientometrics, an important problem is to predict the Citation-Gain-Pattern (CGP) of a paper. CGP can be represented as a curve that can be derived from a particular equation.  Our aim to predict the Citation Gain Pattern (CGP) of a paper as a curve at the time of publication using a network embedding, rather than predicting the citation gain at each point. CGP tells us about the different trends of citations like upward, downward,  cycle, etc.CGP is the analysis of citation count (CC) related to time. CGP is predicted after publication considering Author, journal related citations, and other features, no one explored the paper ‘reference list’ to predict the citation of a paper. using the mprehensive data set of Aminer containing 3,079,007 records. The experiments have been performed for high and low-ranking journals with respect to Impact factor separately. Our results show that the citation curve for high ranking journals can be predicted  more accurately than low ranked journals, as publications in good journals are done by authors with high experience and h-Index in hot research topics are trend to publish in high impact journals. The researchers tend to follow the research of prestigious authors and to cite the publication from a good venue, and journals lead to receiving a large number of citations.
"Zawar Khan



Detecting Road Surface Condition Using Smartphone Sensors"	Bad roads are a public annoyance, and as a result, the people are subjected to passenger discomfort, vehicle damage, and the possibility of accidents. The circumstances associ- ated with the poor road-related factors in the United States contribute to over 22,000 of  the 42,000 traffic deaths that occur each year1 . Despite our constant complaints about poor road conditions, we have no efficient mechanism to identify or report them on a large scale. This paper explores the use of smartphone devices for the detection of road conditions and road anomalies, and rate the specific path from the user feedback. We present a novel approach by utilizing the machine learning algorithms to monitor the road infrastructure by collecting sensor data from the smartphones (accelerome- ter, gyroscope, GPS) present in the pocket of the user in the vehicles. This proposed system, which we call Detecting Road Surface Condition Using Smartphone Sensors, uses the public vehicles, collecting the vibrational data of the vehicles using the ac- celerometer and the gyroscope sensor along with its location from the GPS sensor for different road conditions, and then we present the algorithm to process the data for cleaning. The data will be collected from different road conditions ranging from very good road conditions to very bad road conditions and for different vehicles, covering all the road-related events. We trained the SVM model to distinguish between differ- ent road conditions with the F1-score of 91%. The models utilize the sensor data to identify the road condition as the user drives. Furthermore, these results are used to produce data-rich maps that show the conditions of the city’s roadways.With our ap- proach, city authorities would be empowered to detect and fix broken roadways that annoy commuters and cause accidents.
"Haris Anwar

Patient Mortality Score Prediction Based on Vital Signs Using Machine Learning"	"Collection of healthcare data on routine basis covering all aspects of patient’s history is now approaching to large volume in Electronic health record systems (EHRs) to improve health care standards and reduce cost. In our work, we utilized EHR data from ICU stay of patient to predict mortality score using machine learning techniques. To make life critical decisions in real time and utilizing ICU resources in better way we considered routinely collected vital signs to predict survival chances as mortality
score of patients. Feature engineering performed to collect meaningful variables for time dependent machine learning model."
"Noor Ul Ain

Elevated Quantity and Quality of EMA Responses Via Gamification"	Ecological momentary assessment (EMA) is an experience sampling method used to gather data from users in real time and context. Users fill the survey questions as a day-to-day activity and provide data with minimum recall biases. The communal use of smartphone mobiles has made it easier for researchers to collect data about dynamic changes in behavior and experience of users on the go. The collection of EMA responses on mobile applications highly relies on user’s contribution, the lack of interest and inattentiveness while filling the EMA survey leads to inefficiency in EMA responses. Even though, there are a number of ways to minimizing the recall biases and enhance the accuracy of EMA response; all of the available methods to as-sess the quality and quantity of user’s EMA responses lack efficacy. Filling out flat view questionnaires, even on mobile demands extra effort, requires undivided user attention, time that user might not be willing to give and can also trigger more stress.Lack of user engagement and interest makes them feel that surveys are burdensome which leads to the collection of less and low-quality responses. Especially a survey in which users need to talk about personal experiences, the user feels being judged, which leads to faulty data collection, this if the longer run affects the quality of the research study. Existing gamified EMA applications don’t contain the gamificationelements that are enough to keep the users engaged in the expected way. We are try ing to make the EMA application more interactive by adding different guidelines and good design principles. To improve the quantity and quality of EMA responses, we are adding gamification to the EMA application. Gamification makes the non-game context application engaging and interesting for users. To overcome the issue of repeated prompting of notifications, we used algorithm which provide the earlier moment data i.e., location change, mobile usage and steps taken; the goal is to help user remem ber his daily activities promptly. We added progress map, points, leader board, along with an avatar and narrative screens to make the EMA app interesting for the users. To prove our stance, we developed two android applications. A non-gamified EMA application which shows questions on a flat view scrolling screen. A gamified EMA application which contains an avatar (a penguin), narrative screens, points as coins, progress map and leader board. In both the application we use earlier moment algo rithm which help the user to recall the earlier moments of the day before answering the questionnaire. This information about earlier activities helps the users to respond to questions more accurately. We conducted this controlled experiment with 24 students. The students were sampled into two group. One group was assigned a non-gamified EMA application and other was given a gamified EMA application. Before the data collection process, set of instructions, study protocols were shared with the partici pants and consent was taken. After the data collection period of 7 days. Participants were interviewed online via google meet. In this EMA study users’ responses were gathered on two perceived stress measuring questionnaire and then from a feedbackquestionnaire. Two perceived stress questionnaires were used to gather data regarding the daily and weekly perceived stress of the user. To ensure the accuracy of responses filled by users on perceived stress questionnaires we compared the daily responses of with the responses gathered at the end of the week. The feedback data helps to learn about the user experience in detail and the purpose of conducting interview is to learn about the effect of gamification on the users’ performance. The result shows, gamified EMA captures a greater number of responses on both, perceived stress questionnaires and on feedback questionnaire. The users respond more accurately on a gamified EMA app, since the users find filling survey interesting by playing game. We further found out that the most liked featured of the users was leader board and jumping through the stones.
"Muhammad Hamza

An Automated approach for the Localization Testing of mobile Applications"	The worldwide usage of mobile applications requires the products to be accessible and contextual for users in all markets and regions. Multilingual mobile applications are developed to reach multiple and diverse users around the world. It is desirable to ensure that the Graphical User Interface (GUI) of an application is consistent when it is translated into other languages. Testing of android mobile applications that support multiple languages has its own set of challenges, including functionality testing, i.e., all links are functional. They direct to the correct screens, cosmetic changes, i.e., layout alignment, appearance, size, and alignment of all text on-screen, and linguistic issues,  i.e., the correctness of translated strings on each screen. Such challenges in ultilingual mobile applications demand the language expert to test the multilingual application according to specific locale and context. Currently, most of the existing multilingual testing approaches are manual, which requires manual effort and time to ensure the uality and correctness of the application. The existing automated approaches for testing are designed to test specific languages like Arabic and focus on test the application's functionalities. So,there is a need for an automated language-independent approach for esting multilingual mobile applications. In this thesis, we propose an automated approach to identify linguistic and cosmetic issues in mobile applications. We capture the images of both (base and translated language) of the application and apply image processing techniques to identify the inconsistencies. We develop a prototype tool that translates the text of the base image and compares it with the translated version application text to identify linguistic issues like misspelling, untranslated strings, and crop strings. Our approach identifies cosmetic issues such as overlapping, overflow, and truncated strings. We evaluated our approach on five open-source android multilingual mobile applications and applied mutation testing. The result shows that the proposed approach effectively detects 306 linguistic issues and 81cosmetic issues from the five open-source, multilingual mobile applications.
"Rida Musaffah

Automated testing of dynamic web applications"	Modern Web Applications are becoming popular in the industry. These applications are often very responsive, easily debugged, streamlined, and optimized for developers. Typically, these applications are developed using client-side java scripting frameworks or class libraries such as AngularJs, ReactJs, or VueJs, etc. Since the content of the web application is dynamically generated, this leads to the dynamic generation of the domain object model (DOM) of the web application after each user interaction. The ation of dynamic DOM during each user action makes testing such web applications a challenging task. In the literature, several state-of-the-art approaches are proposed for testing dynamic web applications. Crawling-based techniques are used to generate random test cases for dynamic web applications. Search-based methods use genetic algorithms to explore DOM states. These approaches main limitations are (i) DOM changes rapidly and dynamically, thus mapping all states beforehand is difficult (ii) manual manipulation of dynamic web elements, which are error-prone and laborious tasks. In this thesis, the aim is to propose an automated model-based approach for testing dynamic web applications by modeling all states. For this purpose, a UML profile for structural modeling of single web components and a UML profile for modeling the behavioral aspects of dynamic web applications is proposed. The proposed profiles are used to model System-Under Test (SUT). These models representing the SUT are used by applying a testing strategy to generate abstract test sequences automatically. These abstract test sequences are then be transfor med into concrete (platform-specific) test cases. These concrete test cases are then be executed in an automated way by using a test executer tool on SUT. The constraints written in Object Constraint Language are used as an oracle for the generated test cases. The proposed modeling and testing strategy for testing dynamic web applications are empiricallyevaluated on two open-source benchmark case studies. Our results showed that the proposed approach is very effective in identifying the faults in the system under test.
"Saba Kanwal

Automated Conformance Testing of Mobile App GUI with Requirements"	User Interface (UI) testing is a process to test user’s interaction with an application. The UI of a mobile application provides variety of touch and voice based interactive widgets. However, due to small screen sizes and limited space of mobile UI, it becomes a challenge to provide great user experience. In practice two UI test approaches are being used in mobile application testingnamely random exploration testing and model based testing. A major subset of approaches focuses on system functionality testing such s testing for finding runtime crashes, exceptions or potential bugs. The purpose of UI conformance testing is to compare an application’s observed behavior with its expected behavior. There are several guidelines and principles on usability, accessibility or tion design of a mobile applications which act as reference document for UIconformance testing. There are two major types of mobile UI guidelines i.e. the guidelines specific to appearance of UI widgets and the guidelines specific to behavior of UI in response to some user interaction. The existing automated approaches for UI testing of mobile applications address the testing against first type of guidelines. The testing with respect to second type (interaction oriented guidelines) is mostly conducted manually since it requires a system to be in particular states which cannot be achieved through random UI exploration. The proposed approach deals with the testing of mobile application UI against interaction oriented guidelines. The functional requirements of a ileapplication are used as input to generate the required UI states. The natural language processing is used to transform functional requirements to executable test cases. The test cases are then annotated with guidelines based on the matching behavior found in test case ions. For that each guideline is first analyzed for the condition in which it should be fulfilled and the expected behavior. The execution of annotated test case drive the application’s UI to a state in which it should fulfil the guideline. The system screenshots in the ed state are further processed using computer vision and natural language processing techniques to analyze the outputs against each guideline. The evaluation ofproposed study is performed on 7 real and open source case studies. The results successfully reported violations of guidelines among case studies. The evaluation isperformed to find the effectiveness of the proposed approach in terms of fault (usability issues) detection and efficiency in terms of time required to test the application UI.The proposed approach detected 16 faults in 7 case studies within average time of 80 seconds for each use case.
"Munira Khanum

Comperative Analysis on Android Specific Code Smell Detection Tools"	In this era, mobile applications gain high attention and maintain highest share in the software market which contribute to emergence of number of mobile apps. Due to growing popularity of mobile apps and user demands in term of requirements, mobile evelopers are under pressure to implement, maintain and develop apps rapidly. So, developers adopt poor design and coding practices known as; code smells. During the software development, bad choices made by the developers resulted in having a essimistic impact on the energy usage and on the performance of the mobile apps. Identification of Android-specific code smells is a challenging and difficult task for developers, due to availa -bility of little knowledge and support. Their informal definition encourage researchers to implement various code smell detection tools and techniques. A good amount of work has been done on the identification of code smells linked to object-oriented software systems but there still is a huge research gap in the dentification and rectification of Android -specific code smells in mobile apps. The aim of this work is to compare and evaluate three Android-specific code smell detection tools, namely; PAPRIKA, ADOCTOR and DAAP. These tools detect high number of Android-specific code smells present in Android apps and used by many researchers to refactor the code smells in Android apps. All these three techniques are metric based and use statistical analysis for evaluation. Accuracy of code smell detection tools is calculated through empirical evaluation of 100 And -roid apps based on existing Android-specific code smells in them. This study helps in selection of the most efficient tool to identify code smells correctly in Android apps. It also provides awareness about occurrence of Android-specific code smells and its distribution in different categories of mobile apps. It also provides better understanding of code  smells to be avoided.
"Muhammad Farooq

Safety-Security Risk Management Process For Cyber Physical System"	Cyber-Physical System (CPS) are described as an alternative technology for managing the homogenous or heterogeneous software components. CPS has a significant role in modern emerging industries such as smart grid, connected vehicles, future of factory, and Industrial Internet of Things (IIOT). Each CPS contains a set of computational resources and physical assets; actuators and sensors. CPS includes real-time hybrid and distributed dynamic systems. CPS has a complex entity by its nature because it is comprised of many computer-based services along with physical methods. Tight coupling between CPS components can form new kinds of risks, which have not been addressed by the traditional risk management process. CPS requires high availability and safety capabilities which are no longer remain isolated in the internet era. CPS requires software updates while performing its operations to engage the system vulnerabilities on runtime. It is necessary to address security issues at earlier stages because unknown security risks can arise in no time. In recent years, CPS security-related issues capture a lot of intensions in the research area. The communication process of CPS makes it more vulnerable to security attacks. Due to its interconnected classification, a security breach may affect the safety function of the CPS. Security and safety are two major concerns about CPS. Both share identical goals that are to protect the CPS. Safety is concerned with the protection of CPS from accidental failures. Security deals with the protection of CPS from institutional attacks. Alignment in the objective of security and safety can make the CPS protection invincible. Both safety and security are considered separate entities in traditional software engineering practices. The International Society of Automation (ISA) focuses on the alignment of security and safety risks of CPS accordingly the standards. Week alignment can result into inefficient or partially protected systems which could end up with so vulnerabilities in the system. The traditional risk management processes are not enough to determine the impact of vulnerabilities that can cause risks. Therefore, there is a need for an integrated safety-security risk management process that identifies, analyses, and controls the security vulnerabilities that might create accident failures. This study aims to examine the vulnerabilities of CPS in the context of automation and proposed an integrated risk management process for the cyber-physical system. The research accordingly comprised of three parts; (1) a safety-security risk management process (2) identification of vulnerabilities and forensic investigation of them (3) rectified set of safety-security requirements. Finally, the presented study is demonstrated by two application examples from the cyber-physical system.
"Abdul Rehman

Emotion Mining of Open Source Software Developers Using Machine Learning"	Open-source software development is where software developers work collaboratively while being geographically distributed, towards a mutual goal. Thus, softwaredevelopment activity and particularly open-source software development become a social activity in addition to the technical activity which is influenced by the emotionalstates of the participants. Studies conducted on communication data of open source software developers revealed that software developers express a wide range of emotionsin their communications. Open-source software developers utilize mailing lists, code hosting platforms like github, chat applications, and issue tracking systems like Jira,bugzilla to communicate. These communication channels also serve as huge data repositories. Mining these repositories unveil hidden patterns and relationship of humanaspects in the software development. Human aspects of creativity is also an essential element in problem-solving and the success of software development. Creativity in thecontext of the software maintenance phase is measured using metric of, number of enhancements integrated in mean time/no of issue resolved in mean time. Prior studiesexplored relationships of multiple human aspects on open source software development activities, including the relationship of software developer’s sentiment, politeness, andpersonality traits with software development activities of issue resolution time, productivity, performance, and creativity to understand the human aspect of softwaredevelopment. Furthermore, researchers explored software developer's emotional variation relation in multiple software artifacts including commit comments, programminglanguages of project, the number of files changed, issue resolution time, chances to merge in the main branch. However, the literature lacks in research of the impact of discreteemotions on the creativity of open source software developers, and software developer’s emotions variation relation in issue report comments of different priorities is also not investigated yet. To overcome this gap in this empirical study we investigated the impact of discrete emotions on the creativity of open source software developers, and software developer's emotional variation relation in issues of different priority issues. we used Jira issue tracking dataset published by researchers [1], and the software engineering domain-specific emotions annotated dataset [2] to train a machine learning classifier, and extract emotions from issue report comments of OSS developers. And then explored the relationship of those emotions with the creativity of open source software developers. With the motivation to assist the holistic understanding of the creativity of the open-sourcesoftware developers and understanding of how developers behave differently in issues of different priorities in terms of emotions. Our results indicate that emotions of softwaredevelopers have negligible positive correlation with creativity of open source software developers, additionally we found that open-source software developers issue report comments contain emotions of love, joy, anger, sadness, however emotions of anger and fear are absent.
"Noman Ali

Empirical evaluation of feature location techniques used for software maintenance and evolution"	Software projects are continuously changing. These changes could be in the form of adding new features or updating the existing features of the product. Developers make these changes by first identifying the source code of the feature that requires an update. This activity of locating the source code of a feature is called feature location. Feature location is done by developers or experts who have extensive product and code knowledge. Sometimes experts are not available and the developers’ knowledge about a certain feature  fade with time or developers who are assigned to make changes in the features are not the ones who coded it. In this scenario, the developers search the source code manually to make changes, which becomes an extremely laborious and time- consuming task for large projects. Considering the importance of feature location in the domain of software maintenance, several feature location techniques are proposed to help developers locate a feature. These feature location techniques use static analysis, dynamic analysis, and information retrieval algorithms. However, an empirical evaluation of existing techniques may help developers figure out which automated technique will be the most effective one. Existing empirical studies have conflicting results on techniques that are most effective or high performance. Existing empirical studies utilize different metrics, benchmarks , and different empirical designs which produce conflicting results. Therefore, in this research, we aim to identify the high-performing feature location techniques through an empirical evaluation of feature location techniques by addressing issues in existing empirical studies. In our study, five feature location techniques are assessed through five performance metrics such as precision, recall, f-measure, MAP, and MRR in a standardized empirical design. These feature location techniques are evaluated by using nine open-source systems. This study provides empirical cross-comparison of existing feature location techniques by measuring their relative performance. Results suggest that feature location techniques using random projection produces better results than other techniques.
"Arooj Abid

DepExtract: A Machine Learning based Model to identify underlying Interdependencies among Requirements"	Requirements are the features stakeholders wish to see in the final product. To develop economic and high-quality software it is important to understand stakeholder needs and their priorities. Requirements are usually divided into  two  types;  functional requirements and non-functional requirements; Functional requirements of the software are the user needs or demands from the system and non-functional requirements determine the quality of the product. Requirements are interdependent on each other and have a positive or negative impact on one another e.g., refines, conflicts, constrain, precede, evolve_into, increase/decrease_cost_of, increase/decrease_value_of, be_similar_to, and be_exception _of. Requirements’ dependencies play part in prioritization, architecture design, project planning, and change propagation analysis. However, it is observed from the literature study that interdependencies are often ignored or consider only few types of dependencies among requirements at the early stages of the project. Existing techniques of depend -encies’ extraction consider two or three types of dependencies. Ignoring inter-dependencies may have a serious impact on the final product. Therefore, it is important to consider  these  dependencies  during   requirements prioritization. Since, the requirements are written in natural language making it a challenging task to identify. In this research, (i) we develop a machine learning-based model: DepExtract to extract nine types of requirements interdependencies, (ii) analyze the effect of requirements representation on interdep -endency identification. DepExtract identify nine types of dependencies among the requirements and provide 84% prediction accuracy on requirements in plain text format (user  stories). The requirements representation method i.e., use cases gave more prediction accuracy than user stories i.e., 94%. Use cases provide more accuracy than the user stories for the identification of the requirements interdependencies. Validity of DepExtract empirically evaluated by the existing approaches i.e., DRank and OpenReq-DD and by seeding wrong dependencies among the requirements of the ground truth data for training the model. DepExtract performs better than the DRank and OpenReq-DD both for number of ependencies identification and types of dependencies among the requirements. DepExtract also give accurate results although by seeding wrong dependencies.
"Asma Malik

A Game-Theoretic Model for Crowdsourcing"	Crowdsourcing exploits crowd wisdom to boost creativity in problem-solving. Considering the emergence of crowdsourcing and its perceived promise, both crowdsourcer and crowd expect a greater reward (it can be in the form of quality of work, monetary reward, reputation, gain in knowledge etc.). All the participants become part of the crowd to maximize their reward; for  example,  crowdsourcer’s  might  want to get  quality work in less money whereas crowd might  want to  increase the monetary reward. owever, not everyone is eager to take part in crowdsourcing activities. Incentives are a common technique to make crowdsourcing more successful. Existing incentive models based on auctions talk about the incentives of either the crowd or the rowdsourcer and these models have malicious effects of false riding and reporting. A VCG incentivemechanism is design to maximize crowd and crowdsourcer utility and consider their multiple interests. There are three key aspects of this research: Firstly, identifying themotivating factors for crowd and crowdsourcer. Secondly, designing a VCG incentivem mechanism; which creates a two-sided market in which the crowd and the crowdsourcerare paired and play a game. Subsequently, the mechanism then establishes an optimum and sustainable equilibrium that maximizes the incentives of both the crowd and thecrowdsourcer. Lastly, simulation results prove that the mechanism effectively eliminates free riding and false-reporting while guaranteeing the truthfulness and individualrationality of the mechanism.
"Kamran Abbasi

OntoMicroservices: An ontology for the Identification of Microservices"	Microservices Architecture is built on services which are smaller in size and independently deployable. Identifying appropriate number of microservices, from monolithic architecture, to ensure each microservice acts independently is a challenging task and it plays a vital role in developing a microservices-based system. There are lot of solutions proposed to address this challenge and approaches for identification of microservices can be classified as, Code-based approaches and Design-based approaches. Code-based approaches have limitation that software architect need to have good understanding of code before decomposition is performed. In comparison to code-based approaches design -based approaches are easier to implement. The usability of these approaches can further be enhanced by building an ontology for the identification of microservices. Key bene -fits of using ontologies are; Ontologies are reusable and they provide graphical representation of concepts and relationship among concepts, that is easy to understand. Ontolo -gies are commonly used for the discovery of web services but they are not commonly used for the identification of microservices. So, we propose an ontology for the identification of microservices, this ontology enables nferencing of microservices based on some pre-existing dataflow diagram of software system. We validated our ontology against four case studies and compared results with another approach (DFD-driven approach) that uses DFDs. We calculated accuracy of our results based on the modular quality of  microservices and results show that our approach our approach either out-performs DFD-driven approach or generates same results. Keywords: - Microservice Identification,  Microservice Architecture, Ontology for MSA
"Safiullah Shahid

E-Health Care for monitoring and predicting the blood glucose level using deep learning"	Diabetes is among the most common chronic diseases nowadays; in diabetes manage-ment control of blood glucose is essential. Significant attention has been paid to get the accurate prediction of diabetes. Various deep learning techniques are already pro-posed for predicting BGL such as multiple types of Neural Networks, SVR, LVX, ARX etc. Most of the existing state-of-the-art techniques predict for a short period from 15-60 minutes, and most of the existing studies use just continuous glucose monitoring value as input to expect blood glucose level. The accuracy of current models falls as the prediction time increases. Long-time prediction can cause several false positive notifications, which results in a high error rate. This study presented a hybrid model for predicting blood glucose levels based on two different kinds of neural networks CNN and GRU. The proposed model can predict blood glucose levels with leading accuracy of (MSE = 30.73 ± 21.71 [mg/dl] for 15 mins, MSE = 54.35 ± 36.73 [mg/dl] for 30 mins, MSE = , 91.8 ± 50.66 [mg/dl] for 60 mins, MSE = 149.74 ± 66.93 [mg/dl] for 120 mins-horizon) and (RMSE = 5.12 ± 2.11 [mg/dl] for 15 mins, RMSE = 6.87 ± 2.67 [mg/dl] for 30 mins, RMSE = 9.17 ± 2.761 [mg/dl] for 60 mins, RMSE = 11.91 ± 2.81 [mg/dl] for 120 mins-horizon) on simulated T1D patient. The proposed model used CGM data and used extra features as input, like carbohydrates and insulin. The proposed model is then evaluated on twenty simulated patients of different ages generated using the UVA/Padova simulator. Performance of the proposed CGRU model is compared with five state of the art algorithms. Our proposed model outperforms the existing predictive models such as LSTM, GAN and CRNN.
"Naqash

A Lightweight Encryption with Integrated Security and Privacy for Facial Recognition"	The purpose of authentication in a monitoring environment is to make sure that person is a real person. In the current decade facial recognition is being used as authentication. The image of face are being transfer have most valuable and private data, and requires high level security. Face recognition work as realtime application and run on resource constrained devices. Although, there are a lot of research on image encryption but most of them are not suitable for these devices because of resource limitations. In this thesis a new lightweight encryption approach has been propose along with a customized face recognition approach which reduces the face recognition data. The Lightweight approach is based on dynamic key and nonce with two round which consist of substitution and permutation. The two rounds will reduce the computational power. Images were encrypted differently while avalanche effect is preserved. Finally, this thesis conducts the performance and security analysis for validating the robustness against various attacks. The effic -iency of the proposed approach has been compared to the state-of-the-art approaches. The results show that the proposed approach is fast and outperform other state-of the-art lightweight algorithms in term of performance (execution time). In error propagation it has too low rate of error (only effect the specific sub-matrix) that make it best feasible approach.Brute-force attack and different statistical analysis show its strength against different attacks. Histogram shows encryption high level security in terms of uniform distribution.
"Misbah Minhas

Mutation Analysis to assess the effectiveness of web test repair approaches"	Test breakages in web application testing occur due to various changes in the application code. There are several existing approaches to automatically repair broken test cases to make them usable for the new version of the web application. It is important to evaluate the effectiveness and scalability of the existing test repair approaches based on the test breakages taxonomy. Currently, researchers evaluate the effectiveness of their test case repair approaches manually, thus making the evaluation cumbersome and tedious. To this end, we have adapted mutation analysis to automate the process of empirical evaluation for the test repair approaches. A key challenge to adopt mutation analysis has been the lack of web mutation operators that reflect those changes (breakages) that were claimed to be repaired by test repair approaches. Therefore, we propose new mutation operators based on the test breakage taxonomy to automate the evaluation of test repair approaches and reduce the manual efforts. We also develop a prototype tool to support the new mutation operators. We evaluate our mutation operators on multiple case studies. The results show that our proposed mutation operators are good enough to put breaka -ges in the code that becomes the basis for the test case breakages. We applied the newly proposed mutation operators to three open-source case studies and compared three state-of-the-art test repair approaches, i.e. model-based test repair, WATER and COLOR. The results show that model- based, WATER and COLOR achieved 95%, 83% and 69% mutation score respectively. The experiment shows that our proposed mutation operators are successfully applicable to web applications and can be used to evaluate the effectiveness of test repair approaches.
"Aymen Talib

An Automated approach for testing cross-platform mobile applications."	Mobile applications have been becoming a necessity for human beings in the modern world. But a question arises that how well it is tested to ensure quality before its release. Manual testing is usually not recommended due to human interference, there is a high chance of this process becoming error-prone and time laborious. Automated testing appro-aches have high demand in the market due to their time, resources, and cost-saving benefits. When an application runs on a different platform, sometimes it shows inconsisten-cies that disrupt the user experience. To maintain the quality, we need to ensure that the mobile application goes through enough testing to be smoothly run on every platform. Leadingcompanies are facing challenges due to the inconsistencies found in their applications while it runs on different platforms. Testing failure usually occurs because of the difference in GUI’s of every platform, updates available on one platform but not on another, and some functionality not even able to be executed on some of the platforms. However, we can never make sure that every mobile application works fine on every platform as it is nearly impossible but still we can make sure to make the main functionality works properly on most of the platforms by following appropriate testing strategies. However, the trend of using aframework for application development is seen as a solution to ease the process of testing. The applications developed on a framework have a common code base which is the main reason that it is getting popular as there is no need to write separate code for IOs and Android applications. Many automated techniques havebeen proposed but they are not covering the problems that occur due to the frequently changing GUIs of mobile applications. The existing techniques areunable to handle the testing of platform-specific features. Even though code migration techniques are unableto migrate the test cases fully because some of theGUI events are platform-specific. In this thesis, the goal is to propose an automated model-based approach for testing cross-platform mobile applications. The system- level test cases are generated for testing cross-platform mobile applications. The proposed approach is empirically evaluated on the selected case study which is a to-do List Application. Experimentation is done to analyze the effectiveness and efficiency of the proposed approach. The experimentation resultsshowed that the proposed approach efficaciously tested cross-platform mobile applications.
"Maria Shoaib

An Automated approach for cross-Browser Functional testing of Web Application"	Web applications are widely used by a massive number of users for both personal and business activities. Web application users can access them through any browser of their  interest and expect consistent behavior and appearance across the different browsers. Cross-browser incompatibilities (XBI’s) are becoming an increasingly big problem inmodern web applications. These incompatibilities range from minor cosmetic changes to critical functional bugs. The failure to expose such incompatibilities during testing can degrade the experience of web application users. Cross-browser testing (CBT) is prevalent in this domain to give each user an optimal experience, irrespective of the browser  used to run the application. Cross-browser testing aims to find functional (i.e., web application behavior) and layout-related (i.e., appearance) incompatibilities. Existing CBT approaches focus on identifying, correcting, and mitigating layout-related incompatibilities (i.e., look and feel or appearance-related issues). In general, web application  functionality suffers when executed on cross browsers due to the differentDOM rendering engines used by the browsers, varying execution time required by the browsers to access web elements and widget compatibility support, etc. These issuesseverely affect the functional test scripts that may break while running on different browser configurations. The approaches for cross-browser functional testing of web applications only cater to the detection of functional incompatibilities, the correction of these incompatibilities is still manual. It causes the testers to write separate test scripts for all the browser configurations from scratch by keeping in mind the browser properties, which requires significant time  and testing effort. Considering these limitations, an automated approach for cross-browser functional testing of the web application is proposed that will automatically tailor the given test suite for different browser configurations. The tool is developed to provide automation of the proposed approach. The empirical evaluation is done on four subject  applications. The results show that the approach successfully tailors 90.79% of functional tests while maintaining the same functional coverage and fault-finding capability  as original test scripts.
"Asmar Muqeet

Improving Model based testing cocpit display system"	Cockpit Display Systems (CDS) are graphical user interface that provides critical in- formation such as altitude, roll, yaw, pitch angle to the pilot. They are considered a safety-critical system because the information that is shown on CDS, directly impacts the decision-making process of the pilot. For example, wrong altitude information can cause horrible results in the landing procedure of the aircraft. Therefore, the existing safety standards such as DO-178 require thorough testing of CDS. The current  practices for testing  CDS are manual which are labor-intensive, costly, and time-consuming. There is a need for automated testing of Cockpit Display Systems. In literature, there has been an effort to automate the testing of CDS using a Model-Based Strategy.  These approaches use UML state machine and N+ strategy for automated test path generation and simulator -specific manual scripts for test execution. However, these approaches have several limitations such as Non-deterministic self-transition and insufficient paths that lead to low state-space observation. Since CDS is considered ablack box system so the state space of such systems refers to the diverse data on which such systems are tested. Another problem is to execute these paths in a simulator. For this,  the current practice is to write manual scripts for each test path. To cope with these challenges an on-the-fly fully automated approach AItester is proposed for test ing CDS. The idea is to drive the system according to the simulated environment toachieve test paths with higher data diversity. AItester uses reinforcement learning to drive the simulated UAV according to the behavior of the UAV in the form of a UML state machine and automatically generates test paths that alleviate the limitation of the previous offline approach. The approach also provides a UML profile for modelingthe behavior and structure of UAVs. This profile can help in automating test execution for UAV components. AItester is evaluated on a real industrial cockpit display system called GCS-CDS that uses Ardupilot as an autopilot for UAV simulation. The evaluation showed that the AItester is an effective strategy for achieving larger data diversity and finding faults in the system under test.
"Wasia Javed

Identification of Order-Dependent Flaky Tests in Android Applications"	Regression testing must consistently produce the same outcome when tests are executed for the same version of the code. The tests that can pass and fail non deterministically for the same piece of code are termed as flaky tests. Many industrial giants i.e. Google, Facebook and Mozilla etc. face major challenges in their regression testing due to the presence of flaky tests in their test suites. The developers of a software application perform regression testing to ensure that the new changes made to the code do not cause failure to the previously working functionalities. However, some failures may not be due to the new changes but, they are due to non-deterministic behavior of test cases. Due to the presence of flaky tests, the outcome of application tests is not reliable and developers face difficulty in debugging the test code. There are many factors which are responsible for causing flakiness in the test suites. Among those factors, test order dependencies are known to be the one of topmost causes of flaky tests in android applications due to their high existential probability i.e. 50.5% as well as the effort required for their identification. Test order dependencies also affect the test quality and other activities associated with the testing i.e. regression tests selection, test case prioritization, and parallelization, which primarily assume that tests are independent of each other. Therefore, the problematic dependencies need to be identified and resolved. A test may pass when it is run in the succession of another test but fail when run in isolation. In android applications, dependencies may be among the elements of the application as well as among activities i.e. one activity passes some value to the other activity which performs operations based on that value. In order to have a successful build, the root causes of flakiness of tests, their identification, and mitigation strategies need to be researched. To the best of our knowledge, thereis no identification strategy for the flaky tests caused by dependency in android applications despite the fact that a large set of android application tests fails due to dependencies among them. In this thesis, an approach for the identification of flaky tests caused by test order dependencies i.e. dependencies among activities/screens,GUI elements, and shared resources of an android application has been proposed. It analyzes the android applications and their provided test suite, highlights the dependencies among its tests, and detects the flaky tests among them. In addition to this, it also computes the test execution order which ensures successful test build. The approach has been evaluated by applying it to 5 open-source subject applications which revealed that a significant percentage of test cases produced by software testers is flaky, due to order dependency among them. The results of the proposed work form the basis for the upcoming researchers in the area of flakiness in android applications testing.
"Evaluation of Text- Embedding Schemes for Emoji Prediction

Saad Abbas (MS-CS)
Supervisor: Dr. Arshad Islam"	Emojis are small images that can be viewed as a language for graphical expression of emotions. These emojis are generally used by user in social media where the space for expressing the sentiment is missing. Recent advances in machine learning make it conceivable to automatically recommend emoji with text messages. However, selection of an appropriate embedding scheme to recommend a suitable emoji in a text is a open problem. Prior emoji recommendation mechanisms are not so efficient to recommend suitable emoji in a sentence. Many word embedding techniques have been widely used in emoji recommendation tasks. Word2Vec, lexicon2vec, character2vec, POS2vec and GloVe are currently among the most accurate and usable word embedding methods which can convert words into meaningful vectors. Each embedding scheme has its own pros and cons and one embedding scheme may help to produce accurate results depending on its suitability to the given data. This thesis has evaluated multiple embedding schemes on a single benchmark dataset along with their combinations. The dataset used in this thesis is semeval-2018 task-2 dataset. Our results show that the combination of character2Vec, word2Vec and Part-of-Speech (POS) tagging produce the relatively accurate emoji prediction.
"Securing Video Surveillance of IoT based Smart Housing Society    

Ali Saleh Aziz (MS-SE)
Supervisor: Dr. Subhan Ullah"	Security of data over IoT devices has become a challenge mainly when it comes to resource-limited IoT devices. Several symmetric, asymmetric, and hybrid cryptographic techniques have been proposed to cope with the challenge of achieving data-centric security, providing node-centric security, and providing security over IoT networks. Several cryptographic approaches have been analyzed to identify the challenges and address those identified challenges by proposing a lightweight approach capable of providing data-centric and node-centric security to secure video surveillance data. The hybrid mechanism of two symmetric cryptographic ciphers i.e., 128-bit key supported PRESENT-128 bit cipher and AES-128 bit are implemented. 31-rounds of PRESENT- 128 bit is used to perform encryption of secret key which is passed to AES-128 bit cipher to perform double encryption over the PRESENT-128 bit generated key. The proposed approach introduces a secure way of key transfer. The proposed semi-symmetric hybrid approach is implemented and tested over number of images of different sizes taken as input to do evaluation by comparing the results specific to parameters including input size, input key size, time to encrypt, time to decrypt, size of cipher text, throughput, and security of cipher text against brute force. The proposed approach is proved resource-efficient in providing security of RoI data over the resource-limited smart camera device. Decryption throughput is calculated as 0.1303 bits per second for AES-128 bit and 0.1516 bits per second for Hybrid resulting in better throughput at the time of decryption even with increased cipher text size. The lightweight semi-symmetric hybrid approach proved the identified challenges in means of ensuring security of RoI data with reduced computation, reduced communication and, memory usage overhead without involving any external hardware. Keywords: IoT infrastructure, Symmetric, Lightweight, Smart Housing Society, Semi symmetric, Video Surveillance, PRESENT cipher, AES-128 bit, Throughput.
"Lightweight Sybil Resistant Trust-based
 Mechanism for IoT using Blockchain

Adeel Sarwar (MS-SE)
Supervisor: Dr. Subhan Ullah"	The Internet of Things (IoT) is a network of connected smart devices, which sense, process and analyze the data on-board with limited resources. In recent days, IoT gives revolutionary and advanced applications like home utomation, healthcare, smart city, and smart grids. In a smart city IoT scenario, different IoT devices of smart homes connect to a utility provider system for utility management purposes. These resourcelimited devices involved in the smart cities are highly vulnerable to different malicious attacks especially Sybil attacks in the voting system. As the data gathered by these devices are highly confidential where Sybil attack uses forged identities and can steal the data so there is a great need to ensure the security of these devices for the effectiveness of the system. In this thesis, a decentralized trust mechanism has been proposed to tackle the Sybil attacks in the lightweight IoT environment. The mechanism is based on fog devices and using a public blockchain concept. The results generated by the experiment proves 25 % better throughput when compared to the state-of-the-art trust-based mechanisms and consume less energy of 65 to 80 mJ by the node approximately.
"Software Effort Estimation Using Machine Learning Techniques on Use Case Points 

Sumaira Shaheen (MS-SE)
Supervisor: Dr. Waseem Shahzad"	The effort estimation effects the cost and schedule of the project. It is challenging to accurately estimate the effort of a project which is the problem of software industry. Effort estimation in early stages of software life-cycle is very important to schedule and derive cost of a project. It is very arduous that proper information is available in early stages of a project. Use Case Point model is a useful model for early effort estimation of software especially for object-oriented projects. Reliable effort estimation method requires previous data-set which we have used in our model. Deep Neural Network model is used to improve the accuracy of effort estimation using Use-Case Points. Many developments in machine learning algorithms have been introduced that would improve the estimation accuracy of effort. We have calculated the Mean Square Error (MSE) of Deep Neural Network (DNN) model and evaluated it by comparing it with previous state of the art solutions. The results shows that the proposed Deep Neural Network model have performed better than the stepwise regression model [1] whose Mean Square Error was 118.44. We have improved the estimation of effort by achieving the Mean Square Error of 94.17. We have also tested our model with real world project which gives the Mean square of 16.7.
"An Effective Bug Avoidance Technique

Shakir Rasheed (MS-SE)
Supervisor: Dr. Atif Jilani"	An open-source software project mostly uses an open-source bug tracking system. They’re used to gather bugs from the geographically distributed large user base. The information reported as a bug report has direct impact on resolving a bug on time. Most of the reported bugs vary in their quality metrics as described by most of the industry developers as well as academic researchers. Hence Bug reports with low quality require lots of manual Triaging effort. When a user submits a new bug report to the bug tracking system, a middle man known as a Triager, analyses the bug categorizes it as either a NEW, VALID, INVALID or DUPLICATE bug. Most of the time the submitted bug reports might be duplicate as they describe the same issue. This leads to a waste of resources and time. Duplicate bug detection is an active area of research. Several manuals, semi-automated and automated techniques have been proposed to improve bug deduplication accuracy and recall. But still, there is room for further improvement. Bug reports are written in both structured and unstructured natural language. There is a need to enhance the quality of textual information in the bug reports by providing defined restriction rules and textual patterns of writing a bug report while reporting it to the bug repository. In this study, we firstly aimed to define restriction rules that help in the reduction of natural language ambiguity (when a person can perceive more than one meaning from the phrase or a sentence or a word). Secondly, we provide the textual and categorical patterns for bug reporting template in order to increase the bug report quality as well as to increase the probability of duplicate bug identification while reporting. This will help in the improvement of results of the existing approaches in terms of accuracy and recal
"Identification of Disease Comorbidity 

Ramsha Ahmad (MS-CS)
Supervisor: Dr. Hammad Naveed"	The identification of disease comorbidity is important in identifying genetic relation- ships among diseases. Disease comorbidity results from comorbid diseases sharing the cellular mechanism and etiological pathways. The aim of this work is to predict comorbid patterns among diseases by analyzing the shared cellular mechanisms and to reinforce the relationship among diseases by weighting protein-protein interaction network. The weights are added by the integration of complementary  sources  of  data  like gene-disease  interaction  and  gene  expression  data. The  weighted  network then  executed  on  community detection  algorithm  results  in  communities.The mapping of diseases on the communities gives disease comorbidity networks. The integrated network identifies the disease comorbid patterns.
"Hybrid Session-based Recommendation

Haider Ali (MS-DS)
Supervisor: Dr. Hammad Majeed"	"""Personalized recommendation plays an important role in our life, it assists users in searching items according to their interest. Recently, session-based recommendations have drawn more and more attention due to the increase in demand for the internet. However, unlike other recommender system domains like books, e-commerce, and movies, news recommender systems address additional recommendation challenges. For example, news publishers release hundreds of news daily, that quickly decay over time and it grows exponentially with time as well as become irrelevant to most read- ers. Additionally, user interests change much faster compared with other domains and news articles have recency issues that bring users to read fresh news, instead of old ones. Previously, Collaborative and Content-based methods are proposed, but it suffers from sparsity and repetitive content recommendation problem. The GRU4Rec is proposed that models the user sequential interactions using RNN. However, it is not feasible to adapt to the news recommendation domain due to a huge number of items in news. Additionally the Graph neural network is proposed that models the session sequence as graph-structured data that capture the global and current interest of the session using the attention network. Recently author proposes Hybrid RNN based approach that models the user sequential interaction using RNN which uses the user feature and article content feature to learn the next article recommendation representation. However, none of them uses the contextual article semantic represen- tations for the recommendation, which have a huge impact on the recommendation. We proposed the method that jointly uses the article content contextual representa- tions and user features to perform recommendations. We use pre-trained Multilingual Bidirectional Encoder Representations from Transformers (BERT) language model to capture the sentence level contextual representations and Convolutional Neural Net- work (CNN) to learn paragraph-level article representations. Additionally, LSTM is used to capture user short- and long-term interests inside the session. We perform ex- periments on publicly available Addressa news dataset, in which our model performs state of the art results.""
"
"Cache Optimization in semi-Stream Joins

Muhammad Anees (MS-DS)
Supervisor: Dr. Asif Naeem"	Near real-time processing is in demand because businesses generate unlimited data in the form of streams, real-time analysis is required to help them respond quickly and plan in the event of sudden market fluctuations. The real-time processing allows them to stay ahead of situations that can be costly or, conversely, a major source of opportunity. Good examples are e-commerce order processing, real-time credit card fraud detection, online booking, power consumption/production, and near real-time data warehousing. Working with these streams to produce useful information is a tough ask. There are two main types of processing when it comes to data processing, batch processing, and stream processing. Stream processing is further subdivided into inter-stream and semi-stream processing. Inter-stream processing involves two input streams and produces real-time results. For semi-stream processing, input stream (S) and disk relation (R) is combined to produce near real-time results. One of the main challenges of semi-stream processing is keeping up with the speed of the input stream without losing data. It is also known that reading data from the secondary storage is slow and is considered an expensive operation in the join process. Several algorithms have been proposed with different techniques to avoid these slow disk reads but little attention is paid to the cache module. The cache is one of the best ways to overcome disk seem time issues. In the cache, the most frequent master tuples can be kept in the main memory. Several semi-stream algorithms have been proposed which utilize the CACHE module for an efficient join process, but most of them utilize the traditional cache techniques because of that they are unable to address the following problems i.e. efficient utilization of cache and adaptation for seasonal changes in the input stream. This study proposed a semi-streaming algorithm that not only uses the cache in a better way than all existing cache-based semi-stream algorithms but also dynamically adapts to the seasonal changes without human intervention.
"A Blockchain based approach for decentralized authorization policies management

Noman Ali Sherazi  (MS-SE)
Supervisor: Dr. Ehtesham Zahoor"	Security challenges increase as cloud computing grows. One of the highlighted security challenges is authorization. Authorization process allows or denies specific resource to a specific user for a specific time duration based on access rights. These access rights are written in the form of policies, and the policies are attached to the roles in Role based access control model. These policies can also be delegated to other users based on delegation constraints. In regular situations, delegation constraints are followed as they are while in emergencies these constraints can be overridden to allow delegation. Delegations are evaluated based on one set of delegation constraints for both regular and emergency situation that may allow the delegations in emergency that are not allowed in regular situation because constraints are overridden in emergency. Allowed delegations in emergency will work in regular situations because delegations are managed irrespective of situation that leads to the malicious behaviour. In this paper, we investigated the delegation in emergencies and regular situation using the blockchain Ethereum environment. We have defined the regular and emergency delegations constraints, which are evaluated on every delegation request. Due to the blockchain transparency nature, we can audit access rights and authorization delegation
"Hierarchical Text Classification of Urdu News using Deep Neural Network

Taimoor Ahmed Javed (MS-CS)
Supervisor: Dr. Waseem Shahzad"	Digital text is increasing day by day on the internet. It is very challenging to classify a large and heterogeneous collection of data, which require improved information processing methods to organize text. To classify large size of corpus, one common approach is to use hierarchical text classification, which aims to classify textual data in a hierarchical structure. Several approaches have been proposed to tackle classification of text but most of the research has been done on English language. In this paper, we introduce a hierarchical model based on LSTM mechanism named as Hierarchical Multi-layer LSTMs (HMLSTM) to do Urdu text classification hierarchically. Our method consists of two modules: (1) Text Representing Layer, for obtaining text representation in which we use Word2vec embedding to transform the words to vector. (2) Urdu Hierarchical LSTM Layer (UHLSTML) an end-to-end fully connected deep LSTMs network to perform automatic feature learning, we train one LSTM layer for each level of the class hierarchy. We have performed extensive experiments on our self created dataset named as Urdu News Dataset for Hierarchical Text Classification (UNDHTC). The result shows that our proposed method is very effective for hierarchical text classification and it outperforms baseline methods significantly.
"Context Aware Urdu Transcription Using Deep Learning

Saima Ahmed (MS-CS)
Dr. Mirza Omer Beg"	Building a context-aware automated speech recognition system for Urdu is a challenging task given the lack of publicly available resources. Due to Urdu being a low resource language, very limited work has been done in the automated speech recognition domain. An automated speech recognition for Urdu also has to support different dialects as Urdu is spoken by more than 100 million people around the world, with many accents. In this work, we use CMU Sphinx toolkit for transliteration of Urdu speech. A word error rate of 6.4% and sentence error rate of 48.7% was recorded for a data set of 708 continuous recordings. We will propose methods to improve transcription accuracy for Urdu by expanding the resources available for Urdu, using transfer learning techniques, and provide a much improved acoustic model that can be used for future work in this domain.
"Identifying candidates for Microservices from JavaScript Web  Applications

Daniyal Talat (MS-SE)
Supervisor: Dr. Naveed Ahmad"	"Manual migration from monolithic architecture to microservices architecture is one of the challenging aspects of adopting microservices architecture in existing web applications as more organizations are adopting cloud technology, and modernizing existing monolithic applications to microservices architecture. Identifying candidates for microservices via extracting static and dynamic coupling information from monolithic web applications developed with Node.js is an unexplored research area due to complexity arising from JavaScript’s asynchronous nature, and multi-paradigm programming approach. In this thesis, we propose a semi-automated approach which employs the usage of static analysis and dynamic analysis for identifying microservices candidates from monolithic web applications developed with Node.js. The proposed approach aims to guide practitioners in decomposing monolithic applications via identification
of highly cohesive and loosely coupled microservices. The proposed approach is evaluated on a Node.js web application, with static coupling information extracted from architecture diagram of said monolithic web application, and dynamic coupling information from runtime analysis on the basis of function calls between components and database queries from each component. Our case study is reviewed by an industry expert in microservices, and our results show that our approach can successfully identify candidates for microservices without time-consuming manual refactoring process or the availability of domain experts in microservices."
"Role of Social Media Technologies in  Enabling Family Connectedness in  Pakistan: A Design Science Study

Khunsha Ali (MS-SE)
Supervisor: Dr. Amna Basharat"	The area of Family Connectedness through technologies is getting immensely important in the field of Human-Computer Interaction (HCI). The international HCI research communities are interested in studies focusing on how families around the world use technologies to improve family relationships. To the best of our knowledge, there is lack of research in Pakistan that studies family bonding through technologies. To overcome this gap, this study aims to investigate how families (parents and children) use existing social media apps to enhance their relationships with each other. We also aim to provide design recommendations on how this maybe done better in this regard. We adopt a mixed methods approach to understand the parent-child relationship with respect to technology in Pakistan. First, we conducted a cross-sectional selfreported survey with children to identify which social media app they most frequently use with their parents and to understand the nature of bonding with their parents (N=432). This method helped us understand the extent to which children feel close to their parents and how they remain connected on social media with each other. Based on the results of the survey, we conducted semi-structured interviews (N=10 sets) where we studied the relationships parents have with their children and how do they connect with each other on ’WhatsApp’. This study was focused towards gaining more in–depth knowledge about the conversations made on ’WhatsApp’. We also conducted a design activity along with the interviews. The agenda of this  ctivity was to identify the limitations of existing platforms that parents and children use and identify possible design enhancements for enabling better communication among parents and children. Building on the findings from the two studies, we derive design goals and based on these goals we designed and developed a prototype that was focused towards WhatsApp family enhancement. Lastly, we validated our prototype with both parents and children (N=10 sets) and found out that this enhancement can be helpful for them as it aims to provide better connectivity and provides a facility to deliver messages more quickly.
"Multi-criteria Navigation Planning using Distributed Genetic Algorithm

Muhammad Sohaib Ali (MS-DS)
Supervisor: Dr. Kifayat Ullah"	"Navigation planning from source to destination point can be much efficient if it is designed on run-time according to dynamic environments.Generally, when a route
is created it is on the basis of following single or multi-criteria.The following multi-criteria can be solved using classical algorithms but still during dynamic en- vironments starting the path again from the start to find optimum solution increases the operation and time complexity. Traditional Genetic Algorithms solve the problem of Multi-criteria navigation planning. But when several changes are happening and population size is increasing then execution time of Genetic Algorithm also increases. There are multi-criteria based genetic algorithms to solve navigation planning problem. Yet not an approach for scaling a genetic algorithm in thread-based or distributed environment to solve navigation planning problem. Objective: The objective is to use efficient approach of parallel generic algorithm to solve multi-criteria navigation planning problem along with time efficiency and con- vergence, and to identify parameters causing Genetic Algorithm to increase its time for a larger population and optimise them. Method: We identified parameters and operations causing increase in execution time of Genetic Algorithms for larger population and used Distributed/ Parallel approach to write a scalable genetic algorithm to find an optimal path which is fulfilling all or maximum given criteria. Results: The effects of the proposed approach on execution time, convergence and accuracy was explored with and without parallel environment. Both approaches of using single population and different populations were tested. The final results showed a good accuracy rate and the optimum path was found in lesser generations by using a larger initial population."
"Analysing Visualization techniques for Nested Proportions

Tajallah Maryam (MS-SE)
Supervisor: Dr. Faisal Cheema"	Visualization amplifies a simple picture of the details that you want to give to the user. The proportion data provide a productive relationship between the elements as a whole. When the hierarchical layer of the proportion data increases into subcategories, the data becomes proportionally nested. These nested levels of hierarchy make the data difficult to analyze. Rapid decision analysis is enabled by representing such data through visualizations. Nested proportion data is widely used in many areas. Various visualizations are used to represent such data in the literature, but all have pros and cons. It is difficult to represent complex nested hierarchies through visualizations on a single screen. The analysis of the most commonly used visualizations for nested proportion data on multiple hierarchal structure and complex analysis tasks is missing in the literature. These visualizations are the base of lots of new techniques presented to visualize nested data. Our research focused on the comparative analysis of four widely used visualizations on nested proportion data that we implemented according to our experiment factors (Circle Packing, Treemap, Sunburst, and Icicle plot). To evaluate their effectiveness and user preferences based on our experimental factors, we designed a controlled experiment. Multiple datasets (Cars, Covid-19, and Elections) of various nested hierarchal architectures are used to explore our designed research tasks. Findings of our experiment demonstrate that all techniques have different behaviors for each experimental factor as not one size fits all. The study indicates that the icicle plot is the easiest to complete the analysis tasks, but the user preferred the circle packing based on usability criteria. Based on our results, we recommended design guidelines for designers based on nested data visualization choices.
"Prediction of Energy Consumption of Android Native Source Code

Muhammad Awais (MS-CS)
Supervisor: Dr. Omer Beg"	The energy consumption problem is a hot topic in Android communities. The high energy cost caused by improper development brings lots of complaints from users. An effective and efficient energy consumption analysis technique can guide Android developers to improve the energy efficiency of their apps. Existing researches on this problem focus on either system entity level that gives the energy consumption of the hardware, or source line level that calculates the energy cost of source codes. With the consideration of accuracy and cost of analysis, this paper proposes a novel and automatic approach to analyze and predict the energy consumption for Android apps. We conduct the study from a method-level and API-level perspective. The method- level analysis gives developers facts about the energy consumption of the user methods in their apps, while the API-level analysis shows the energy consumption of Android APls, which can help them make good decisions about how to choose appropriate APls to improve the energy efficiency of an Android app. In this paper, we are representing a approach for energy prediction model which is based on the experimentation on 20 real smartphone devices. Our data-set includes about total of 10,000 records which are executed on 20 different types of devices. we have selected the top fourteen features for prediction of energy on an Android application. we have selected 6 system specific features, 5 device specific and 3 program specific total 14 features and 14 different type of applications. After applying the Machine Learning Models, we train our modal in 17-10th gen overclock-able Machine with GPU of RTX 2060, we get the F1 score off Linear Regressor is 83.00, Decision Tree Regressor is 81.00, Support Vector Machine 86.00, Random Forest is 82.00 and our Mathematical modal F1 score is 79.00, and the RMSE of LR is 0.17, RF is 0.185, DT is 0.195, SVM is 0.145 and the last our Mathematical Model is 0.20, we believe that the energy prediction can be predicted from device specific system specific and program specific across different Android OS versions. Based on the results of our study the machine learning models perform best prediction on these features.
"Identification of Mircroservices & Their Scope from Requirements

Mati Ur Rehman (MS-SE)
Supervisor: Dr. Naveed Ahmad"	"Microservices are small, and scalable services that are independently deployed. Microservices architectural offers various benefits over monolithic architectures such as: scalability, modifiability, deploy ability etc. This has resulted in migration of monolithic systems to microservices based systems. One of the key sub problems in this migration literature is microservices identification. Various methods and techniques have been proposed for migrating monolithic systems to microservices including their identification. These methods use artifacts such as source code to identify microservices. To the best of our knowledge, from literature on microservices identification, there is no method for microservices identification in new product development. This is twofold problem: 1) identifying similar functionality from the requirements/system description; and 2) limiting the functionality so that the identified microservice remains small and independent.
This research proposed an approach to identify microservices from requirements. The proposed method is based on word embedding models to identify similarity in words in requirements. We have used/compared three word embedding models (Glove, Fasttext, Wrod2Vec) to find the semantic similarity of the words and their distances to resolve these problems. By using the semantic similarity of words and their distances, we use K-mean clustering to find a cluster of microservices. We select three case studies of student portal and combine all the case studies to implement our approach.
Finally, we interviewed the experts by giving them a requirement document that contains requirements in raw form to find microservices. Then, we compare our obtained microservices with experts that extract microservices from the raw requirements. Almost all of identified microservices by our approach is same with experts identified microservices but some microservices are not identified by our approach due to small dataset."
"Automated Model and Hyper-Parameter Selection using Data Statistics

Saeed Ahmad (MS-DS)
Dr. Hammad Majeed"	This work extends the problem complexity similarity computation for a hyper-heuristic framework Deja Vu. The framework proposed a new method to use knowledge of previously solved problems for solving similar new problems. To test and verify this framework an extensive solution space was created using 70 well-known data sets solved with a reasonably large number of available related algorithms. To determine how similar two problems are, a complexity function is proposed to measure the statistical complexity of a problem, further, a clustering of problems based on this complexity is created. This is done to assign a solution set to problems having similar or same complexity, this complexity function and the proposed approach is comprehensively tested and is very well supported by the results. The solution to a new problem is proposed by  nding its complexity and determining the related cluster. Deja Vu groups 70 di erent problems based on complexity into 5 clusters, this clustering a ects the quali cation and suitability of the solution proposed for a new problem. In this work, we attempted to improve the clustering based on the claim that increasing the granularity of the clustering reduces the size of the solution set for and reduces the solution search space. Ideally, the complexity similarity function should propose a single solution to a given problem instead of a set or cluster of solutions, in this work, we experimented with a variety of cluster size including the ideal case, and evaluated the results by comparing our proposed solution with the best one available in Deja Vu's solution domain. Basically, our approach to solving this problem by batter representing data sets on multidimensional space instead of a single space landmark in Deja Vu, We generate an approximate boundary of data sets on multidimensional space to  nd similar data set by the overlapped boundaries and we got excellent results on our test data sets.
"Semantic Based Knowledge Extraction From Hadith In Urdu Language

Ahmad Hassan (MS-CS)
Supervisor: Dr. Waseem Shahzad"	"Hadith are the second most important source of legislation for Islamic creed, which are the sayings and actions of Prophet Muhammad (Peace Be Upon Him). Hadith data is very huge and its words are very complex for a person unfamiliar with the Hadith Science. Thus Natural Language Processing techniques are applied on Hadith for a lay man to understand it without consulting to Hadith Scholar. In this research work, I have used BERT Multilingual model to make a question and answering system for
the Urdu translation of Hadith. BERT Multilingual supports 104 languages including Urdu and keeps the context of the words in Hadith text as well by the use of deeply bi-directional embedding, which makes it unique of its kind for the Hadith text. This question answering system has achieved 94% accuracy and it will enable anyone to query from Hadith text, explanation of the Quranic verses available in Hadith and other information at the distance of few clicks
"
"TinyLFU based Semi-Stream Cachejoin for Near-Real-Time Data Warehousing

Wasiullah Waqar (MS-DS)
Supervisor:  Dr. Asif Naeem"	"Semi-streamjoinisanemergingresearchtopicintheareaofnear-real-timedataware- housing. Asemi-streamjoinisbasicallyajoinbetweenafaststream(S)andaslow disk-based data(R).Inthemoderneraoftechnology,alotofdataisbeinggenerated swiftly onadailybasiswhichneedstobeinstantlyanalyzedformakingsuccessful business decisions.Keepingthisinmind,afamousalgorithmcalledCacheJoinwas proposed.ThelimitationofCacheJoinalgorithmwasthatitdoesn’tnotefficiently deal withthefrequentlychangingtrendsinstreamdata.Toovercomethislimitation, weproposeTinyLFU-  usedCacheJoinalgorithmwhichisamodifiedversionofthe original Cachejoinalgorithm.Therevisedalgorithmisdesignedtoenhancetheperfor- mance ofexistingCacheJoinalgorithm.TheproposedalgorithmimplementsTinyLFU-
based cachingtechniquewhichkeepsonlythoserecordsofRinthecachethathave highest hitrate.Thenewcachingtechniquealsoenablesthealgorithmtodealwiththe sudden andabrupttrendchangesinthestreamdata.Weassesstheperformanceof our proposedTinyLFUCachejoinalgorithmwiththeexistingCacheJoinalgorithmona skewedsyntheticdataset.Throughourexperiments,weprovethatTinyLFUCachejoin algorithm ignificantlyoutperformstheexisitngCacheJoinalgorithm. Keywords- CacheJoin; TinyLFUCacheJoin;Semi-streamjoins;Cacheoptimization; Data Warehousing"
"Generating synthetic color fundus images for Diabetic Retinopathy using Generative Adversarial Network

Saad Ali (MS-DS)
Supervisor: Dr. Waseem Shahzad"	Data diversity is crucial for strong generalizability when training deep learning (DL) Models. Medical imaging data sets are often imbalanced as advanced stages of patho- logical findings are generally rare, which introduces significant challenges when train- ing deep learning models. In this work, we identify Diabetic Retinopathy (DR) as No. 1 cause for vision impairment among working-class adults, globally. Moreover, we report the presence of severe class-imbalance, between the grading levels of DR pathogen progression, where the latter stages are gravely underrepresented. Building a DL classifier with class-imbalance would result in sub-optimal performance, despite applying traditional data-augmentation techniques. Therefore, we propose to alleviate the problem of class-imbalance via condition- ally generated artificial data. Specifically, we propose to employ an Image-to-Image translation technique that leverages a novel technique, called SPADE, for synthesizing new Color Fundus Images containing DR pathogen in progression stages via semantic segmentation map. SPADE is an acronym which stands for Spatially Adaptive De- Normalization technique, which takes into consideration the spatial information of lesions associated with a particular DR stage; hence, generating clinically coherent DR images. Through image synthesis, we demonstrate the value of generative models as a data anonymization tool, which not only helps with medical data acquisition, for the public at large, but also provide DL models with diverse examples of rare instances. Hence, an enabler to produce better results for Rare-disease understanding.
"Multi Criteria Path Selection in Road Network

Zeeshan Ali (MS-DS)
Supervisor: Dr. Kifayat Ullah"	This thesis presents research study on efficient and effective path selection on road networks.Although measuring shortest paths between all nodes in a large network is computationally expensive even its only one criteria. while performing multi-criteria path search, the traversal of whole network and comparison between all possible paths prove to be costly and inefficient.Existing paper solve aforementioned problem by introducing reference point but they performed large number of offline pre- computations. In this thesis, we introduced an efficient multi-criteria based approach, inwhich we restrict our algorithm to explore minimum number of hops while getting maximum criteria. Our objective is to get optimal path, having minimum path length while meeting maximum criteria. Experiments are conducted to verify the effectiveness of proposed approach. The experimental results depict that the proposed algorithm achieve high accuracy regarding criteria meeting. while removing preprocessing steps with minor change in execution time.
"Confidential and Authentic Communication between UAVs for Target Surveillance

Haris Khan (MS-SE)
Dr. SubhanUllah"	Unmanned Aerial Vehicle (UAV) is an autonomous aircraft system of having no human pilot for targets surveillance which gain more attention worldwide from the last few decades because of its wide use in public, civilian and army applications like a specific area monitoring, thief detection, search and rescue operations. But the nature of these UAVs are very limited in term of memory storage and battery power which results in short-term and unreliable surveillance in complicated environments. In such situations there is a solution of using more than one UAVs which share and merge their partial information with each other to perform such complicated task in a team. Secure communication among these UAVs is a key factor for accomplishing such complicated tasks. Secure communication involved confidentiality and authentication of the data share between UAVs, because sharing non-confidential and non-authenticated data can cause catastrophic failure depending on severity level of an application. Security in UAVs is an active research area and multiple approaches for providing security has been introduced by multiple researcher but still, there is a gap for further improvement. State-of-the-art approaches based on cryptographic and non-cryptographic algorithms for communication security are highly computational and vulnerable to security attacks. Value-to-HMAC approach is proposed for authentication purpose in which every node requires a pre-defined hash tables to compare the received hash with pre-defined hash tables for considering a message authenticated or non-authenticated which creates extra computational overhead. This thesis presents a lightweight security approach for providing confidentiality, authentication and integrity to data share between UAV to UAV and UAV to GCS. The proposed approach based on HMAC with AES-128 bit which uses the concept of “Encrypt-then-MAC (EtM)”. This concept make the proposed approach lightweight and suitable for resources limited UAVs as compared to previous proposed approaches. Experiment has been performed to test the proposed approach in term of performance and security which improves 70% performance with the achieving of confidentiality, authentication and integrity.
"Identify and Isolate Malicious Fog Node in Fog-2-Fog Collaboration Model



Iram Waheed (MS-CS)
Supervisor: Dr. Muhammad Asim"	Most of the time-sensitive loT applications need low latency. Some other criteria for Quality of Services (QoS) are difficult to achieve through cloud computing. Cisco Launched a new model Fog Computing in 2015 to address these issues. However, fog computing faces many security challenges due to the dynamic fog computing environ ment. Secondly, the fog nodes are deployed by different vendors who have different security policies. When fog node collaborates and offloads load data to complete a task, they face many security isues. Little work is being done on their security inn the fog computing environment. Traditional cryptography strategies are not suitable for detecting malicious fog nodes that are part of the network. Therefore, malicious nodes may threaten the reputation of an IoT service and user's private data. This thesis proposes a trust-based approach that finds the most trusted node for offloading and isolating the malicious node within the fog domain. Our approach provides inside net- work security and enhances QoS. With the help of our approach we are able to reduce the malicious collaboration request between fog nodes during offloading process and minimize the response time of time sensitive applications. The result shows that there is 18.18% less malicious collaboration requests and 14.04% more secure collaboration requests in the proposed model when compared to the state-of-the-art. It also shows 16.69% less latency in terms of response time) in the proposed model due to more se-cure offloading to the trusted nodes compared to the other where no such mechanism was used.
"Minimize Power Consumption and SLA Violation using Dynamic VM Consolidation in Cloud Data Centers

Umer Arshad (MS-CS)
Supervisor: Dr. Muhammad Aleem"	The cloud services can be accessed anytime and everywhere over the internet. The purpose of most of the Cloud providers,including Google, Microsoft, and Amazon, is to make new data centers for their customers. Cloud Computing data centers is expanding, the server and other infrastructure energy consumption have increased. The overwhelming growth of cloud data centers, in the last decade, has been jeopardising as it enhanced their expanses because of the hefty energy’s consumption. Moreover, Computing resource is another adversity caused by consumption of energy and high power. The energy is needed to run the cooling system as well as the infrastructure. As a result, the system emits carbon dioxide (CO2) and other green house gases which pollute our ecosystem. The enormous amount of power consumption increase the input cost and subsequently decrease investment return. The main aim of this study was to alleviate the energy onsumption of the cloud system without compromising on its service quality. It is a performance contract that is signed, after negotiation, between the Cloud service provider and the customer. Central Processing Unit (CPU), memory, network interfaces, MISC, temperature, and disk storage are imperative for determining power consumption by the computing nodes. Since the CPU and memory mainly consume a hefty portion of energy, the study’s prime focus was to utilize these resources meticulously by managing the power consumption. A new algorithm named EEOVMC (Energy Efficiency Optimization using VM Consolidation) was proposed to counteract the conundrum of high energy consumption by the cloud system. The approach is basically virtual machines consolidation that reduces both, the power consumption by the cloud system and SLA violation. The idea is to categorize the host in the cloud data centers based on CPU and memory utilization for better Dynamic VM consolidation. By setting the two-thresholds framework of CPU and Memory utilization, the host can be categorized into three main classes: host over-loaded, host medium loaded, and host under-loaded. VMs will migrate into the medium loaded server to minimize the energy consumption in overloaded hosts. In the medium loaded host, all the virtual machines will be kept unchanged. In under-loaded host, to save the energy consumed by idle hosts, the algorithm collected VM from an under-loaded host and plot them to reduce the number of running host and sets off the left empty hosts into the sleep mode. A new simulation framework, the CloudSim toolkit, was chosen for the Cloud computing environment as a simulation platform. The experimental evaluation of EEOVMC was performed and compared with other virtual machine consolidation techniques. The results can stipulate that the EEOVMC approach significantly minimize consumption of energy and service level agreement violations
"Detection of Reactive Jamming attacks in Internet of Things (IoT)

Alia Ashraf (MS-CS)
Dr. Muhammad Asim"	"Internet of Things (IoT) has gained huge interest in current time due to its huge assortment of different domain applications. Security and privacy have become more important and highly challenging, in combination with the rapid evolution of IoT. Many studies gave solutions and ideas for offering security and solving IoT scalability issues. Many attacks badly affect the IoT network. One among them is the reactive jamming attack that halts the communication channel by sending inconsistent data. There exist various solutions to solve this problem. One of the proposed techniques is Countermeasure Detection and Consistency Algorithm (CDCA). It is a distributed approach; however, there persist issues like extra energy consumption with maximum traffic delay. For this purpose, We intend to propose a lightweight yet efficient method to detect a reactive jamming attack.To detect reactive jamming attack we proposed collaborative detection technique (CDRA) of reactive jamming attack.That works in a collaborative way each node in the IoT network maintain neighborhood information and monitor the behaviour of all others using two metrics that is packet forwarding ratio (PFR) and
Received signal strength indication (RSSI). After detection of reactive jamming attacks, we compared our results with state-of-the-art using certain performance parameters (i.e., energy consumption, and traffic delay) using the Cooja simulator.We simulated our technique under four conditions: 1) Under varying traffic intervals 2) Under a varying number of malicious nodes 3) Under a realistic condition 4) Under random mobility. When proposed approach(CDRA) apply it reduced energy approximately 3% inder varying traffic intervals and under a varying number of malicious nodes it consume energy 17% that is 5% low from existing CDCA approach.It reduced delay 10%. Collaborative detection of reactive jamming attack (CDRA) is performing better and consume less energy and minimum traffic delay and detect jamming attack faster."
"Research Rich Knowledge Domain Prediction

Waqas Raza (MS-DS)
Supervisor: Dr. Arshad Islam"	"The task of knowledge domain prediction that focuses on the identification of the research rich field. Such a study will be beneficial for researchers, donor agencies, and policy making organizations. Because it will benefits researchers to find fruitful research area and making better decisions about conducting their future studies and saving their time, endeavour & funding. This thesis aims to predict the areas which will be knowledge rich in the future by taking the keywords of research papers as our data set. The research problem is addressed formulating keywords as a graph and then  link prediction mechanism is used to identify the research rich keywords. The aim is to find the set of features and network properties that can identify existing keywords with the most potential to be used with new keywords in future. We are using keywords that are provided by the author, assuming an author of a paper better understand to which fields or concepts this paper belongs to. We employ hop distance, common neighbors, preferential attachment, Jaccard Index and use the techniques proposed in 2.4 for link prediction task. The results are reported using standard metrics such as accuracy,
ROC(receiver operating characteristic curve) and AUC(Area under the curve). Our results show that minimum error is observed with hop distance 2 along with the three other features (Adamic Adar (AA), katz and Preferential Attachment(PA) with accuracy of 63%, ROC score 88% with (katz,PA) and PR(Precision-Recall) 82 % with (AA,katz,PA,Resource Allocation(RA))."
"Verification of AWS IAM Policies for  Internet of Things 

Mohsin Ijaz (MS-CNS)
Supervisor: Dr. Ehtesham Zahoor"	Identity and Access Management policies for the Internet of things provide the digital identity for IoT devices. These digital identities are linked with human identities in the form of users to gain more benefits. AWS has provided varied solutions to secure IoT policies but these solutions are not enough to secure IoT policies. A problem of resource privilege escalation has occurred when a legitimate user can be able to exploit or bypass the security checks. We have provided a solution for resources privilege escalation. Our proposed approach is based on three types of relationships associated with four policy checks to verify which policy is overly or less permissive. Our proposed approach is beneficial to verify any type of AWS policy. We have also provided the solution for contextual redundancy in the policies.Our proposed approach is supportive in the verification of policies and the elimination of redundancy. Our proposed approach is practical and essential for AWS Identity and Access Management policies for the Internet of things.We have assisted the administrator, he can choose the appropriate policies that fulfill the principle of least privilege.
"Lightweight Authentication Technique for Smart Home Application

Mohib Ullah (MS-CNS)
Supervisor: Dr. Subhan Ullah"	The Internet of Things (IoT) technology is rapidly increasing day-by-day offers more opportunity. Many of IoT devices are placed in public places. The IoT have many challenges related to security, authentication and privacy, etc. The focus of this thesis is authentication of IoT devices within smart home IoT network. Only the legitimate devices can communicate with each other in a smart home. A real-time IoT networks like smart hospital, smart home etc, are time sensitive applications. In a smart house an intruder can manipulate devices such as lock the smart door and modifying heat, ventilation and air conditioning settings (HVAC). In the smart home all sensors are authenticated with a gateway and the gateway have a key pool for sensor nodes, where nodes are requesting for authentication to gateway. Gateway is a sensor device, and when multiple authentication requests come to gateway on the same time the gateway can be congested or down. Since the second concern is the security when the IoT enabled devices are requesting the cloud datacenter to ping for consuming some service over it. Data center which run in the cloud environment and does not respond once the authentication has been done. In the proposed lightweight authentication scheme we deploy an authentication server (AS) to reduce the congestion on gateway. Deployment of AS decreases overhead from gateway and also protects the web server (Cloud) from being attacked by illegitimate users. In the proposed scheme XOR, addition, subtraction and one time hash function are used for lightweight authentication between sensor nodes and authentication servers. The proposed approach is very efficient and use low computational power. During authentication between IoT devices and AS, there is minimum number of authentication messages have been exchanged. Due to the minimum number of exchange messages and lightweight a XOR operation the IoT devices have been minimized the execution time, network usage, delay, computational cost and communication cost. The proposed scheme presents lightweight authentication that is secure from well-known attacks like spoofing. The results show that the proposed scheme minimizes the network usage 25%, network delay 22% and reduce the execution time by 19%. The novelty of this work is to reduce a bottleneck on the gateway.
"Securing IoT Devices from Unauthorized
 Access in Smart Homes using Software Defined Networks (SDN)


Hassan Abdul Ghaffar (MS-CNS)
Supervisor: Dr. Abdul Waheed"	connected and accessible through the internet. Majority of IoT devices however have not been designed with strong emphasis on security in mind at the time of manufacturing and are thus, vulnerable to illegitimate access. Existing solutions to protect IoT devices are mainly based onOpenFlowtechnology. However, traditional routers come with builtin firmware hard coded by the manufacturer thereby, lacking scalability and customization features. Moreover, existing IoT security approaches are mostly based on authentication and encryption mechanisms that are not optimized for low-power, computationally and resource constrained devices. For such devices, authentication and encryption mechanisms are still in the infancy of their research and are often unable to provide guaranteed results. In recent years, flowbased network security solutions have taken the spotlight. This researchwork proposes a universal and easy to deploy mechanism that has builtin scalability and customization features while restricting unauthorized access to IoT devices. The proposed framework has been simulated using CloudSimSDN and makes use of Software Defined Network’s (SDN) controller augmented with amicrocontroller. All inbound and outbound traffic to/from IoT devices will be monitored and filtered by the microcontroller based on a set of installed rules that are provided by the SDN controller. The flow rules are generated based on policies implemented on the SDN controller via the northbound interface. As proof of concept, this research work makes use of flow rules that are installed for the purpose of blocking volume based attacks thereby taking into account the amount of traffic generated/destined by/for IoT devices. The proposed framework performs flow-level characterization of IoT traffic with minimal resource utilization and processing costs. Demonstrated by simulated results, the proposed solution restricts unauthorized access to IoT devices with less energy consumption, CPU usage, RAM consumption, data-plane and IoT traffic load compared to existing solutions. The proposed approach has been validated and evaluated via load overflow on sensors and an analysis of the output has been generated, resulting in the successful blocking of volume-based attacks.
"DDOS attacks Mitigation in Data Centre Networks using SDN

Muhammad Ijaz Riaz (MS-CNS)
Supervisor: Dr. Abdul Waheed"	TCP SYN flood attacks are the highly occurred Distributed Denial of Services attack type that consumes large proportion of the server resources in the Data Center Networks (DCNs). The DCNs consists of complex architecture with large number of network devices. Software Define Networking (SDN) appeared as flexible technology that can be deployed on the existing DCNs infrastructure for improved security and management. The existing schemes incur high cost on part of webservers as well as SDN controller during the SYN Flood attack. This research work introduces a novel SDN-based methodology to detect and mitigate SYN flood attacks in DCNs. The proposed methodology protects the DCNs against SYN flood attack at the expense of least resource consumption as compared to existing schemes while ensuring the servers' availability to legitimate users.
"Mitigation of ARP broadcasting in Data Centre using SDN

Ahmad Raza Cheema (MS-CNS)
Supervisor: Dr. Abdul Waheed "	"Ethernet is the most widely trusted network technology due to its high speed, low cost and sharing of resources with high performance. However, there are many practical limitations attached to the Ethernet that hinders the scalability of the network due to its broadcast mechanism particularly which is linked with the discovery process. Software Defined Network (SDN) is an emerging paradigm which have solved many existing issues in the legacy network and we have utilized its services in order to minimize the ARP broadcasting in the Campus Area Network. Existing frameworks which are used to mitigate the broadcasting of ARP packets using SDN approach impose a significant load on control plane as all the packets are sent from the switch to the controller for processing. In our work we have proposed a technique which overcomes the issue of ARP broadcasting by balancing the load between the switches and the controller and enhance the performance of the network. We have also compared our results with
the existing approach and our simulation results verify that our proposed mechanism has the ability to suppress the broadcasting and improve the scalability of the network, lessening the peak overhead on the controller and improving the ARP response time.
"
"Machine Learning Approach of Detection of Backdoor Malware

Ali Raza Khaliq (MS-CNS)
Supervisor: Dr. SubhanUllah"	Backdoor malware is in the list of top 10 malwares that are mostly detected in organizations as they enter the victim’s computer and try to hide their registry key to conceal their detection and hook certain API calls for persistence. Recently hackers attacked Solar Wind by inserting malicious code into the updates that helped attackers to distribute the malware and install backdoor. This campaign was widespread, affecting public and private organizations around the world. Therefore, malware detection scheme is needed to detect the malware that is executed from legitimate software or malicious software to damage the victim’s computer by exploiting vulnerability. This thesis presents a hybrid malware detection technique that is the combination of both data mining and machine learning approaches to detect the backdoor malware. We perform static analysis technique to extract features of malware. We extract features from malware binaries then calling frequencies of the raw features are collected to select key features. Feature engineering technique is used to reduce the number of the selected features. Then, the created feature set is used to train three classifiers J48, Naïve Bayes and Simple logistic for the detection of malwares that exploit heap based overflow vulnerability. By embracing the notion of machine learning and data mining, a static malware detection technique is proposed for malware detection. The proposed technique is validated on two different validation models 10-Fold cross validation and use training set, and with these validation techniques, we achieved 90.29% and 84.46% accuracy. The proposed technique is easy to implement in operations of cyber security to comprehend the behavior of malwares targeting their organizations.
"Enhanced Clustering for Energy and Delay Sensitive Wireless Sensors Network

Hassam Ud Din (MS-CNS)
Dr. Abdul Waheed"	A Wireless Sensor Network (WSN) is comprised of several sensor nodes that are deployed in a specific area for cooperative monitoring and reporting of some events of interests. Due to resources constraints on part of such nodes, optimal energy utilization is the prime objective in almost all deployments of WSNs. In this regard, clustering the sensor network has proved to be a good strategy to prolong the network lifetime. However, the existing clustering techniques either generate huge network control overheads in clustering/re-clustering of network or make use of non-optimal data delivery routes. This research work proposes an Enhanced Clustering technique for Energy and Delay Sensitive (ECEDS) sensor network that not only achieves the clustering of network at the expense of least network control overheads but also establishes and maintains nearly optimal data delivery routes thereby reducing the data delivery latency. By virtue of its realistic clustering, re-clustering and clusters' merging criterion, the proposed EDEDS outperforms LEACH and Enhanced LEACH in terms of energy-efficiency and end-to-end delay as demonstrated in simulation results.
"Authorization policies for decentralized storage systems


Hooria Khan (MS-CNS)
Supervisor: Dr. Ehtesham Zahoor"	Cloud computing is considered one of the dominant domain within the field of information technology recently. It offers many services from the infrastructure to the software level. However, with all of the benefits cloud computing provides, there are still many challenges associated with it, such as high bandwidth of the internet, data security, accidental loss of data, and cyber-attacks. So, there is a need for a decentralized storage system that can store data independent of central authority and has more control over the system. Distributed file system(DFS) provides a solution that distributes data chunks in a network and stores it on local devices. The interplanetary file system(IPFS) is a famous type of DFS that provides alternative solutions for storing large amounts of data in a decentralized manner. It has versatile features in which data chunks are stored based on content addressing. However, it also has some limitations related to security. It does not provide any mechanism for implementing access control policies which become a hurdle for migrating sensitive data from cloud servers. In our proposed approach, we migrated data files with access policies from Amazon S3 to IPFS and stored access policies in our custom blockchain. Further, we’ve provided implementation and detailed performance evaluation results.
"EEG Based Diagnosis of Schizophrenia using machine learning

Talha Anwar (MS-DS)
Supervisor: Dr. Hammad Naveed"	Schizophrenia is a prolonged mental disorder that affects the behavioural, speech and thinking process of a person. This disease is characterized by delusion, hallucination and abrupt motor activities. Schizophrenia patients are diagnosed by a psychologist by asking questions and observing behaviours. This process is largely subjective and can be automated by analyzing electroencephalography (EEG) signals. The aim of this study was to design a machine learning approach that can accurately classify healthy subjects and schizophrenia patients using EEG. We first select the most variant electrodes and extract features from these electrodes. After selecting the best features, different machine learning classifiers are used to classify the disease. Our methodology is validated on different datasets. The proposed method is independent of the dataset and can be applied on any EEG schizophrenia dataset and other similar datasets of different diseases such as epilepsy, intellectual developmental disorder and Parkinson etc. To check the importance of electrodes, we used two scenarios. In one scenario, all electrodes are used, in other scenario only selected electrodes are used. We achieved best performance when selected electrodes are used. White noise is added to the dataset to check the reliability and robustness of approach against the noisy dataset. The performance of machine learning classifier is not affected much by adding 10% of noise to the data. We kept the same generic approach for all the datasets and diseases and achieved 93%, 85% and 80% F1 score on schizophrenia, epilepsy and Parkinson disease, respectively
"Visualizing Univariate data distribution: Comparative analysis of varying Boxplots

Ayesha Javed (MS-SE)
Supervisor: Dr. Faisal Cheema"	"The main motive to focus on visualization is that visuals are processed faster by the brain also they can express patterns easily. It helps to simplify complex information. Univariate data is a group of information dependent on only one random variable. Univariate analysis is mostly performed because it does not deal with effects on different relationships in variables and allows us to focus on the single attribute of data. We require visualization to check the distribution and analysis of univariate data. Multiple visualization techniques exist for univariate data analysis, but a reason to focus on boxplot variations was that it overcame shortcomings of previous visualization techniques like sample size and graphical representation also it is useful to express outliers of data, symmetry, and skewness of distributions. In literature, many boxplot variations and their comparison using different distributions exist but due to the lack of HCI perspective and lesser variations used for comparison that work is inadequate. The motivation behind this research is to figure out the best variation of boxplot with respect to HCI. This study focuses on the comparison and evaluation of boxplot variations as well as usability evaluation on four mostly used boxplot variations (i-e the Notched boxplot, Violin plot, Bean plot, and Beeswarm plot) that we implemented according to our research questions. Multiple datasets are used (i-e small, medium, and large) w.r.t each other and we performed analysis tasks on them. Effectiveness, efficiency, satisfaction, usefulness, understandability, learnability, and enjoyment are the metrics of usability which are being evaluated in this study. For the valuation of effectiveness and efficiency, a controlled experiment is conducted with 48 participants of which 24 are experienced and 24 are inexperienced. For the evaluation of the remaining usability metrics, a post-questionnaire was performed. Results of the controlled experiment show that boxplot variations act differently based on experimental factors. The effectiveness analysis indicates the beeswarm plot is more preferable over other variations, but the user
highly preferred the notched boxplot based on usability metrics. Based on experiment and its results, a set of guidelines recommended for designers, specific to boxplot variations."
"Face recognition from law resolution images 

Umer Sufyan (MS-CS)
Supervisor: Dr. Sibt Ul Hussain "	Face recognition systems have achieved near human performances on well known datasets in recent years. Neural networks are able to learn the image representation more accurately then before. Recognizing all the people in the wild is a long standing challenge. It has its own issues like poor illumination conditions and pose variations. Subsequently, Low Resolution Face Recognition (LRFR) also remains a difficult task because faces captured in such conditions are often contaminated by blur, nonuniform lighting, and non-frontal face pose. In this work, our main objective is to design a deep learning algorithm for recognizing all the visible faces from a low resolution image. We have tried to improve the performance of LRFR using generative adversarial net- works GANs by building an end-to-end pipeline for LRFR using GANs and state of the art recognition algorithm ArcFace. We test our system using SCFace dataset. We show that GAN based approaches can be used to improve the performance of LRFR.The proposed approach achieve near state of the art LRFR results by using GANs. 
"An Enhance Sybil Attack Detection in IOT 

Majida Khan Tareen (MS-CS)
Supervisor: Dr. Muhammad Asim"	"Internet of Things (IoT) is rapidly growing paradigm that has great effect on our life style. It has become essential part of our lives. It covers many domains including industries, automobile, transportation, cities, homes, sports and healthcare. In com- bination with the fast evolution of IoT, security and privacy becomes more important and highly challenging issue. Many researches gave solutions and ideas to resolve security issues in IoT. Along with many other security threats, one of them is Sybil attack. In this attack some adversary nodes in network create many fake identities. Then these illegal Sybil identities perform malicious activities in network. These nodes attract data towards them more then other normal nodes and lose data packets before forwarding it to destination. Such type of attacks are highly risky in almost every
scenario. Sybil attack are of two types, a direct Sybil attack and a colluded Sybil at- tack. The direct Sybil attack can easily occurred in both static and mobile networks but colluded Sybil attack is serious threat in case of mobile networks. To detect these attacks there exist numerous solutions, one of the most reliable countermeasure is Re- ceived signal strength indicator (RSSI) based scheme for localization and detection. It is lightweight localization solution that is vastly used to detect Sybil attack due to low cost and efficient energy. In this mechanism distance between sender and receiver is calculated and unique ids are assigned to them. Sybil attack is detected by comparing RSSI ratio time to time in network. But there are issues with RSSI based mechanisms, it can detect direct Sybil attack in static networks but majority of these mechanisms can not detect colluded Sybil attack in mobile networks. Also there is issues like extra energy usage, storage and communication complexity because of periodic localization. In this thesis, Sybil attack detection mechanism is proposed that can detect both di- rect and colluded Sybil attacks, also cater overhead issues by use of mobile agents and fog layer. Mobile agent is an independent entity placed in an environment, used to make different decisions based on objectives, it is capable of providing communication among network nodes, sink and fog intrusion detection system (IDS). While fog layer provides many facilities to end users. In this work we introduce mobile agent and fog layer to build a model that can cater the overhead issues and the results show better im- provements. There 11.7% improvement in computation overhead, 13.6% improvement in communication overhead and 17% improvement in storage. "
"An efficiet Trust-based routing in PRL to secure IoT network from Sybil attack


Danyal Arshad (MS-CS)
Supervisor: Dr. Muhammad Asim"	In recent years, the Internet of Things (lOT) and its relevant advances have pulled in scholarly, government, and industrial researchers' attention. Since the IoT specifi cations are quite difterent from what the Internet can deliver today, however, many groundbreaking techniques have slowly been developed and integrated into loT. The routing protocol for Low Power and Lossy network (RPL) is the de-facto loT routing protocol. RPL is susceptible to numerous internal attacks, however, the attacker node already part of a legitimate network. To counter this many techniques are available such as cryptography, intrusion detection system (IDS), and authorization. Enormous computations of these techniques limit them they do not apply directly to loT nodes due to low power and lossy nature of IoT devices. However, a trust-based technique provides vital security, by observing neighboring node behavior and eliminate ma licious nodes. Diferent trust-based strategies to protect RPL protocol from insider attackers have been suggested. They use several metrics, doing full node-level com- putations that lead to a decrease in the life span of nodes of Low Power and Lossy Network (LLN). We propose in this research a Trust-based Hybrid Cooperative RPL protocol (THC-RPL). In THC-RPL every node registered with a root node. Mobile node list created by the root node and disseminate to all child nodes. Child nodes Child nodes check the behavior of a directly connected neighbor. It checks the mobile node list It checks the mobile node list in case of a new identity, if it matches then it will perform their normal operations otherwise inform the root node about this new identity. We have compared our work with [1] and [2]. Evaluated overwork using the metrics number of attacks detected, packet loss ratio, the energy consumption of nodes, and average energy consumption of the network. Our techniques detects more number of attacks the packet loss ratio in our technique remains in the range of the 15-25o. Average energy consumption of the nodes are also remains in the ratio of 60-80(mj). THC-RPL is performing better and Onsumes less ernergy, less packet loss ratio, and detect more attacks.
"Disease and symptom classification on
social sites

Haider Ali
Supervisor: Dr. Omer Beg"	Social connecting sites plays important role in the connecting and communicating peo- ple, which help in sharing their opinions and others. With the increase in the number of users also increase the number of the opinions for specific task. Similarly health mention on social sites are increasing as well. Health mentions allow us to understand the disease outbreak and also the concern of the health mention. So there exist the ambiguity of the health mention whether the health mention is literal or non health usage. Mostly like cancer or heart related diseases rarely mentioned in literal meaning. In our research we will solve this problem the health and condition mentioning on so- cial sites. This particular task will be the first phase of the classification as there is large unstructured and unlabelled dataset available.The dataset used in this research will betweets. In our case diseases used were flu, insomnia, asthma and diabetes . We also have labelled data and used different machine learning and deep learning techniques to this problem.
"Automated Detection of Diabetic
Retinopathy using Machine Learning
Aided with Augmented Features

Muhammad Usman (MS-CS)
Supervisor: Dr. Omer Ishaq "	Diabetic retinopathy (DR) is a vasculopathy, damages vessels in the eye. It is the main cause of preventable blindness in the age group of twenty to seventy four years. Almost half of diabetic patients are vulnerable to DR, however fewer than half of DR patients know their condition. Therefore, early detection and treatment of DR is essen tial to reduce no of patients who lost their vision due to this. Ophthalmologists typically iagnose the presence and severity of DR by examining the colored fundus image and condition of the patient. Many automated solution of detection and classifications of DR were proposed in the past. Thosetechniques fail at a certain point due to factors like equipment used to capture the fundus image and Data-set size as it is also a major factor for deep learning-based solutions for DR clas- sification. We provided solution to tackle the issues of smaller data-set in DR classification by  using augmented features for classification and improved the results on IDRiD data- set by achieving 76% accuracy without using any external data for training. Accuracy also remains stable when only 50% IDRiD data used, resulting in reduced need of data points for DR classification. 
"3D Cell Segmentation


Ahsan Shafiq (MS-CS)
Supervisor: Dr. Omer Ishaq "	Time-lapse microscopy is used for analysis of biological structure and function in dif- ferent bio-medical applications. Segmentation and tracking of these structures are two of the fundamental operations in such applications. These microscopic image datasets can sometimes suffer from information loss due to low signal-to-noise ratio (SNR) and contrast ratio (CR). Video frames suffering from low SNR and CR cannot be segmented easily and they require customized methods for segmentation and tracking. We targeted the segmentation of Fluo-N3DH-CE dataset which is openly available cell image dataset in time-lapse videos. This dataset was obtained using confocal micro- scope, which is a specific fluorescent microscope that allows obtaining 3D images of the sample with good resolution. This dataset is part of the ISBI cell tracking chal- lenge. It is suffering from low SNR and CR. Previously this dataset has been found to be difficult to segment using commonly available image analysis pipelines. Our aim is to accurately segment cell boundaries in these time-lapse videos. Segmenting and tracking of cells is required and used in scientific and industrial applications like early medical diagnosis and medicine. We proposed customized image analysis pipeline for this dataset. This pipeline is a hybrid between traditional image processing algorithms and deep learning models.This pipeline first uses object detection algorithm to detect cellular regions in the image followed by a classification algorithm which removes false-positive regions detected by detection algorithm. After that images are passed through an image processing pipeline to get the final segmentation. We introduced a new method to handle the false negative and false positive detected regions for 3D images. For Fluo-N3DH-CE training dataset we have achieved competitive results.
"An Adaptive System for Tajweed Learning and
Teaching: A User Centered Design Approach

Aiman Ali (MS-CS)
Supervisor: Dr. Amna Basharat "	In the context of the recitation of the Quran, Tajweed is a set of rules for the correct pronunciation of the letters. Tajweed is effectively taught when the teacher gives feedback to students in realtime. However, online students learn Tajweed by communicating with teachers through voice notes, which is not as effective as learning in person. Contemporary Tajweed learning systems attempt to eliminate the role of a teacher in the process of teaching Tajweed. The aim of this study is to design a Tajweed learning and teaching adaptive system to be used by teachers in order to provide personalized feedback to their online students, thereby assisting teachers and students. We  conducted needs assessment through semi structured interviews and questionnaires at an institute in Islamabad. Based on findings, the design implications for the ap- plication design were generated. We involved the users throughout the user centered design process to ensure that the application is aligned with the users’ expectations. We conducted two rounds of empirical evaluation through prototypes to evaluate our design with teachers and students with think-aloud protocol and Technology Accep- tance Model (TAM) questionnaires as evaluation instruments. Results suggest that our application meets the needs of Tajweed teachers and students as they perceived it practical and useful.
"Ontology Based Knowledge Model for Tajweed of the Holy Quran 

Ramsha Amin (MS-CS)
Supervisor: Dr. Amna Basharat "	Semantic web is an extension of the current web in which semantic-based techniques are used to define and link data which provides better information integration and search experiences for the web users. In the domain of Islamic knowledge, especially focusing on the Quranic Tajweed which is the science of Quranic recitation, not enough work has been done for gathering all the knowledge related to the recitation rules of the Holy Quran in one place. Ontologies, are one of the tools frequently used for organizing knowledge which describes the terms of the domain and explains the relationships among them. In our study, we have developed an ontology-based Tajweed knowledge model by using Proteg ́ e framework and state-of-the-art semantic web technologies (OWL and SPARQL). METHONTOLOGY, an iterative design methodology was used for the ontology development that describes the articulation points of Arabic letters and their characteristics together with the Tajweed rules. It consists of 47 concepts and includes 167 individuals in Arabic, English, and Urdu. Semantic Web Rule Language (SWRL) was used for the implementation of the Tajweed rules. The ontology was evaluated in two steps. In the first phase the expert driven validation and criteria based evaluation was conducted for the Arabic letters and their charac teristics to evaluate the accuracy and structure of ontology. Results from the experts were incrementally improved before evaluating it with the next expert which results in 100% accuracy. In the second stage we evaluated the developed Tajweed rules on the complete text of the Holy Quran. We achieved almost the best F1 score i.e, 94% which shows that maximum rules were predicted correctly by our designed knowledge model. Also, the dataset of the entire Quran was generated in OWL format using the developed ontology.
"ML based Classification to Predict Aetiological LncRNAs in Humans 

Razia Khalid  (MS-CS)
Supervisor: Dr. Zoya Khalid"	"Long non-coding RNAs (lncRNAs), which were once considered as transcriptional to fully comprehend the involvement of lncRNAs with disease formation.
noise, are now in the limelight of current research. LncRNAs play a major role in regulating various biological processes such as imprinting, cell differentiation, and splicing, to name a few. The mutations of lncRNAs are involved in various complex diseases and identifying lncRNA-disease associations has gained a lot of attention as predicting it efficiently will lead towards better disease treatment. In this study, we have developed a machine learning model that predicts disease-related lncRNAs by combining sequence and structure-based features. The features were trained on different machine learning models that includes SVM, Naive Bayes, Xgboost and Random Forest. The results showed that SVM had outperformed with the highest F1-score of 0.75 without similarity cut-off and 0.55 with a 70% similarity cut-off. We compared our method with the state-of-the-art and obtained a similar F1-score of 0.65 with non-redundant data and 0.86 with redundant data. Moreover, this study has overcome two serious limitations of the reported method which are lack in redundancy checking and implementation of oversampling for balancing the positive and negative classes. So far, our developed method has achieved an improved performance among the machine learn ing models reported for the lncRNA-disease associations. Still, there is a huge room for improvement, hence in the future, we will also combine features from biological pathways to predict lncRNA disease association and"
"Predicting Drug-Target Interactions Using ML Techniques 

Hamna Anwar (MS-CS)
Supervisor: Dr. Zoya Khalid "	The traditional drug development process is long and costly, with drug side effects often being the cause of its high failure rate. Side effects occur because drugs typically bind to multiple protein targets in the body. We aim to supplement this development process by computationaly predicting drug target interactions, thereby saving time and money as well as enabling drug repuurposing. We leverage sequence features of the targets and in some models, molecular structural features of drugs, as predictors for various machine learning algorithms. Sequence information is easily available for many more targets than other complex feature information such as structural information and gene expression data. Models are created for two broad categories of targets: those belonging to diverse protein families and those belonging to the kinase protein Results show that SVM with protein and drug features performs best on both the Kifamily. nase and Diverse datasets. On the Kinase dataset, we achieved 60.7% sensitivity and 61.9% Specificity. The state of the art method [1], which uses structural binding site information, achieves an average sensitivity of 52% and average specificity of 55%. On the Diverse dataset, we achieved 98.2% sensitivity and 98.2% specificity. In comparison, the state of the art method, achieves an average sensitivity of 63% and average specificity of 81%. Therefore, we can use SVM with features consisting of simple sequence information of targets and molecular structural information of drugs as a generic model for classifying drug-target predictions of targets and drugs belonging to same and diverse families
"Detecting Web Applications Vulnerabilities Using Machine Learning 

Waqas Tahir  (MS-CS)
Supervisor: Dr. Omer Beg"	In recent years, the number of cyber-attacks is growing rapidly. Every product or service which is connected to the internet is vulnerable to this issue. Every top company has faced this directly or indirectly which ultimately affects their reputation, trust and face regulatory fines. To prevent these issues organization employee's cybersecurity persons to follow security standards or perform a security audit of their product in which another company performs these tasks called the blue team. made it a new gold mine. Amongst all other, web applications are the top vulnerable source for the hacker. This is because they are virtually always exposed to the hacker to access them. Web attacks are of many types like on network or application attacks. Application attack contains the domain of surface vulnerability attack which is caused by human error. These errors can expose the system to malware or cyber-attack. Some popular attacks are SQLI, XSS, LSF etc. These errors are hard to find and need the brute force technique in black-box testing. Looking into the code we can find it as a special case of natural language. The code is acting as a communication medium of command betweern humans and machines. We been human can analysis the code to identify the vulnerable part but this is a challenge for the machine. We are proposing a novel way in which we will process this code using NLP technique and find vulnerability using a similarity classifier
"Predicting Protien-Ligand Interactions using Genetic Algorithm & Machine Learning 

Zubash Alam (MS-CS)
Supervisor: Dr. Hammad Naveed 
"	In silico methods, present efficient ways to predict potential interactions between targets and ligands. Identification of protein-ligand interactions are time consuming and costly, to overcome these limitations we design Machine Learning models that can be helpful in discovering drugs and also beneficial for understanding side effects caused from existing drugs. Therefore, we have proposed a feature selection based model to describe the interactions between targets and ligands. We extracted targets and ligands from sc-PDB database. In the first phase, we created target dictionary and identified different sequence-based features such as propensity, physico-chemical features of amino acids for each target. Each binding site is divided into 4200 trimmer features and further divided into 199 trimmer clusters according to their physico-chemical properties. For ligands, we created ligand dictionary and every ligand is represented as binary vector of 747-dimensional, whose elements indicate the existence or absence of every substructure. After extracting all features, we applied an Extremely Randomized Trees on extracted features i.e. propensity, physico-chemical properties as well as on trimmer features obtained from binding sites to reduce dimensions and improve accuracy. Finally, we applied different machine learning models i.e. SVM, RF, NN, KNN for predicting protein-ligand interaction and get 93 % accuracy.
"Deep Neural Network Based Detection of Wmotion in NL 

Adil Majeed (MS-CS)
Supervisor: Dr. Hassan Mujtaba "	Emotion detection is playing a very important role in our life. People express their emotions in different ways i.e face expression, gestures, speech, and text. This research focuses 00 detecting emotions from the Roman Urdu text. Previously, A lot of work has been done on different languages for emotion detection but there is limited work done in Roman Urdu. Therefore, there is a need to explore Roman Urdu as it is the most widely used language on social media platforms for communication. One major issue for the Roman Urdu is the absence of benchmark corpora for emotion detection from text because language assets are essential for different natural language process-ing (NIL') tasks. There are many useful applications of the emotional analysis of a text such as improving the quality of products, dialog systems, investment trends, men-tal health. In this research, to focus on the emotional polarity of the Roman Urdu sentence we develop a comprehensive corpus of 18k sentences that are gathered from different domains and annotate it with six different classes. We also proposed an en-semble model for emotion detection from the Roman Urdu text. Our proposed model is based on LSTM (Long short-term memory) and CNN (Convolutional neural net-work) feature learners. We applied different baseline algorithms like LSTM, Adaboost, XGboost, MLI, KNN, Decision tree, SVM, and Random Forest on our corpus. After experimentation and evaluation, the results showed that our model achieves better F-measure score than LSTM, KNN, SVM, Adaboost, XGboost, MLP, Decision tree, and Random Forest.
"Aspect Feature Based Opinion Mining Using Deep Neural Network

Rabail Zahid (MS-CS)
Supervisor: Dr. Hasan Mujtaba "	"Social media, today, demonstrates the rapid growth of modern society as it becomes the main platform for Internet users to communicate and express themselves. Now a days it is impossible to imagine our lives without gadgets like computers, smart-phones, lap- tops, and tablets. People around the world, use many devices and resources to access the Internet, set up social networks, conduct online business, e-commerce, e-surveys, etc. Currently, social media is not only a technology that provides information to consumers, but it also encourages users to connect and share their views and perspectivesS. It leads to an increase in inspiration towards Opinion Mining (OM), which is important for both customers and companies. Individuals like to see the opinions provided by other customers about a particular product or a service. Companies need to analyze their customer's feedback to strengthen their business decisions. This work proposes a novel approach Aspect-Feature-Based Opinion Mining Using Deep Neural Network. The proposed algorithm will be able to extract significant features from reviews. These features are then used for Aspect Category Detection which could be beneficial for market research and product enhancement. We normalized our dataset for tagging nouns and adjectives. It helps us in finding the aspects from the review. Our proposed framework tackles the problem by using Word2vec and glove embedding together with CNN and attention. Our methodology provides better outcomes than other methods used for this purpose. The results demonstrate 60% F1-score for aspect detection and80% for aspect-based polarity.
"
"Context Aware Characterization of Offensive Language in Natural Language. 

Muhammad Owais Idrees (MS-CS)
Supervisor: Dr. Hasan Mujtaba  "	"The free speech on social media enables people to express their emotions and ideas on social media or verbally. On the other hand, that speech can hurt someones feeling and can be a case of mental torture. Sonmething that is ottensive upsets or enmbarrasses people because it is rude or insulting is called offensive language. Nowadays, the use of social media has increased to a great extent and it has become a source of expression for people's feelings and reviews. Due to free speech, people are always afraid of being attacked or criticized by someone. Although some social media platfornm provides the option of filtering the content that is limited to blacklist word. So, there is a requirement for automatic detection of offense language online and take some action against the predator/ extremist. We propose a model for the detection of oftensive language in the Urdu language social media. In literature, it has been reported that most of the researchers used the blacklist technicque and other features to predict the offensive language. Our work explores the context and subject of the sentence that have much impact on the sentence. So, we take the context and subject as the main features and use deep neural networks for the classification of offensive language. We explore more features including the polarity of the sentence and train
model on deep neural networks with attention and LSTMs layers because it maintains the context in a good manner, which can be seen through its success in sequencing tasks. The model is compared with its benchmark by using the Fl evaluation matrix and achieve good results. This approach was challenging because of less availability of data. We create a new dataset tor our research purpose. We will make our modeleasily available for the public and future research "
"Enploiting Logs to Predict the Energy Consumtion of Android Applications

Mamoona Bilal (MS-CS)
Supervisor: Dr. Omer Beg "	Logging is a common practice in software development. Previous research has exam- ined the properties of logging techniques in system software and desktop applications. Although mobile applications are very popular, little is known about logging. In An- droid applications, our focus is on logging. Several research studies have focused on overcoming energy related-issues in Android applications. We use logging to predict the energy consumption of Android applications. For this, we selected 24 open-source Android applications in the FDroid repository. In this research work, we find different logs and then predict the energy consumption of different Android applications. En- ergy is calculated by using an Android energy profiler. Our model uses an ensemble technique for the prediction of energy and fine tuned MLP regressor achieve better results in tfidf with 5.30 MAE error. Five similar activities are performed in 10 appli- cations and on the basis of the activity logs and energy we predict the efficiency of theapplication on average energy.
"Contact Aware emotion detection in texual conversation

Syed Ali Imran (MS-CS)
Supervisor: Dr. Omer Ishaq 
"	Analysis on the basis of emotions is quite exasperating challenge for Natural Language Processing. Finding the emotions of a person in a conversation such as happy, sad and angry is difficult and becomes more challenging when we have to consider context and background of the whole conversation instead of just one sentence. Mapping and keeping track of long sentence dependencies is unsuitable and challenging even for methods like neural network, problems like vanishing gradients make it strenuous for coming up with a good classifier. We propose a method based on transformers, self attention mechanism and bert base, for the classification of emotion during a textual conversation. In our approach we extended pair to pair relationship between words using the attention mechanism. In our research, we experimented with different networks, and parameters to find the best result. We researched, with respect to embedding representations, attention mechanism, pre-processing and network architecture. Our proposed method, which extends attention mechanism, was able to beat the state of the art. 
"Protein Secondary Structure prediction
using Sequential Features

Hamza Mustafa Alvi (MS-CS)
Supervisor: Dr. Hammad Naveed "	Secondary structure of protein is used in studying the 3D structure of the protein. 3D structure is helpful in studying the function of protein, which helps in designing the drugs that bind to specific proteins. Most of the existing studies only use sequence and position specific scoring matrix (PSSM) to predict the secondary structure or they use deep learning models to capture local and global context of amino acids from the sequences. A deep learning model can effectively capture local or global context, it can’t capture both effectively. To address this problem, we used local context of amino acid as motifs and anti-motifs in deep learning models. Class-specific motifs and anti-motifs alone produced 43.8% Q3 accuracy. Thus incorporating this information will lead to better results. Moreover, we used pre-trained embeddings of amino acids along with the sequence and PSSM as input features for the deep learning model. The model using pre-trained embeddings reached to a Q8 accuracy of 71.7%. Most of the recent studies used deep learning models that include convolutional neural networks (CNN) and/or recurrent neural networks (RNN). In contrast to these, we have used attention based RNN model that incorporates the importance of residues while making prediction. The attention based LSTM produced a Q8 accuracy of 68.5%. In future, we will combine all the above mentioned features to improve the performance of proposeddeep learning based models.
"A qualitative and quantitative analysis of gamification elements on its effectiveness

Uqba Awan (MS-SE)
Supervisor: Dr. Naveed Ahmad "	Gamification has been widely employed in the educational domain over the past eight years. It is the use of game elements in a non-gaming context to increase the engagement between human and computers and to solve problems effectively. Effectiveness of gamification is a well-studied problem, it has been proven in learning mathematical concepts at the primary-school level. p carefully designed games improve the effectiveness of gamification. However, gamification still lacks the use of some game design factors. A qualitative and quantitative analysis is required to see the impact of different elements on effectiveness of gamification. In this study we consolidate the list of elements/guidelines for gamification, investigate their presence in top games, and identify the elements which are most influential in the effectiveness of gamification. To test this a controlled experiment is conducted in Primary school of Pakistan, the results indicate strong correlation between game design elements and effectiveness of gamification. Top identified gamification elements we found at the end of experiment results not only help students to engage and motivate in learning but also aid game designers . in developing effective educational mathematical games in future. This study would be a great contribution in HCI field, as we are studying gamification elements and it is an interesting research topic in HCI field.
"Automated Hardware-in-the-loop
Testing of UAV systems

Hira Naveed (MS-SE)
Supervisor: Dr. Zohaib Zafar Iqbal "	Avionics present in UAVs fall under the category of safety critical systems. Testing them is an extremely laborious yet important task. Hardware in the Loop (HiL) simulation is an industry wide accepted strategy for testing hardware components in a virtual setup. HiL is often used for testing avionic systems as it provides the benefits of early testing without high costs or the risk of  damage to the system and the environment. urrently only HiL test execution has been automated whereas test cases are still written manually, which is difficult and expensive in terms of time and effort. There is no existing work in literature that automatically generates HiL test cases for UAV systems. This thesis shall propose an automated model-based approach for HiL testing of UAV systems using high fidelity digital twins that act as virtual replicas of the hardware components. The presented technique has been evaluated on the A10-Thunderbolt case study and one bug has been identified.
"A Model based approach to transfer Elderly Care/ Fall Prevention System data to FHIR Conformant data ""

Muhammad Salman Tariq (MS-SE)
Supervisor: Dr. Atif Aftab A Jilani "	Over the past few years, healthcare industry has witnessed a sharp increase in digitization. The patient data is a crucial component of healthcare systems and is used for various purposes that range from the diagnosis and treatment of the patient to research. For such purposes this data quite often has to be transferred and exchanged among different healthcare platforms. Thus, creating a need for compliance to a healthcare data exchange standard to ensure wider interoperability amongst the healthcare systems. One of the most widely used standard used for this very purpose is (Health Level Seven) HL7. The latest variant of HL7 called Fast Healthcare Interoperability Resources (FHIR) incorporates the latest technologies of web for data transmission. Yet despite the features offered FHIR itself is yet to witness widespread adoption because there is a lack of an approach that automatically converts existing non-compliant patient data to its equivalent in FHIR compliant resource due to the diversity in the structures of FHIR resources. Existing approaches that range from Ontologies to Rule based reasoning still involve significant manual effort or don’t entirely convert the data to equivalent FHIR form. Hence keeping the limitations in mind, we propose a novel model-based approach that applies the concepts of model transformations to convert non-compliant FHIR data into an FHIR compliant one. In this approach we first identify the possible mappings at meta-level and then develop subsequent transformation rules between the non-compliant data and the FHIR standard’s specification. Once identified we use those transformation rules to create FHIR compliant models. We then develop a tool that reads the non-compliant patient data as models and based on the transformation rules/restrictions generates corresponding FHIR resources. Each generated resource is then sent to an FHIR compliant server to check its validity. The approach is further evaluated by experimenting on an industrial case study of a fall prevention system that has the patient data of approximately 5000 patients. Our experiment results show that our model transformations successfully converted that non-compliant patient data into its equivalent FHIR resource. 
"Usability Evaluation of Facebook and Instagram
by Visually Impaired People

Amna Sajid (MS-SE)
Supervisor: Dr Naveed Ahmad"	Social networking websites have become the main medium for communication, information sharing, entertainment, buying/selling, and various other purposes. People of every age use social networking websites and their usage is increasing day by day especially in current circumstances. People with different abilities also use social networking websites, but each set of users have their requirements when it comes to using these websites. Visually impaired people use computers and web with the help of screen reading tools e.g.; JAWS, NVDA, and others. Screen reading tools read a web page in a sequential manner which is time-consuming. The major problem with screen readings tools comes while reading visual contents. Screen reading tools only read the alternate text of non-visual contents behind its tag. If the alternate text is empty the screen reader cannot describe a non-visual content so it is not accessible to visually impaired users. WCAG (Web Content Accessibility Guidelines) is the de facto standard proposed by W3C (World Wide Web Consortium) which is an international organization. These guidelines are generic and can apply to all kinds of websites. This study focuses on the usability of social networking websites by visually impaired people. Two of the most commonly used social networking websites acebook and Instagram are selected for the usability evaluation because these are used by sight as well as visually impaired and it is a demand of the era. Accessibility, efficiency, and effectiveness are the metrics of usability which are being evaluated in this study. For the evaluation of usability, a controlled experiment is conducted with 28 visually impaired people in which 16 participants evaluate Facebook and 12 evaluates Instagram to find the usability problems faced by visually impaired people. Results of the controlled experiment show that Instagram is more usable to visually impaired people as of Facebook. After that, a set of consolidated guidelines specific forsocial networking websites are presented in which some new guidelines are also proposed for Facebook. Based on the new proposed guidelines for Facebook a mock interface is developed.
"A Social Network approach to resolve biasedness and Prioritization issues in  requirement engineering ""

Haris Yaqub (MS-SE)
Supervisor: Dr. Naveed Ahmad "	Social network helps us in almost every aspect of life such as digital marketing, education, business and in requirement engineering. In requirement engineering, social network helps us in identification of stakeholders, stakeholder's prioritization, elicitation of requirements and requirement prioritization. Whileconstructing a stakeholder's interaction network, stakeholders are recommending their friends as other key stakeholders of the project, so biasness issue arises. Some of the researcher has tried to resolve the biasness issue by creating a stakeholder interaction network and applying different centrality measures but it is still considered as an unresolved issue. This is a result of the way this network is constructed. In some cases, researchers have not considered the weighted graph and treat all stakeholders equally influential. In case of weighted graphs, they have put the weight on the edges, which depicts the strength ofa relationship between stakeholders rather than the stakeholders influence on the project. They have treated the strength of relationship between stakeholders as the stakeholder's weight in the project. This research proposes a new technique of coInstruction using bipartite graph between stakeholders and requirements. We used page rank, degree centrality along with TOPSIS for measuring influence and activeness of stakeholders. This technique allows us to prioritize stakeholders and requirements by minimizing the biasness because this technique is on the basis of activeness and influence of stakeholder in the project. For the evaluation of our technique we have performed a controlled experiment and compared the results with state of the art. It was observed from the Tesult of our experiment that our proposed social network process prioritizes the stakeholders and requirements effectively
"Methematical Model to Understand Behavior of Changes in Software Projects

Aruba Haroon (MS-SE)
Supervisor: Dr. Naveed Ahmad"	Changes are ubiquitous they can occur at any stage and may affect the project performance. Unmanaged changes result in project delays and in the worst case can lead to project failure. Priorimpact analysis techniques are qualitative (rely on subjective opinion of practitioners) as well as quantitative (use models to quantify impact). Most of the quantitative methods use estimation models and rely on information such as: LOC (also relate it to type change request addition, deletion, or modification), actual effort, development code status to determine impact of changes but do not consider important information which is basis of project scheduling. It includes but not limited to number of tasks, size of project, number of change requests, arrival time of changes, change types etc. Hence, there is a need of a model that includes this information when determining impact of changes. There are two phases of this research. In the first phase, we gathered change request data of seven projects and used this data to test the hypotheses identified from literature. The results of these tests prove the relationship between number/arrival time of changes request on project lead time. In the second phase, we constructed a mathematical model for change impact analysis. In order to validate the accuracy of the model we compared the results with the actual project data. The results suggest that the proposed model can help in analyzing the impact of changes and can support change impact analysis in industry.
"Enhancing E-Commerce Usibility for Visually Impaired 


Hassan Imtiaz (MS-SE)
Supervisor: Dr. Naveed Ahmad"	Graphical User Interface was developed to make the user comfortable while using the application or website but the Visually Impaired have to use other ways to access the same interface. They mainly use synthesizers or screen readers. While using a website with a screen reader visually impaired face different types of issues like a communication gap between user and machine, text enhancement, etc. These issues not only become a barrier for VI users but also have an adverse effect on the user Among those different issues reaching a goal or specific link in less time with a screen reader is an issue because the screen reader reads everything in sequence on a webpage. In this research, we propose and develop a new interface in the form of mindmaps. The graphical representation shows the information in hierarchical form. When the thing in the hierarchy it is easy to understand as a whole or graph. Find the goal in a smaller solution space is easier to find. To evaluate our solution we performed a controlled experiment with visually impaired users. The results indicated that the new interface helps the visually impaired user in navigation as well as reaching the goal in less time.
"Model guided Reinforcement-Learning
based Automated Game Testing
Approach for Platform games


Nigar Azhar Butt (MS-SE)
Supervisor: Dr. Zohaib Zafar Iqbal 

"	In the last few years, the number of games produced yearly has increased radically. The most common way of testing games in the industry is through manual execution of simple to complex scenarios by the testers. This becomes a monotonous and tedious task especially for frequently changing games. Recently, several approaches have been proposed for automated game-testing. However, these generally require either refactoring the game's actual source code to get the required information from the game to handle automated testing, or necessitate the development of the game in a particular platform such as Unity3D. Since game testing is generally outsourced and the source code of the game under testing is not made available, the industry professionals are generally forced to manually test the games. Hence, keeping these limitations in mind, we propose an automated game testing approach for Platform games using high-dimensional Sensory Inputs. It is a model guided deep Reinforcement learning based approach that allows for automated testing of platform games. Allowing us to find the test scenarios that catch bugs, without need to refactor the source code of the game to make it testable. A UML class diagram and state machine model, specific to the game under test is developed using the provided game testing profile. Our approach extracts the set of user actions and configuration information for the DRL agent from the model. We then find the user action sequences using our model guided deep einforcement Learning approach to catch bugs, using the developed UML state machine model to ensure the validity of test cases. To the best of our knowledge, we introduce the first deep reinforcement learning agent that learns with the aid of UML models. We demonstrate our model-based approach by using an open-source implementation of Flappy bird game. Our controlled experiment evaluates the goal-achieving capability of our approach using standard gym-atari setup used for evaluation of DRL algorithms on Atari Alien and Space Invaders. Our experiment shows that our model guided DRL performs better than traditional DRL.
"Porting Legacy Application to Achieve FACE Data Layer Compliance 

Wajeeha Khanam (MS-SE)
Supervisor: Dr. Zohaib Zafar Iqbal "	"In today's world when technology is changing so quickly that it is hard to cope with it effectively in real time industries like aviation industry. Safety critical systems require a lot of budget, time and human resources to fulfil standardized systems regarding safety and security point of view. Industry is seriously striving toward the solution having reusability, portability andinteroperability concepts. Future Airborne Capability Environment (FACE) reference architecture is one the solution proposed so far that is covering all mentioned concepts including budget and time redeemable. Research is going on FACE to make new systems FACE compliant and get benefits of FACE. But as mentioned aviation industry applications take huge amount of resources and they cannot be simply thrown to shift on new technology. There are a lot of systems still being used as legacy systems and bound to specific platforms and can onlycommunicate with limited defined systems. So, it is needed to do research on it to propose some automated or semi- automated approach that helps in converting these legacy codes into FACE compliant efficiently and effectively. An industrial case study is selected to evaluate our approach on it to test its effectiveness. This research is based on proof of concept for automation of legacy system for FACE compliance. There are certain limitations discussed in detail
in report that can be addressed in future."
"""Goal based safety requirements elicitation at runtime for smart autonomous systems (SAS)""

Ghulam Zainab (MS-SE)
Supervisor: Dr. Irum Inayat "	Smart autonomous systems face uncertainty or runtime change of situation without any human intervention. Wrong or incomplete safety requirements may lead to disasters. Mostly safety requirements are written and retrieved at design time from users or stakeholders but as smart autonomous systems face uncertain situations at runtime thus arising a need to monitor and specify safety requirements at runtime. This study is designed to handle the increasing safety requirements of smart autonomous systems. For this, the proposed solution is to identify the afetyrequirements of smart autonomous systems from critical scenarios by using goal based approaches. The Gore methods are applied to find runtime safety requirements on the agriculture domain case study Tractor implement automation(TIA). The gore methods are analyzed using the DESMET evaluation technique. Methods are analyzed for evaluating the features of methods and the number of requirements was identified. From the results, it showed that the I* method can be used for better results for generating requirements. The limitation of our approach is that we have not compared the accuracy of the methods empirically. Our future work includes in finding the accuracy of the used GORE methods in this research.
"Automated Testing of Self Adaptive
Behavior of UAVs in Swarm

Abeera Naveed (MS-SE)
Supervisor: Dr. Uzair Khan "	The UAVs swarm is an emerging area of research due to its utilization in a complex mission environment. Many swarm controlling strategies have been proposed that help UAVs to cooperatively move into the mission environment towards the target while avoiding conflict between swarm members and other elements of the environment. To make these systems compliant to the safety standard of aviation, testing such systems have the utmost importance. The common practice that has been adopted for the testing of such system is simulation-based testing where the system model is tested in simulated scenarios. These simulated scenarios are manually created by the tester through the configuration of all the parameters of the simulated mission. Manually creating testing scenarios for mission-critical systems that require rigorous testing of the system on all scenarios that can be possible in a mission environment is a quite laborious and tedious task. In contrast to that, there is limited research in the field of automating the process of test scenario generation for testing the self-adaptive behavior of swarm. Existing approaches that automate the process of generating testing scenarios are not thorough they have not considered parameters related to all the possible elements of mission that need to be configured or that can trigger the self-adaptive behavior of UAVs in swarm including parameters related to UAV model, behavioral parameters and none of them have generated testing scenarios for a swarm of UAVs. So, considering aviation industry safety requirements and limitation of existing testing approaches, we propose a Model and Search-based approach that will automate the process of test scenario generation while considering all parameters that can trigger self- adaptive behavior of UAVs in a swarm and will automatically report those scenarios where swarm can complete a mission without having any collision i.e. scenario where system can resolve conflict. We have used a multi-objective search algorithm NSGA-II for generating test scenarios and have applied our approach on an open source case study of swarm simulation model. We have compared our generated results with Random search for generating resolved conflicting scenarios for swarm. Through statistical results it has been proved that our approach performed better than random search in generating resolved conflicting scenarios.
"An Automated Approach to identify and
Mitigate the Order Dependent Flaky Tests
in Web Application Testing

Anmol Bilal (MS-SE)
Supervisor: Dr. Uzair Khan 
"	The rising importance of web applications has made the practitioners focus on their automated testing especially regression. Capture and Replay (CRT) tools are being widely used by the industry for web application testing due to their ease-of-use and facility of automated GM regression testing. The major challenge that is faced by not only industry giants such as; Google, Facebook, and Microsoft Windows is that regression testing often fails because of test case flakiness i.e. non-deterministic behavior. Testing failure leads to delayed releases, buggy systems, etc. Especially when a test suite build fails because of the test case flakiness; it impacts the system more adversely. As to have a successful build the tester has to locate the root cause of flakiness and then formulate an appropriate strategy of mitigation and then retest the build to ensure that flakiness has been removed. The number of flaky test cases increases heftily during continuous integration in the system under test. Existing literature available on flaky tests mainly focuses on exploring factors such as; dependency among test cases, concurrency, and Asynchronous wait; which are considered to be the major causes of the flakiness. The test case dependency is considered to be the topmost cause of test case flakiness in web application testing due to their high existential probability i.e. 50.5% as well as the effort required to their identification and mitigation in web application testing. Effects of dependent flaky tests have been widely known and explored by both practitioners and researchers over the years such as; maintenance cost increases with the number of test flakes, test suites tend to fail, a huge percentage of testing effort is spent upon their identification and mitigation. Existing approaches of identification and mitigation of order-dependent flakes require several re-runs of the test suite as well as several input parameters such as; execution logs, test suite execution orders (Both passing and failing) to work correctly. In this thesis, we propose an automated web application testing approach that will identify and mitigate the order-dependent flaky tests without re-running the test suite. The approach is evaluated by applying it to multiple case studies.
"Automated Test Case Generation for Testing of Lab view Code

Sara Ahmed (MS-SE)
Supervisor: Dr. Uzair Khan "	In the world of mechanical and electrical systems, embedded systems tackle different real-time constraints with the help of complex software engineering solutions. Software engineers are engaged in developing the software to control these embedded systems to tackle real-time constraints with the help of coding practices but certain challenges exist in the development of these softwares like the complexity that a developer encounters while encounters while coding without integrating hardware that makes the development time-taking and costly. The development environment of LabVIEW software overcome these limitations by offering an extensive list of hardware imitators and pre-made functions to create graphical code for normal systems and to produce prototypes, measurement sottwares and controllers for embedded systems which also tackles the real- time constraints. Most of the embedded systems are serving in safety-critical domains like avionics and automotive industry; therefore, the validation of the controlling softwares is a matter of utmost importance. Many testing strategies are proposed, but all of the existing testing techniques are generating the test cases manually for testing the LabVIEW application. There are some LabVIEW compliant testing frameworks that have just automated the test case execution but the test case generation process is manual. Considering this limitation, we proposed a model-based approach for the automatic generation of test cases that includes test data and test sequences for testing the graphical code of LabVIEW that reduced the human effort, the required time for testing and increase the efficiency of finding bugs. We evaluated our approach empirically by applying it on two open-source case studies.
"SECURITY RISK MITIGATION FOR INDUSTRIAL AUTOMATION SYSTEM  

Tehreem Saboor (MS-SE)
Supervisor: Dr. Irum Inayat "	Industrial automation gets more and more acceptance from industries due to its benefits, like high productivity, high quality, and safety at a low cost. But the introduction of digital technology and system connections with each other in industries creates the security-related vulnerabilities which can be exploited by security threats, leads to undesirable loss or accidents. However, safety and security are analyzed separately but they should not be. Both safety and security are interleaved because a security threat leads to the same dangerous accident or loss as a safety incident. Thus, identification, assessment, and mitigation of these vulnerabilities and risks become an important part of effective risk management. As increased attacks and threats on the automation system in the industry, make them less trustworthy. However, most targeted and consider security constraints are the integrity of data, availability, and also authentication of the system. Highlight and consideration have been paid on the security constraints like non-repudiation, confidentiality, integrity, and authentication. Lack of proper countermeasures and mitigation strategies lead to security breaches in the industrial automation system. Therefore, we imply the security risk mitigation guidelines for the industrial automation system that focused on the security constraints i.e., Confidentiality, Integrity, Availability and Data Freshness. Additionally, evaluate the abstract solution with the help of a case study have the domain of industrial automation system. As a result,applied the hybrid risk identification technique and identified the risk and assessed them with machinery specific standard and for risk mitigation suggest risk scenarios for both before and after the guideline that if there is an attack in the communication, the message inferred some delay and compromised the secure communication between them. The attack caused the packet delay and also packet loss in the communication. Moreover, it affects the performance in terms of time as of delays.For controlling the risk, the guideline is followed to control the attacks in communication and mitigate the risks.At last, results visibly state the before and after impact of identified risks in the light of mitigating guideline.We plan to apply the solution for other case studies rather than industrial cases to generalize our findings. Also, consider other industrial case studies and make a comparison for them. (Avionics, mission or safety-critical). We also planned to develop a tool to automate the overall risk assessment activities. Further work is done for other attacks regarding the application layer or network layer as well as for the physical layer to mitigate them for the improvement in the industrial automation security. Furthermore, it’s also in our focus, to design a trust-based solution that handles the Man in the Middle attacks. Mostly the risk assessment is done offline, which means find and predict the vulnerabilities, likelihood of occurrence, and evaluate the risks. However, Industrial Automation System (IAS) is a real-time automation system, dynamic risk management, and assessment methodology needs to be developed. 
"Skill Assessment of CS Students Using Active
Learning based Serious Game


Darshna Ishwar (MS-SE)
Supervisor: Dr. Irum Inayat "	"Serious games are used for learning purposes in CS education. The objective of serious games is to teach students through a distinct teaching style. The active learning practices are an important part of measuring and improving the learning outcome of students and analyzing the engagement of students in a new teaching style. The active learning practices are mapped with game designfactors and a game is developed which is used for increasing the learning outcome and student engagement in the game. A controlled experiment was performed for measuring the learning
outcome of students and after measuring learning outcome, student engagement in the game was analyzed by analyzing the form which was filled by the participants after the game played."
"Eliciting Usability requirements with the help of Implicit and explicit feedback

Fizza Shabbir (MS-SE)
Supervisor: Dr. Irum Inayat "	Usability requirements are focused mainly to satisfy the user’s needs related to the interface. Usability is a matter of concern for end-users. These users are considered as a potential basis of feedback for improving software applications. The feedback gathered from users is of two types i.e. implicit and explicit feedback. Implicit feedback is gathered from the interaction of end-users with the system and explicit feedback is in the form of textual reviews or comments on different platforms etc. The existing methods that are extracting usability requirements are based on natural language processing of social network discussions, reviews, and user forums, etc. Very few of them are considering implicit or explicit feedback as a source of usability requirements. In addition to that, no method has used both explicit and implicit feedback for getting usability requirements. Both types of feedbacks are necessary to include because one solves the limitation of the other. Therefore, the proposed solution is to use both implicit and explicit feedback for eliciting usability requirements. In our solution, we consider an e-commerce website and used both explicit and implicit feedback to elicit usability requirements of that website. Explicit feedback is collected from questions in the questionnaire that is based on usability factors. Whereas implicit feedback is based on user behavior like time, successful tasks, etc, and further mapped on the usability factors. In the results total of 12 usability requirements were elicited for the e-commerce website we used. There is a total of five usability factors used in this research but there are a lot more mentioned in the literature that can be used to elicit more usability requirements to move from better to best. In the future, the same algorithm and factors can be used for other domains e.g. gaming websites, mobile applications, desktop applications, etc.
"An IOT Security Analysis Framework for Smart Locks

Sadia Saleem (MS-SE)
Supervisor: Dr. Muhammad Asim"	Internet of Things (IoT) is a collection of smart devices that are physical objects, actuators and sensors. These devices may help in data and flow of this data among other devices throughinternet. IoT devices are developed to improve daily life in which smart homes devices are the most popular ones. Smart homes consist of a network of smart devices which belong to differentapplications for instance home automation, lighting control, smart door locks, smoke detector, smart TV and safety systems (surveillance cameras). Smart homes contain critical private information. In order to work properly they need to be secured to Due to this fact it demand strict security requirements. Disclosure of data or privacy breaches in IoT system shows some serious concerns with respect to security. Security of a smart lock is equally important as it controls the front door of the home. If smart locks are not secure, they will make the home vulnerable to threats. This thesis examine the security of smart lock system in smart home environment. We have made a threat model that defines valuable assets that needs to be protected, threats and attackers of smart lock environment. The model suggests a framework that investigate the security of smart locks. We examine few threats in our framework and associate different attacks with them. Test cases of framework is applied to components in smart lock environment. Smart lock system under DDoS attack shows that it uses server's resources. Brute-.force attack is evaluated using four smart locks application. Vulnerabilities shows that these applications lack security mechanism.
"Automated Diagnosis of DR and Serinity Detection. 

Zeeshan Shabir (MS-DS)
Supervisor: Dr. Omer Ishaq"	Diabetic retinopathy (DR) is a damage caused to the retina due to continuance of di-abetes. Retina is a thin layer of tissue that lies at the back of eye and is responsible for converting the light into neural signals and send these signals to the brain for vi-sual recognition. Basically diabetes is a disease in which body's ability to produce or respond to the hormone insulin is impaired, resulting in abnormal metabolism of car-bohydrates and elevated levels of glucose in the blood. Whereas, insulin is a hormone produced in the pancreas by the islets of Langerhans, which regulates the amount of glucose in the blood. The lack of insulin causes a form of diabetes. Worldwide, the prevalence of diabetic retinopathy is increasing at an alarming rate. A lot of work has been done at Fundus images in classifying the DR into multiple stages whereas very limited work has been done at OCT images while classifying into multiple stages of DR. The motivation of this work is robust and accurate detection of multiple stages of DR from low contrast images advancing towards improved funda-mental results based on OCT scans. In this research, we gathered our own dataset of OCT images having descriptive in-formation for multiple stages of DR than the existing datasets that have been used in earlier researches. We annotated this data into four classes: Normal (No DR), Mild/Moderate DR (Microaneurysms/Hard Exudates), Severe DR (Cotton Wool Spots) and Proliferative DR (Choroidal Neovascularization). We proposed a CNN approach by using transfer learning followed by individual detection of pathological regions by YOLO v3 to diagnose DR from OCT images leading towards accurate classification of multiple stages of DR. We trained specialized detectors that will be publicly available and help others in classifying single stage detection of pathological regions. Applying CNN approach to a dataset of OCT images, we achieved an accuracy of 94.73% and by validating our model over the two stages as Normal (Stage 0) and Proliferative DR (Stage 4) of an external dataset, we got an accuracy of 97.97%.
"Analyzing Bot like Behavior of Twitter Users using Public Features


Muhammad Aqeel Yasin (MS-DS)
Supervisor: Dr. Omer Beg "	People these days use electronic media to share their opinions and sentiments with the rest of the world. Social media platforms like Twitter facilitate 330 million monthly active users worldwide as of 2019. These users uses such platform to share their own opinion (tweets) and to share other person’s views (retweet) from which they were influenced. These communications play a very important role in judging the trend of an online community and help users to influence other users who follow them on these platforms. Unfortunately, many automated accounts (also known as Bots) try to manipulate these trends by observing the sentiment polarity in a community trend. To detect such Bots it requires complete personal information of a user profile through which we can categorize a user as a bot. Thus, using such personal information is not a good idea for the detecting the botness behaviour of a user. In this research we created a feature set from publicly available dataset we calculated from a trending hashtag. then we trained a model and aimed to improve the recall and f1 score of the model so that we cannot miss classify a botness behaviour considering the public attributes of a user. we achieved 0.68 model f1 score and 0.80 recall with 5-fold cross validation on our balanced dataset. Further analysis shows that Bots posses the typical properties and they are being more versatile in mimicking human behaviour in terms of Context deviation, Sentiment polarities and usage of other Trending Hashtags.
"Generic Neural Architechture Search using Transfer Learning 

Turab Ali Kazmi (MS-DS)
Supervisor: Dr. Hammad Majeed "	3#$aDeep learning becomes much popular due to its ability to extract features from un-structured data. This progress is mostly attributed to the design of neural architecture that extract better features. In recent years a lot of work is been conducted in neural network design that requires effort, time, and a lot of domain expertise. So there is a need to automate the neural network design that becomes the motivation for neural architecture search (NAS). NAS is a process of searching a neural architecture from search space. In recent work, search space is constrained with human bias. Many hyperparameters of the neural network kept fixed to reduce the exploration of search space in order to get the optimized network for specific problem keeping in view state of art human designed networks for that specific problem. This kind of human bias additions reduces the search space significantly however, this makes it unlikely for NAS to find architectures that are fundamentally different than human-designed networks and also results in task-specific approaches that are not able to generalize well over different domains. So to address these problems we have proposed an ap-proach without human bias addition. In our method we allowed architecture to learn all parameters / hyperparameters itself rather than restricting our search space. We proposed three level neural architecture search space exploration method that searches for neural architectures in multi-levels to make progress iteratively. Our proposed technique is generic that can be used for different problems without re-engineering of the entire technique and also maintain high accuracy over different problems. Our approach finds transferable (representative) architectures that perform well over dif-ferent datasets rather than only one dataset. Experiments have shown that our method gives highly competitive results in comparison with related approaches while being generic and compute efficient. Furthermore, transferring the architecture among dif-ferent datasets gives impressive results.
"Reducing Entropy Over Estimation in SAC

Hamid Ali (MS-DS)
Supervisor: Dr. Hammad Majeed "	In Reinforcement Learning agent learns in an environment through hit and trail. RL dynamic behavior allows the agent to learn in complex and difficult environments. In R1 its agentresponsibility to decide how he want to explore or exploit the environ-ment for learning. Recent proposed model free reinforcement learning methods have been successfully applied to many control and decision making problems. But these methods normally suffers from two major problems, first they need high number of samples for learning, second they are very sensitive to hyper parameter tuning. Be-cause of these problems RL methods cannot be successfully applied to many real life problems. Recent proposed off policy algorithm called Soft Actor Critic [1] [?] tries to overcome these problems through maximum entropy framework. In which actor tries to maximize entropy along with the expected discounted rewards. In SAC agent tries to be as random as possible while making sure it is moving towards the maximum reward. This randomness allows the agent to explore the environment and stops him from stucking into local optima. In this research we studied that maximizing the en-tropy causes the overestimation of entropy term. Which result in slow policy learning for agent. Because action distribution changes drastically whenever agent revisits the similar states. To overcome this problem we proposed Dual policy optimization frame-work, in which two independent policies are trained, both policies tries to maximize entropy but to reduce the overestimation it chooses actions against the minimum en-tropy. This underestimation results in better and faster convergence of policies. We demonstrated our approach on different continuous control simulated environments created by Mujoco [1. Results shows our proposed technique achieved better results against state of the art SAC algorithm and learns better policies.
"Earth Quake Prediction 

Waqar Saleem (MS-DS)
Supervisor: Dr. Hammad Majeed"	Prediction of time before the earthquake happens is major challenges in seismology and machine learning. Using the seismic signal from the shear laboratory experiments, we try to find the undetected periodicity in the signal. From frictional stick and slip characteristics of the material, we record the seismic signal in the form of continuous values and can be expressed in the form of sound waves. This data shows similar behavior just like natural earthquakes. Machine learning identifies the emitted signal from fault zone earlier it was considered to be noise. Earthquakes signals have been observed by analyzing statistical features. The properties of the signals are presented by applying machine learning models. A relation is observed between signal duration and magnitude, using that relationship we predict the time remaining before the next earthquake. This prediction from seismic signals leads to new understanding in fault physics.
"Auto Improving Neural Architecture Search for
Object Detection

Shakeel Ahmed Tariq (MS-DS)
Supervisor: Dr. Hammad Majeed"	Now a day Neural Architecture Search (NAS) has got top position for automating the machine learning and deep learning problems, especially for large scale image classification. But there have been very limited works focused on NAS for object detection due to its costly training pbaseS. For object detection a big computation power is required because NAS automatically find the best architecture that takes too much time and the accuracy is still too low. NAS usually start searching for models from scratch that requires too much computation power as well as no computation power is saved. In this work we have used pre-trained image classification models as a backbone for NAS. Our model used previous models and their weight and start searching for object detection model from that phase. The architecture search is performed on the trained backbone model using evolutionary algorithm based approximation method. In this way our model is trained in very less time as compared to the training from scratch and our resulting architecture will give good performance as compared to the handcrafted network models on COCO with much less training time complexity while keeping fast as we have used much simpler architecture and search space. The purposed model has reduced the time complexity by 40% as compared to base model while surpassing the base model by 2 point average precision .
"Anonymizing of Multi Valued Stream Data Set

Faizan Ahmed (MS-DS)
Supervisor: Dr. Hammad Majeed
"	"Privacy Preserving has taken much attention of researcher in this new era of technology when,industries have accumulated large amounts of data to discover useful knowledge. This poses many challenges i.e., preserve the privacy of data on one hand and maintain its utility on otheThand. The Privacy Preserving Data Publishing field (PPDP) has developed as a potential answer or such compromise, permitting information diggers to dissect the distributed information,while giving a sufficient level of security. Most existing anonymization approaches deals withsingle value nominal attribute of data. There are real world applications that generates stream of data which can be multi-valued attributes which is the case of Information loss. To our knowledge, there is no technique introduce in privacy preserving that deals with multi value nominal attribute and can maintain the trade-offof data privacy and data utility. In this paper, we introduce an approach "" Anonymization of Multi Valued Streaming Data"" for multi-value nominal data streams whose propose is to minimize the infomation loss and disclosure risk. The algorithm is implemented via five main steps: encrypt the multi value with a unique key,
stored in a dictionary data type and maintain it; create new clusters with respect to the incoming tuples; assign tuples in the appropriate cluster; observing each clusters in order to detect concept drift; and keep publishing of preserved tuples. Whenever a multi value is detected in a streaming, that valued will be updated with a new value without effecting the clustering procedure and publishing process. In our evaluation process, as multi value has never been handled before in PPDP, we analyze the performance of our multi value preserved algorithm and compare it with the removed comma algorithm and proved that handling multi value in the data not only increase the utility but also increase privacy.
"
"Player Based Cricket Team Ranking

Muhammad Zia Ul Haq (MS-DS)
Supervisor: Dr. Arshad Islam "	3#$aPredicting the winning team of a cricket match is a complex task. In cricket there are various statistics calculated for a player, team and ground. There are various prediction methods in which the winning team is predicted with some level of the accuracy. In this thesis, This research paper proposes a prediction method that is based on the current players that are part of the team. The IPL (Indian premier league) data used in this research paper is ball by ball data from 2008 to 2017 gathered from the kaggle. After pre-processing, cleaning and transforming the data into the required format, KNN (K nearest neighbour), SVC (Support vector classifier), DT (Decision tree), RF (Random Forest), GB (Gradient Boost) and LR (Logistic Regression) supervised machine learning algorithms are used to train the models on the data. The data is divided into the 80:20 ratio. The 80% part of the data is used for the training and the 20% for the testing. After getting the results form the very first experiment the accuracy of 82% is achieved. After the first experiments only first five players were considered as batsman because they have played the most balls in all the previous matches and the last 5 were considered as bowlers because they have bowled the most balls in the previous matches. After applying the same models on the updated data set the accuracy was improved by 15%. It reached the accuracy of 98% after that.
"Predicting citation count to evaluate the most influential paper award

Fatima Sadaf (MS-DS)
Supervisor: Dr. Arshad Islam "	The early discrimination between the influential papers and insignificant papers is significant for assessing the scientific achievements of researchers, teams, institutions and countries. It can help in addressing the processes in academic and scientific field, such as promotions, recruitment decision and funding allocation. The most influential paper award is given to the paper, ten year subsequent to their publication. The dataset used for the research is extracted from Microsoft Academic Graph(MAG). The data of five different conferences are used for evaluating the most influential paper award which are ICSE, ICFP, POPL, PLDI and OOPSLA. Research have been done on predicting the long-term citations to predict the future influence of the paper. Five different machine learning algorithms are used to prediction purpose. Gradient boost model was selected among them for predicting the citation count of the paper. The impact of time window and the citation gain patterns of awarded and non-awarded papers are analyzed after predicting the citation counts of the paper. The experiments shows that three to five years of time window is good enough to evaluate the most influential paper award. The Citation gain patterns of the awarded paper vary from the Citation gain patterns of non-awarded paper.
"Computational Prediction of LncRNA-Protien interaction using Machine Learning 

Muhammad Mushtaq (MS-DS)
Supervisor: Dr. Zoya Khalid "	By interacting with proteins, the key role of long non-coding RNAs shortly known as complements the experimental techniques for this function. lncRNAs is to regulate different biological processes and disease progression. The biological experimental approaches for predicting the interactions are tedious, laborious and expensive. Recently, to predict interactions amongst lncRNA and protein, a large number of computationally prediction methodologies have been reported, but they of ten have some prevalent flaws that limit their prediction efficiency. In current study, we proposed a computational method based on a similarity scheme that integrates features derived from sequence similarities (k-mers, physicochemical properties) and structure similarities (binding site and 2D RNA similarity) of proteins and lncRNAs.The features were trained on three different models namely logistic regression, SVM and XGBoost. The results obtained form XGBoost has achieved highest performance among all with accuracy of 98.68% and 98.71% F1 measure, with comparison to the state of the art had achieved 95.2%, 94.6% accuracy and F1 measure respectively. This demonstrates that the lncRNA protein interaction can be better predicted by incorporating both sequence and structure-based features and also
"An Efficient Approach for Frequent Periodic Pattern Mining

Muhammad Arslan Tariq (MS-DS)
Dr. Kifayat Ullah "	"Mining Periodic pattern is a fundamental problem in data mining, is applied in many domains, such as customer shopping cart analysis, weblog analysis and DNA sequence analysis. Although there are many efficient algorithms for mining Periodic patterns. However, each approach has its own disadvantages most crucial being the space requirements and the mining time is still high, especially for large datasets. Now the question is, how to overcome these limitations? Objective: The objective is to use an efficient approach and data structure with various other novel features to solve the problems of time efficiency and space requirements. Method: We will convert dataset into dynamic bit vector (DBV) format though which we will calculate the support candidate pair on fast way and reduce space. Then through (DBV) to discover all frequent periodic pattern. Results: Experiments are conducted to verify the effectiveness of (DBV) approach. The experimental results show that the proposed algorithm outperforms for mining periodic
pattern in terms of mining time and memory usage."
"Community Search in Attributed Graph 

Naveed Javaid (MS-DS)
Dr. Kifayat Ullah "	Community search is a well studied problem in literature to find similar and strongly connected vertices in a graph for a give set of query vertices. It can assist in finding similar structures in a large graph and has many potential applications in different do- mains, such as molecular biology, data science, and sociology. However, it is non-trivial to identify analogous communities in a large multi-attributed graph for a given query graph due to complex structure of underlying network. Majority of the existing ap-proaches either focus on structural or attributed aspect of the network for community search in a multi-attributed graph, while other are computation intensive. Therefore, we introduce a simple and efficient approach to find communities for a given query  graph using collaborative similarity measure (CSM) and representation selection strat- egy. We apply an incremental clustering approach to determine k sets of nodes from the original graph based on structural and attribute similarity. Afterwards, we find representative and most relevant vertices in each cluster using PageRank approach. In order to get optimal communities, we perform clustering coefficient based pruning on the resultant communities. The experimental analysis on various real-world graphs shows the effectiveness and efficiency of our approach in terms of execution time and results accuracy.Objective: The aim is to cluster a large-scale attributed graph where structural and attribute similarities are maximum. It is not simple ecausesystemic and attributable resemblances tend to be two distinct or even overlapping targets. Method: Our proposed solution takes unclustered graph and a query graph as input. We perform Intra-graph clustering by using existing algorithm CSM [1]. The maingoal of graph clustering is to discover densely connected sub-graphs in a large graph. Representative selection process provides the vertices which best represent the cluster. Pruning is performed by using clustering coefficient threshold value. Final output of the proposed solution is communities, which are most relevant to the input query graph. Results: We evaluated the effects of our approach and contrasted the results with the state of the art MDC, ACQ, QDC. Our results show that our algorithm reduces the time required to search the community by almost 50%, regardless of the size of the graph and no of query vertices. Furthermore, the results depicts that when it comes to sampling representative nodes, PageRank out-stands. Sampling 350 representative nodes from a network of 150,000 takes just a few seconds
"Summerization of Multidimentional Networks 

Muhammad Abrar Khalid (MS-DS)
Dr. Kifayat Ullah "	An intense amount of data is generated at every moment. Graphs are a great medium for analysis on large datasets. Summarizing a large graph helps in analyzing the graph more conveniently and overcomes several challenges. Different summarization tech-niques have been purposed in literature such as sparsification, sampling, and grouping approach. Among all these approaches, potentially useful information is removed from the graph resulting in a reduced sized graph. Consequently, the summarized graph’s information affects lessened. In the literature, such summarization approaches exist that helps in monitoring the utility of the graph while summarizing it. Monitoring the utility of graph during summarization is helpful since we can define a threshold for how much information loss is acceptable. Although there are few limitations in these approaches. The reconstruction of the summarized graph is computationally expen-sive when we are using corrections. In the case of reconstructing the graph without corrections, we have seen higher information loss. We will propose an algorithm that will allow us to summarize graphs while preserving its utility to a certain threshold. In this approach, we have identified the characteristics of supernodes which results in reducing the information loss of the reconstructed graph without maintaining the corrections.
"Ontology Evolution using Recoverable
SQL Logs

Awais Yousaf Chughtai (MS-DS)
Dr. Kifayat Ullah"	The database logs are useful for building the system design, upgrading, and checking which queries are running on applications. SQL Queries have used for building on- tology’s. Ontology is a knowledge-based system. It models the data that represents knowledge as a set of concepts. In the literature, query logs used to find patterns where the underlying data and database schema is not available. Although identifying new concepts from logs in a controlled environment is a challenge. Therefore in thipaper, we have proposed a methodology to identify new concepts from SQL logs and evolve the ontology. Therefore to recover the SQL logs, we have used the prefix trees.
"“Urdu ki duniya”- An assistive learning
technology for dyslexic children




Arooba Shabbir (MS-SE)
Dr. Amna Basharat"	Dyslexia is a lifelong learning disability that causes various kinds of learning problems including reading and writing problems in people. To date, most of the research on dyslexia has focused towards the English language but no contribution towards Urdu language has been found. No evidence of learning technologies, design guidelines or any other work towards Urdu language difficulties of dyslexia has been found in literature. To address this issue, we explored the existing Urdu learning applications that have been designed for non-dyslexic children. The purpose of exploring these applications was to identify if the existing technologies can help dyslexic children with their Urdu reading skills. In order to review these applications, we derived design guidelines for dyslexia that can be applied on Urdu language-based technologies and reviewed the existing applications based on those guidelines. The applications were also reviewed on the basis of learning content for dyslexic children. Results showed that none of the applications fulfilled sufficient design guidelines and learning content hence proving that no existing application can be used to help dyslexic children with their Urdu learning skills. Therefore, in this study, we have designed a mobile application in accordance with the design guidelines for dyslexia as well as the appropriate content for dyslexic children. Our center of interest is to provide a teaching aid to the teachers of dyslexic children as well as help such children improve their Urdu reading skills. The design of our mobile application was evaluated by five evaluators who also evaluated top five existing applications based on the review done earlier. We compared the results of theevaluation performed on our application and the top five applications which proved our application to be the most suitable and sufficient. We also evaluated the acceptability of theapplicationamong experts (therapists) and teachers of dyslexic children based on technology acceptance model TAM. Results from the evaluation procedure shows a positive indication on the acceptance of the application by the therapists and teachers. This study also provides design recommendations that can help in designing Urdu learning applications for dyslexic children in future.
"Predicting protein folding rates using machine learning 

Aleena Kayani (MS-CS)
Supervisor: Dr. Hammad Naveed"	Proteins are basic unit of each cell in body. Proteins are functional only when they fold into a specific 3D shape. The Misfolding of proteins can lead to certain disease like Alzheimer's. The prediction of folding rate of proteins can lead to determination of the root causes of these disease. In this study, we have used machine learning algorithms to predict the change in folding rate of protein, and performed feature engineering to only obtain relevant features required for this prediction. The model is expected to improve or at least maintain the reported accuracy by using a feature subset, generated from both sequential and structural features. We further divided our dataset into three classes for classification and predicted each class using ML models like SVM, DT, ICN.-N and LR.
"Emergency message dissemination for flying adhoc networks (FANETS)

Hannan Ali (MS-CS)
Supervisor: Dr. Kashif Munir"	Flying ad-hoc network or FANET is a special form of Mobile Ad-hoc network. As the technology progresses in the field of electronics, communication systems and sensors, the production of the small Unmanned Air vehicle (UAV) becomes possible. The multi-ple UAVs have the potential to unlock the capabilities that are beyond the limitations of the single UAV. The network of the multiple UAVs is known as Flying ad-hoc network or FANETs. There FANET can be used for several civilians, commercial and various military applications. FANET communications have the features like central control, self-organizing, and ad-hoc nature, which could extend the communication and connectivity range of infrastructure-less area. FANETs are rapidly deployed infrastructure less, flexible, self-configurable and is relatively small and less expense network. Broad-casting an emergency message in FANET is crucial for different search and rescue missions. The current emergency message broadcasting techniques are specially de-signed for the predictable moving VANETs and slow movements of MANETs ad-hoc network in 2D environment. The purpose of this research is to formulate a dissemination technique of an Emergency Message in FANETs for delay-tolerant application like search and rescue operations. The proposed Greedy-OLSR is specially designed for the dissemination of the message in the 3D environment. The simulation results show that the proposed G-OLSR technique reduces the message latency and overhead in comparison with an existing OLSR approach.
"Efficient Flexble Periodic pattern Mining 

Muhammad Fasih Javed (MS-SE)
Supervisor:Dr. Kifayat Ullah"	Finding Flexible periodic patterns in a dataset are of great importance especially because of their ability  to detect patterns with unimportant events  in between.  There are multiple algorithms with various different approaches for finding these patterns. However, each approach have  itsown  disadvantages  most  crucial  being  the  redundant  pattern  generation  and  space requirements. Now the question is, how to overcome these limitations? Current  algorithms  uses  tree  structures  to  for  flexible  periodic  pattern mining  but  they  still require a significant amount of time when traversing the tree structures especially when dealing with  large  datasets.  The  use  of  tree  structure  also  requires  a  significant  amount  of  extra information which  isn’t needed to mine  the patterns. So, the objective  is to use various novel properties to tackle the problems of time efficiency and redundant patterns problem. We used Apriori based approach combined with an occurrence vectors to find flexible periodic patterns and reduce the time and space required for mining the patterns by eliminating the tree structures and  their  related  information. We measured  the performance of our proposed approach and compared  the  results with  the  FPPM. Our  results  show  that  our  algorithm  reduces  the  time required  to mine  the patterns  to almost 50%,  regardless of  the size of  the data or  the period value for which we are mining patterns for, while keeping the space required in the same range as that of the FPPM.
"Text classification using ensemble method

Muhammad Saad Javed (MS-CS)
Supervisor: Dr. Omer Beg "	In recent years, the number of online reviews has grown rapidly especially in the case of products and services. Many websites allow consumers to post reviews for products and services. These reviews have a great impact on businesses. These reviews give help customers to decide whether to buy a particular product or not. And hence, these reviews are having a direct impact on the consumer’s purchasing decision. The opportunity of posting online reviews opens the doors for the spammers to post the fake reviews (spam), reviews that are not written by genuine consumers. Fake reviews sentences also being generated by automated bots. These reviews have a direct impact on the reputation of products and businesses. Furthermore, consumers have been misleading. Fake reviews are not only misleading the organizations but also preventing them from accurately collect the information of reviews and making a good decision. Thus, the detection of reviews as f ake and real has become more important. The detection of fake reviews is of practical significance as compared to real. In this work, we propose a novel approach for the detection of fake reviews by using linguistic and semantic features as well as reviewer behavior. We determine the review embedding with a wide convolution neural network. Words used in fake and real reviews are much similar. These embeddings are helpful in distinguishing words of the fake and real reviews. We use ensemble methods to combine different models that are trained in a different search space. Models are trained with distinct features subsets. To the best of our knowledge, no previous work has been done which combines Textual, Non-Textual and behavioral features by using an ensemble method to extract the fake reviews. We evaluate our approach on publically available Yelp Filtered Dataset, which is labeled by the Yelp filtering system. Results showes that our methodology is better than previously proposed techniques. We achieve 92% accuracy on the restaurant Yelp Filtered Dataset.
"Utilizing the Extractions of Bio-Medical Named Entities from Unstructured Data with Deep Neural Networks 

Muhammad Sajid Ali (MS-CS)
Supervisor: Dr. Ejaz Ahmad "	"Patients utilizes medical related social media platforms like Askapatient.com and Drugs .com to share about their health experiences and treatments with each other. Data on these platforms is huge in nature and contains health related information, such as Bio-Medical Named Entities like Drugs, Disease and Adverse Drug Reactions (ADRs). Data on these platforms is unstructured (i.e. not organized) and required automated methods to process and mine useful information. Extraction of such useful informa- tion from unstructured text falls into the category of a sequence classification problem. In this classification problem, each word in a sequence is assigned a label (i.e. is it desired entity or not). Label for each word in a sequence is predicted on the bases of its characteristics and contextual information. Deep Neural Networks such as Re- current Neural Network (RNN) utilizes such contextual information by taking word embedding as input features. In the past, not just in medical domain but also in other domains researchers have been feeding RNN with pre-trained general embedding’s frequently. This arises a question, is there a need to train domain specific embedding in the presence of these pre-trained general embeddings. However, various work has utilized domain knowledge along with word embedding’s to optimize neural network performances. In this study, we observed the effect of domain specific and pre-trained word embedding over BILSTM for extracting six bio-medical entities, Drug, Disease, Symptom, ADR and Findings from benchmark CADEC and DrugNER dataset. We utilized two types of NER encoding schemes for sequence labeling: IO and IOB. To evaluate BILSTM performance, we utilized existing evaluation metrics Precision, Re- call, F1-score and Micro Average. It is observed that BILSTM model performed 10% better on benchmark CADEC dataset with domain specific embedding as compared to general embedding in terms of F1-Score. Further, on DrugNER benchmark, model trained with domain specific embedding, extracted 6% more new drugs than model trained with general embedding in terms of F1-Score. Moreover, we have also intro- duced weak matching similarity technique to integrate extracted entities, especially ADR with an existing collection of MeddRa ADR entities.
"
"Efficient Deep Learning Algorithms For Face Recognition

Muhammad Shaoor Siddique (MS-CS)
Supervisor: Dr. Sibt Ul Hussain"	In computer vision, deep learning-based face recognition system achieves state of the art results (in terms of accuracy) on face-detection, -alignment and -recognition. To achieve high accuracy mostly people have used ensembles of deep networks. These ensemble networks are not particularly useful for practical usage because they are too slow at inference time. To reduce inference time of deep learning-based face recognition system we give two main contributions in this thesis: (i) Due to the unavailability of bench-marking on inference time of face recognition standard pipeline. we compute benchmarks on face-detection and -recognition to estimate total inference time taken by each single image/frame. (ii) we apply compact convolutional layers such as depthwise and pointwise convolutions for feature extraction and detection with different fusion layer using WiderFace dataset. These compact convolutions holds fewer number of parameters and has less computational cost which helps to reduce inference time. The overall aim of this proposed work is to reduce inference time of deep learning-based face recognition system.
"MBOR Prediction Using Time Series
Analysiss 

Muzammil Hussain Shahid (MS-CS)
Supervisor: Dr. Arshad Islam"	"As the size of investment for movie production rises, the significance to correctly predict the profitability of a movie in the early stages has increased manifolds. In order to support the decision to invest in movies, it is important to predict the profitability of movies at the time of the investment. Researchers have investigated the movie profitability prediction in the pre-production phase using metadata-based features but they have not explored the aspect of the movie genre popularity that changes with time. The pre-production phase has limited basic information for a movie, and it is a challenging task to predict the movie profitability at this stage. Therefore in this research, utilizing time series analysis, multiple ""Genre popularity"" based features are proposed. In this research, the proposed ""Genre popularity"" features are temporal in nature and are defined in terms of budget, revenue, frequency, success, and Return on Investment (ROI). This research also investigated the genre's importance and its impact on movie profitability. The existing pre-production features along with the proposed ""Genre popularity"" based features are used to train and evaluate multiple classifiers to predict the success of the movie. Gradient boosting classifier performs better than other classifiers so it is selected for evaluating and comparison of the research. The addition of the time series based ""Genre popularity"" features has made a significant improvement in the results to predict the success of the movie, i.e., the accuracy of 92.4%. The results of the experiments show that this work has improved the results obtained by earlier methods by 8.3%. It is observed that by changing the release time of a movies, profitability class of 62.84% movies has been changed after the inclusion of temporal ""Genre popularity"" based features which shows release time does influence the ROI based classes when the release time of the movie is altered. Hence, the study suggests that releasing a movie when its genre is popular, will have higher chances of success."
"Bi-Model Smartphone Fallback Authentication  

Numan Ghuffar (MS-CS)
Supervisor:Dr. Asma Ahmad"	As the size of investment for movie production rises, the significance to correctly predict the profitability of a movie in the early stages has increased manifolds. In order to support the decision to invest in movies, it is important to predict the profitability of movies at the time of the investment. Researchers have investigated the movie profitability prediction in the pre-production phase using metadata-based features but they have not explored the aspect of the movie genre popularity that changes with time. The pre-production phase has limited basic information for a movie, and it is a challenging task to predict the movie profitability at this stage. Therefore in this research, utilizing time series analysis, multiple “Genre popularity” based features are proposed. Inthisresearch, the proposed “Genre popularity” features are temporal in nature and are defined in terms of budget, revenue, frequency, success, and Return on Investment (ROI). This research also investigated the genre’s importance and its impact on movie profitability. The existing pre-production features along with the proposed “Genre popularity” based features are used to train and evaluate multiple classifiers to predict the success of the movie. Gradient boosting classifier performs better than other classifiers so it is selected for evaluating and comparison of the research. The addition of the time series based “Genre popularity” features has made a significant improvement in the results to predict the success of the movie, i.e., the accuracy of 92.4%. The results of the experiments show that this work has improved the results obtained by earlier methods by 8.3%. It is observed that by changing the release time of a movies, profitability class of 62.84% movies has been changed after the inclusion of temporal “Genre popularity” based features which shows release time does influence the ROI based classes when the release time of the movie is altered. Hence, the study suggests that releasing a movie when its genre is popular, will have higher chances of success.
"Machine learning driven load shedding in parallel CEP

Qurat Ul Ain Aftab (MS-CS)
Supervisor: Dr. Muhammad Adnan Tariq "	with the advent of technology Internet of Things has become quite popular in the world. Millions of sensor devices are connected, dealing with billions of incoming event streams originating from input sources. These massive event streams are processed by operators in Complex Event Processing to interpret particular situations. Complex Event Processing is a framework to process single or multiple events and to identify meaningful event pat-terns from multiple event streams. In the area of parallel CEP, related work has mentioned a few traditional approaches of operator parallelization, i.e. a key-based, a batch-based or a window-based. Operator parallelization reduces the input load through horizontal scal-ability. However, it has the significant drawback of correctness in high peak loads. At high peak loads, some essential events are randomly dropped at a single point in time. So the concept of load-shedding got highlighted. Through literature, it is known that all existing load-shedding approaches are limited to specific query operators and are not able to achieve correctness in abnormally high data rates, which is a prime requirement of a CEP system. So, the challenge here is to decide where and how many events should get drop with mini-mal effect on correctness. To solve this problem we proposed a black box approach. In black box approach it does not matter what query operator is being used as only the inputs and outputs of the query operator are being observed. Deep learning models are applied to learn patterns from the observational data and the model predicts which events should get drop.
"Automatically Solving Arithmetic Word Problems Using Supervised Machine Learning Classifiers

Sana Waheed (MS-CS)
Supervisor:Dr. Omer Beg "	Computers can perform complex calculations faster than a human being and it can save time too. However, automatically generating equations for math word prob-lems is extremely challenging Artificial Intelligence problem. During recent years, there has been a growing interest in automatically solving math word problems. Significance of MWP solvers can be helpful in many ways, be it learning systems for students, personal assistants, or in understanding the essential steps for solving math word problems. In our research, we discuss the work done on three different types of word problem such as, arithmetic, algebra, and geometry but the main fo-cus is on arithmetic word problems. After collecting a large number of questions from different resources we finally formulate a dataset in json format. The number of questions we collected are approximately 4k. In this research work, we introduce a novel approach for solving arithmetic word problems using supervised machine learning classifiers, like Decision Tree, Random Forest, Neural Network, Logistic Regression, one vs all (neural network), and one vs all (logistic regression). As our base work, we have selected S. Roy and D. Roth declarative knowledge method and MathDQN. Our feature extraction process has been inspired by the base work. Our feature extraction process has been inspired by the base work. Our models performs 1 to 2 percent better than base models on one operator and performs 10 to 12 per-cent better than the base models on two operator. We have achieved 79 percent of fl-score on one operator and 89 percent on two operator arithmetic word problems. In future, we will expand our work for algebraic and equation set problems as well.
"QSR: A Quantifiable approach towards
Social Relationship Analysis

Sibgha Anwar (MS-CS)
Supervisor:Dr. Omer Beg "	"""Despite significant recent progress in relationship analysis, the introduction of a quan-tifiable social relationship model presents a challenge to existing approaches. In this
 work, we introduce a novel approach QSR to identify the social relationships between agents based on their textual conversations. In this research, our task is to classify
 eight types of relationships named as Close Acquaintance, Superficial Acquaintance,Consanguine, Conjugal, Mentoring, Diverse Work, Annoying Acquaintance and Un-
 desirable. Sentiments and Interactions are the two key features of our research. Wefollow eight different rules to extract these interactions.For the comparison between features,
we use state-of-the-art embeddings named asword2vec, GloVe, and Bert. Our model uses the data of Cornell Movie Corpus. For this purpose, we adopt two methods for feature
 engineering. The first method is the direct method in which we extract features directly through the state-of-the-art embeddings.In a combined method, we integrate our proposed 
features with embeddings and then analyze the results of both approaches. We use different matrices for evaluation of results. After various experiments, we achieve our high score
 through the combined method. By integrating our proposed features with BERT embedding, we obtain thebest f1-score for relationship classification task is 89% through Neural Networks."""
"Ctrust: A control layer-based Trust Mechanism for Supporting Secure Routing in PRL-based IoT Applications

Temur Ul Hassan (MS-CS)
Supervisor: Dr. Muhammad Asim"	Internet of Things (IoT) fostered a new epoch of innovation by interconnecting digital devices to make human life more convenient and attractive, for instance smart home, smart healthcare, etc. These smart objectives are largely developed as low power and lossy networks (LLN) to provide innovative services in various application domains, such as smart cities, smart health, smart community, etc. The LLN is a class of networks where the interconnected devices are highly resource-constrained (power, money, processing etc.) and are characterized by high loss rates, low data rates and instability in the communication links. The Engineering Task force (IETF) has designed a lightweight IPv6network routing protocol called routing protocol for LLNs (RPL), which facilitates the communication between LLN-based network device. However, the PRL routing protocol is extremely vulnerable to large variety of both external and internal attacks in order to cause devastating and calamitous effects. The scope of this thesis revolves around internal attacks only, where nodes are already part of a legitimate network. Therefore, trust-based security helps in establishing a secure and reliable routing by excluding selfish and compromised node. Various trust based mechanisms have been proposed to secure PRL protocol from insider attackers. However, existing trust mechanisms have high energy depilation due to complex computation on the node level, which consequently decreases the performance of LLNs. This thesis presents a hierarchical trust based mechanism “C Trust-RPL” With three layers: node, sink and control layer for trust analysis. We also compare the proposed mechanism with two state-of-art techniques. Our mechanism demonstrates a superior performance over other in detecting and isolating black hole attacks. The results depict that CTrust-RPL detected and isolated 30 more malicious nodes than SecTrust-PRL in the same time lapse. The average packet loss ratio difference was less for our proposed mechanism with 35% more energy conservancy.
"A Decentralized Lightweight Blockchain-based Authentication Mechanism for IoT Systems

Umair Khalid (MS-SE)
Supervisor: Dr. Muhammad Asim"	The Internet of Things (IoT) is an rising paradigm branded through heterogeneous technology comprised of smart ubiquitous items which are seamlessly related to the Internet. These objects are frequently deployed in open environments to offer revolutionary services in diverse utility domains such as smart health, smart communities, and smart cities. These IoT devices produce a large amount of data that is securitysensitive and confidential. Thus, security of these devices is very important in order to ensure the safety and effectiveness of the system. In this paper, a decentralized authentication and access control mechanism is proposed for lightweight IoT devices and is applicable to a large number of scenarios. The mechanism is based on the technology of the fog computing and the concept of the public blockchain. The results gained from the experiments demonstrate a remarkable performance of the presented mechanism when compared to a state-of-the-art blockchain-based authentication technique.
"Capacity Planning of Fog Network for Time Critical Tasks


Ume Kalsoom Saba (MS-CS)
Supervisor: Dr. Kashif Munir "	Due to the massive growth of IoT applications and challenges of a Cloud network, Fog computing emerged to immediately process requests from time critical applications. Fog network provides local -aggregation, analysis, and processing of IoT requests that may or may not be time critical. One of the major issues of Fog network is capacity planning considering the stochastic traffic loads of time-critical. The processing time can be huge If a lime critical request is processed on Cloud.The processing time of a time critical request can be big on Fog layer if they are not prioritized, Hence, there is a need to handle the time critical traffic on priority basis at the Fog layer, A priority queueing model with preemption has been proposed considering the mixed types of requests at the Fog layers The proposed approach determines the required number of Fog nodes in order to satisfy the desired QoS requirements of loT requests, The proposed mechanism is evaluated through simulation using iFogSim simulator.
"Generation of AI Character for Fighting Game Using Evolution Inspired Approach

Usama Imtiaz (MS-CS)
Supervisor: Dr. Hasan Mujtaba "	For many years. AI in .games have been studied as games are perfect for providing scenario for testing artificially intelligent approaches. However, the momentous goal of studying AI in games is that most of the games agent lack intelligence .The agent is unable to mimic human player's strategy to make game more engaging and adaptive. Usually deterministic scripts are used for the game-based agent, but these scripts are easily exploitable .To address the problem a multi swarm technique based agent is proposed .The proposed agent is able to adapt and mimic the actions performed by the human player.The agent has shown promising results during the evaluation against human players and the standard Al's.
"A Novel Binary Opt-aiNet for Feature Selection Optimization

Warda Rasul Malik (MS-CS)
Supervisor: Dr. Waseem Shahzad "	Feature Selection a significant importance in the classification domain. To get better accuracy results the feature selection should be optimized. We know from our experiments that using full feature vector does not give the best accuracy, so an optimized subset of feature vector is required to improve classification. We are proposing a binary opt-aiNet for feature selection optimization. SVM will be used for classification and comparisons. The datasets are taken from the UCI archives. The results show improvement in the accuracy results after the implementation of our proposed algorithm.
"A new method for multivariate regression problem for improving fitness in Genetic Programming

Sharan Gohar Khan (MS-CS)
Supervisor: Dr. Hammad Majeed"	"In this thesis research genetic programming (GP) for symbolic regression problem with multivariate points is evolved to produce better fitness. Normally GP is a good method for symbolic regression problem, it produce significant results outperforming human generated results. Genetic Programming is a powerful method but it has a downside of high computation cost, over-fitting, premature convergence and high error rate. These problems are more glaring when GP has difficult to envolve data points. If these points are few and high importance GP will not produce good results. In this search a novel approach is used for connecting this issue for GP to have a full potential, this method is simple and cost effective this technique is used for multivariate regression problem for improving fitness.This method steps include pre-processing step by transforming the problem from a multivariate problem to a single variable problem by using Dimensionality reduction technique of principal Component Analysis. The difficult to evolve points are identified in the new transformed problem by using technique of difficult first strategy (DFS). Using DFS technique the strategy has bias toward the difficult points and in the latter stage easy points. By using this technique it’s made sure that GP spends maximum time evolve the difficult points the results show that with this technique higher generalization of the model and higher fitness is produced using the same fitness evaluations.Our technique was evaluated with common known metrics of convergence speed, fitness and variance in the best results. Results have shown 10-15% improvement from standard GP. This result has also reduced computation cost while still maintaining better quality results with 30-50% less computations to match the best performance of Standard GP.
"
"Feature correlation based sensor data reduction using RICE compression

Muqaddas Sarwar (MS-CS)
Supervisor: Dr. Hammad Majeed"	Wireless Sensor Networks (WSN) has been used for monitoring time series datasets. Long duration recordings of multisensory networks generate a large amount of data that need a huge amount of storage and network bandwidth. Data reduction dra-matically reduce the transmission cost and lengthen the lifespan of the network. One of the biggest challenges for multisensory data analytics is to aggregate data in an energy-efficient manner. To resolve this issue, many recent researchers focused on data reduction using methodologies of compression before forwarding it to the main server. The main objective of Our proposal is to produce a minimized form of the dataset which would be useful in recognition of activities of the smart home. This reduced form of the dataset would be as helpful as the original dataset in the activity recognition process. Our proposed study based on a lossless compression algorithm with a two-step process which mainly focuses on data reduction with no degradation. In the first step, redundancies that occur in raw sensor data being eliminated to get a refined form of a dataset. Secondly, data gathered from the previous step is embed-ded in the next level for generating an encoded file of the dataset using compression. This encoded dataset travels through transmission media to the main server and de-compresses this data before using it for further processing. The raw sensor is collected and preprocessed by removing redundant features using feature correlation. Layer 1 is responsible for generating a feature set from raw sensor dataset and gen-erate a correlation matrix on the bases of most correlated features. This correlation between features are compared and on the basis of the threshold value, highly cor-related features are dropped. A value is set to check the relationship between two features named as f-value. After removing every feature, f-value is measured in each case to decide whether to keep this feature or not on the basis of relationship and de-pendence of this feature with others. This would let the data removing with no quality reduction.
"Group Thermal Comfort for HVAC Buildings using Machine Learning Algorithms

Muhammad Fayyaz (MS-CS)
Supervisor: Dr. Asma Ahmad"	Thermal comfort is the condition of mind that expresses the satisfaction of thermal environment. Thermal comfort systems providing a comfort living and better productivity of individuals. In recent years research is focused on thermal comfort using machine learning algorithms. Using thermal comfort ranges of individuals multiple occupants can be entertained. In this thesis work we will propose a novel machine learning based approach for human thermal comfort sensation. In this work we used publicly available dataset ASHRAE RP-884. First pre-process the raw data then han- dle missing values accordingly and balance the class imbalance dataset. Apart from that we proposed a novel machine learning base approach to predict human thermal sensation vote. We evaluate our approach’s results using 10 fold cross-validation with current state of the art Fanger’s model which gives the accuracy of our approach is 86.08% versus 35.4%. Furthermore, our results are outperformed the base paper re-sults that had the accuracy of 76.7%.
"Handover authentication latency reduction using mobile edge computing and mobility patterns

Fatima Abdullah (MS-CS)
Supervisor:Dr. Kashif Munir"	With the advancement in technology and the exponential growth of mobile devices, network traffic has increased manifold in cellular networks. Due to this reason, latency reduction has become a challenging issue for mobile devices. In order to achieve the seamless connectivity and minimal disruption during movement, latency reduction is crucial in handover authentication -process. Handover authentication is a process in which legitimacy of the mobile node is checked, when it crosses the boundary of an access network.
"Issues identification and prioritization in discussion forums

Asad Abdul Hameed (MS-CS)
Supervisor: Dr. Waseem Shahzad"	Users create a lots of posts on the technical support forums, these posts often contain information about particular issues/problems faced with the product. Typically, the posts that have most comments or views are considered issues, however this might not always represent which issues are adversely affecting the user. Therefore we want a computational methodology to identify which issues are affecting the users. Previous work on this topic involved lexicon based sentiment analysis, in which sentiment of the text is analyzed to check the severity of an issue. However, that ap-proach has its limitations. In this research, we have used Aspect Based Sentiment Analysis (ABSA) in which sentiment regarding each aspect about a product/service is captured. For this purpose semeval 2016 task 5 dataset is used, data is also scraped from Samsung forums to improve out of domain ABSA results and stored in a nossl database. The text data is preprocessed by doing normalization, expanding contrac-tions and noise removal. Named entity recognition (NER) is also performed, keyword based bootstrapping approach is utilized for capturing words like 'Samsung Galaxy S7'. Using Standford CoreNLP, a dependency parse tree is generated and Rule Based ABSA (RB-ABSA) is applied to fetch all the aspect entity pairs. Context resolution vec-tor is used to accurately predict the entity associated with an aspect. Sentiment values are predicted using Sentiwordnet lexicon. Using RB-ABSA, we managed to extract all the aspect-entity pairs. The pairs with negative sentiment represented the problems that the users are facing with a product. We evaluated our methodology by measuring Fl-score of extracting aspect, entities and sentiment from sentences of the posts. We also used our methodology on the unseen dataset and evaluated its performance using out of domain dataset from SemEval'16.
"Activities Prediction in Smart Homes


Rafi Ullah Khan(MS-CS)
Supervisor: Dr. Labiba Fahad"	"People spend most of their times in homes so need of incorporating all potential facil-of combining predictive model with sequential models. Cities with conventional households appliances. Creating smart, protected, and healthy environment for the aged, impaired, and handicapped people is the main objective. Re-duction of power wastage and other daily features such as Heating, cooling, lighting home safety systems, health care services, and manipulation of other home applica- tions are other important tasks to be achieved. Human behavior is complex in nature, and information regarding human emotion or physical signals is hard to detect and predict activities and its appropriate classes. Various statistical and probabilistic approached have been proposed to predict user activities in a smart home. One of the  most important and crucial problem is the less accurate prediction of activity classes that occur rarely. Such activity classes can’t be correctly predicted using direct proba- bility. In smart home, two different types of models are used for prediction purposes; predictive and sequential models. The main problem in applying predictive models is the less accurate result but it has less computational cost. Sequential models provide higher prediction accuracy. The main problem in learning models occur due to noise, bias and variance which effect the performance of an individual prediction model. En-
semble models are useful by merging multiple models into a single model in order to assist in hiding the weaknesses of each single model. The ensemble approach considers only correct predictions of sub models which results in higher accurate outcome. Experimental evaluation shows the importance"
"Exploring Impacts of Weight Initialization and Input on Deep Reinforcement Learning Trained Autonomous Driving Agents


Shoaib Mehboob (MS-CS)
Supervisor: Dr. Sibt ul Hussain"	"Training autonomous driving agent using supervised learning through human demonstrations cannot be trusted enough because it is impossible to have a dataset covering all the possible scenarios of real driving. Alternatively, using Deep reinforcement learning algorithms to train driving agents looks natural choice because such agents learn through their own experience by exploring the environment. However, the difficultyof using deep reinforcement learning for driving task is that such agents cannot be trained in real environment, because cost would not only involve money but can alsorisks lives. Second problem is the low exploration efficiency for large continuous action space, which prohibits the use of these algorithms for such complex tasks. Tohandle the first problem, we train our agent in Carla, a high fidelity car simulator.Second problem is addressed by exploring over constrained action space using mix-ture of supervised learning andreinforcement learning. In this thesis, We explore three different approaches that incorporate mixture of supervised and reinforcementsignals to exploit the domain knowledge gathered through training our agent on hu- mans demonstrations. Our agents are then exposed to explore the environment withthe complex cases successfully, which are not part of demonstrations. In the first ap- proach, we use the exact methodology as proposed by [1] in which the agent istrainedonhumans demonstrations and then fine-tuned by training using Deep Deterministic Policy Gradients(DDPG), which is deep reinforcement learning method for continuousoutput. In second and third approach, We made enhancements to existing technique of [1], that help in speeding up the training process during second phase i.e training using DDPG. In the second approach, rather than transferring weights of pre-trained model to actor only, we also share convolutional layersweights with critic as well. In third approach, in addition to what we did in second approach, we also divide the network into two parts, features network and succeeding network. At any time step, we pass five recent images through features network and then forward the average of those CNN features to succeeding network. After further training for identical num- ber of epochs in Town1 under different weather conditions, we show that, both of our approaches help in speeding up the learning and result in better success rate.
"
"Data access and performance enhancement using physical design and logical implementation paradigms 

Maryam Shahid (MS-CS)
Supervisor: Dr. Ejaz Ahmed "	Database tuning signifies a process ensuring that the database application runs effec-tively and meet its performance goals. Database tuning is a broad dimension, how-ever in our research, we are managing the physical and logical implementation of the database. We are targeting row-based storage for our research. Our methodology incorporates tuning techniques such as Partitioning, Clustering, Indexing and opti-mization of queries. The Elapse time is calculated after tuning the database on the proposed tuning technique. Our objective also is to ensure that query transaction time is minimized, without compromising the accuracy and consistency of the database. A large Medcare dataset is utilized for the experimentation of this research work. We aim to optimize the query and transaction time of the row-based database by tuning the physical design. Partitioning of the schema is managed with respect to the database table and data complexity. Clustering technique is applied with variations in the clus-tering parameters used in RDBMS Oracle. In logical implementation, complex range queries are used for the experimentation to measure performance. Queries are opti-mized to decrease the elapse time and increase the efficiency of the database. After managing the proposed tuning techniques, the resulting elapse time is compared with the elapse time of the default installation of Oracle. The comparison validates the ef-ficiency of the proposed technique. The statistical analysis demonstrates the relation between the various tuning parameters and their impact on the query and transaction time.
"An Effective Way to Classifying the Semi-Structured Research Articles

Sumbal Ashraf (MS-SE)
Supervisor: Dr. Ejaz Ahmed"	"Due to the drastic increase in the research publication, numerous of research articles are available electronically on different digital libraries online. The proper structured research articles are relatively easily approachable as compared to semi-structured and unstructured research articles, and sometimes the reader does not get accurate results on different digital libraries as the research articles are not classified properly. Neglecting the semi-structured and unstructured published research not only causes gap deficiency but also affects the results of the proposed techniques and citations for other articles. Usually, researchers exclude these kinds of research papers. Due to these semi-structured research papers; the proposed technique does not yield effective results. Classification techniques have been applied before on structured papers but no significant work has been performed towards classification of semi-structured and unstructured research papers. Therefore, this research focuses on the classification of semi structured research articles using different supervised classification techniques so that most accurate and large amount of relevant research results will be received. For experimentation, a labeled dataset was used for the classification of semi structured papers. The dataset we used for
experimentation comprised of manually gathered research articles from Santos dataset and labeling them accordingly. We go through thousands of research articles from Santos datasets to gather these semi-structured research articles. Usually, semi-structure research articles lack keywords; we used different python libraries (TF-IDF, gensim) to extract keywords from those papers which later acted as dataset to train the models we build for classification. The current study used four different supervised classification techniques which includes Support Vector Machine (SVM) classifier, Naïve Based classifier, K Nearest Neighbor classifier and Decision Tree classifier. Comparison was performed between these supervised classification techniques to see which classifier gives more accuracy and F-score. The unit of measure selected to compare these classifiers are: accuracy, recall, precision and f-score. Evaluation was performed on the basis of classifiers results and compares it with the cluster of semi-structured labeled research articles. We manually convert structured paper into semi structured papers and then apply the same technique on the new dataset of converted structured papers.
"
"Emotion Mining of Open Source Software Developers

Syed Muhammad Uzair Ghalib (MS-SE)
Supervisor: Dr. Irum Anayat"	Software development is a collaborative activity in which software developers interact with each other to create a software system. Whenever there is interaction, it evokes emotions. Recent studies show that developers experience a wide range of emotions and these emotions effect the team performance and quality of a software. There are many studies regarding the analysis of developer emotions but less is known about the effect of emotions on developer performance and contribution. Our work is focused on providing an analysis of the developer's sentiments with respect to different parameters. One of the main aspects of the work is providing an analysis of committers emotions in commit comments with its contribution to the project. Analysis of the effect of time with emotion in commit comments has also been done. Syuzhet R package is used for sentiment analysis of commit comments. Results of the analysis show that negative emotions increase with time while positive emotions decrease. In release months of the projects fear, anticipation and trust have highest percentages. Top contributors are expressing more negative emotions in the commit comments as compared to positive emotions, while least committers show more positive sentiments as compared to negative emotions. The most central users have more positive emotions if compared to negative emotions.
"Congestion avoidance in wireless sensor networks using software defined networks

Ahmed Nawaz Khan (MS-CS)
Supervisor: Dr. Adnan Tariq"	Wireless Sensor Networks (WSN) have numerous applications in different fields, such as automation process in industries, patient monitoring in e-health systems, ac-tivity monitoring in surveillance system or in fire detection system all of these systems are categorized as Time Critical Systems(TCS). In such TCS, aspects of Quality Of Ser-vice (QOS) are highly concerned. There are multiple reasons for not satisfying these Q0S conditions, and queuing delay could be one of them. In the case of multiple applications relaying data on the same network in a distributed environment would cause the suboptimal path selection. This suboptimal path selection would cause the queue on the multiple nodes. In this study we have considered SDN based WSN approach, in which we uti-lize the logically centralized controller to get an overview of the whole network. This overview of the network helps to identify those potential nodes on which queue is pos-sible. We have considered multiple application environment in which each application have different time constraints to be satisfied for delivering data from its source to a destination . In order to meet these time constraints we have utilized the paths diver-sity so that the such potential nodes can be avoided. The proposed technique will find such combination of paths for each source to destination pair that will cause minimal increase in average queue length of the whole network thus reducing induced queuing delay.
"Emotion detection from Urdu text 


Muhammad Farrukh Bashir (MS-CS)
Supervisor: Dr. Waseem Shahzad"	Emotion Detection (ED) plays an important role in finding peoples interest in any field. A human can use gestures, facial expressions, speech and texts to describe their emotions. A lot of research work has been done to detect emotions from the textual data in English and other languages. But due to unavailability of the labeled corpus, emotion classification has not been explored in the Urdu language to the best of my knowledge. In this thesis, we propose a new technique for the classification of emotions in the Urdu language using Long Short Term Memory (LSTM). We have also created a diverse dataset of sentences and paragraphs based of ED and labelled it. This is a multi-class data set and has six classes. We have performed an extensive experimentation to check the worth of proposed technique using state of the art performances measures including F-Measure, accuracy, precision etc. The experimental results showed that the proposed technique performed better than the other state of the art techniques.
"Balanced quantum inspired evolutionary algorithm


Muhammad Shahid Sharif (MS-CS)
Supervisor: Dr. Hasan Mujtaba"	Quantum evolutionary algorithms promised great improvement in fast convergence and solution quality due to their properties like qubit representation, superposition and entanglement. Despite these benefits, pre-mature convergence is the main issue of QEA because QEA uses the only best individual to update quantum population. In this thesis, we have introduced a new way to update the quantum population of QEA to avoid premature convergence. Best individual and worst individual are used for up-dating the population for balanced exploration and exploitation. The balance between exploration and exploitation maintains enough diversity in population to avoid pre-mature convergence. Knapsack problem and lane reservation problem are selected for experiments and testing of BQEA. The knapsack problem is about an optimal selection of items from a repository to maximize profit while keeping the total weight under the limit. Lane reservation problem aims at optimal selection and reservation of lanes that minimize the negative traffic impact. Experiments are performed on different sizes of the knapsack problem and BQEA is performing better than the state of the art QEA's.
"Load balancing and response time reduction of IoT requests through vehicular fog networks 

Ahmad Raza Hameed (MS-CS)
Supervisor: Dr. Kashif Munir"	Recently, many real-time IoT-based applications have been developed that require min-imum response-time from traditional cloud networks. Fog paradigm has been intro-duced to efficiently address the time constraints of real-time critical applications, by providing cloud-like services near the IoT devices. A bunch of vehicles is connected together to form cloudlets, which can process the requests of IoT devices. Due to enough resources of storage, communication, and computation, we consider vehicles as Fog devices. In order to utilize vehicular Fog devices, we devise a mechanism which manages mobility of Fog devices and data load across the vehicular devices. The proposed mechanism works in two folds: clustering among mobile Fog devices and capacity-based load balancing among clusters. The clustering algorithm efficiently builds clusters and selection of a cluster head based on the Fog mobility factor. The mo-bility factor consists of position, relative speed, and direction of vehicles, which iden-tify the time to leave the vehicles from clusters. In addition to reduce the congestion in the network, capacity-based load-balancing algorithm is introduced, which efficiently balances the load within a cluster and among the clusters. Furthermore, during com-munication, capacity-based algorithm utilizes the network energy resources efficiently and manages response time of devices during the offloading of data from one device to another. The simulation results validate the proposed mechanism that performs well in terms of load distribution, energy efficiency, network output and end-to-end delay in the network.
"Word sense disambiguation for Urdu 


Muhammad Umair Arshad (MS-CS)
Supervisor: Dr. Waseem Shahzad"	Typically, there are words in all languages which may have multiple senses/meanings. The meaning/sense associated with a word is referred to as the Word Sense. In ad-dition, ascertaining the correct sense of such a word with reference to its context and use is called Word Sense Disambiguation (WSD). This research focuses on WSD for the Urdu language. Previously, a lot of work on WSD has been performed for the English language, but WSD for Urdu is still in infancy due to rich morphological structure of the language. Therefore, there is a need to explore whether the techniques used for other languages work well on the Urdu language. Moreover, a number of initiatives have resulted in the development of the WSD corpora benchmark for a wide range of languages from different language families. Nevertheless, there is an absence of bench-mark WSD corpora for South Asian languages including Urdu, despite more than 300 million Urdu speakers and a lot of digital Urdu text online. The importance of this exploration is amplified by the fact that WSD is very crucial for some core problems of NLP like information retrieval, machine translation, speech processing, question answering and, text categorization tasks etc. Previous work uses machine learning algorithms like Naive Bayes, decision trees, SVM etc. In this thesis, we explore the use of Long short-term memory (LSTM) for WSD for Urdu language. It is a supervised learning algorithm for WSD on Urdu dataset. We applied different baseline algorithms like SVM, Decision tree, Naive Bayes and Random Forest on our dataset. For testing, we used k-fold validation. Extensive experiments have been performed to evaluate our approach. The results showed a better F-measure than SVM, Decision tree, Naive Bayes and Random Forest. For the proposed approach, the maximum F-measure was recorded over two hundred and seventy-one million words raw Urdu corpus.
"Empirical investigation on requirements change management practices in Pakistani agile based industries 

Kanwal Batool (MS-SE)
Supervisor: Dr. Irum Anayat"	Requirements engineering is the key process of software development. Effectively dealing with changing requirements is a critical characteristic of software engineering. A significant characteristic of the agile process model is that' change is an integral part of the software development process. The question arises in our mind that which requirements change management practices are the utmost to follow? Through a questionnaire-based survey, we explored the Pakistani software development industry to identify the processes, methods, practices being followed by the agile practitioners for requirements change management, and ranked them based on the perceived importance. We identified 30 practices for agile requirements change management from literature study, and conducted a survey with 140 agile practitioners. We used a Multi-criteria Decision Method (MCDM) ranking method i.e. PROMETHEE family of methods for ranking of the relative importance of the practices. The findings of this research recommend the most important and highly ranked agile requirements change management practices. Moreover, in numerous cases, the perceived importance of the change management practices depends on the type of the software project (e.g. methodology, domain and type of application or project).
"Usability assessment of an mHealth app for real-time patient monitoring 

Qurat Ul Ain(MS-CS)
Supervisor: Dr. Amna Basharat"	Over the recent years smartphones and tablets have become the most popular and widespread types of mobile devices. Sophisticated features and advanced comput-ing capabilities of mobile devices have been incorporated in the field of health, called mHealth, has proved to be revolutionary in the improvement of this field. A grow-ing number of mobile health technology-based apps (mHealth apps) are being devel-oped, however, evidence on their usability and effectiveness is limited but crucial for their successful implementation. A large number of self-monitoring mHealth apps are available which are used by patients themselves and many usability studies for such applications can be found in literature. However, patient-monitoring apps differ from self-monitoring apps due to their specific design features and specialized context of use i.e. clinical setting. Evidence is sparse in literature regarding usability assessment and design recommendations for patient-monitoring mHealth applications. This re-search uses the case study of a patient-monitoring mHealth app called Clinical Events Annotator (CEA app) which is currently being used in a Neonatal Intensive Care Unit (NICU) of Childrens Hospital of Eastern Ontario, Canada (CF1E0). CEA app is used to annotate events like patient monitor alarms, clinical interventions, routine care, and patient movements on critically ill babies at their bedside, in real-time. In the first iter-ation of this study, an expert-based heuristic evaluation was conducted with usability experts aiming to determine anticipated usability problems in the app using Nielsens 10 heuristics. The results of heuristic evaluation indicated that the most frequently violated heuristics were flexibility and efficiency and user control and freedom. The expert-based testing was complemented by a usability testing conducted with a group of 15 participants from the medical science domain. The usability parameters evaluated were effectiveness, efficiency, acceptability, error rate, learnability and user satisfac-tion. Based on the findings from the experts and users, CEA app was redesigned and again tested with another group of fifteen representative users to evaluate the impact of redesign on the usability of the app. The redesign was found to significantly in-crease usability of CEA app in terms of effectiveness (p-value<0.05 = 0.0000219), error rate (p-value<0.05, = 0.00018), learnability (p-value<0.05, = 0.000001934), acceptabil-ity (p=value<0.05, = 0.0281), efficiency (p-value<0.05, = 0.0000304). Moreover, partici-pants ranked CEA app as having high user satisfaction on PSSUQ questionnaire (mean = 2.00). This research contributes to the existing literature in terms of an empirical evi-dence on usability assessment of a patient-monitoring mHealth app using two usability evaluation methods: expert-based and user based. Moreover, as a result of this study, usability of a real-world case study; CEA app is improved. Furthermore, the results from the study are contributed as generalized design recommendations which will guide designers and researchers in future development of patient-monitoring mHealth apps.
"Identification of JUnit Test Smells that Impact Test Case Maintenance

Shafaq Riaz Bhatti (MS-SE)
Supervisor: Dr. Muhammad Uzair Khan"	"Testing is crucial when it comes to maintain the quality of software systems. There are many guidelines to write quality tests but violation of those guidelines introduces the concept of test smells i-e symptoms of poor design and implementation choices in test code. Smelly tests are reported to have a negative impact on maintainability and indicates a need of refactoring. Not all the smells could be refactored due to time and budget constraint. So, there is a need to identify which smell cause more changes and increase the maintenance effort that smell should refactor first. The goal of this study is to reduce the maintenance effort by realizing the impact of the smell on maintenance and to increase the awareness of both researchers and practitioners that have dealt with the maintenance issue that are caused by test smell. In this thesis, we conducted a mining study on major repositories to find out which test smell have great impact of on the maintenance. We considered number of changes as a measuring factor of maintenance. To find the impact of each smell, we had to 
incorporate the number of changes while prioritizing. So for this purpose, we extracted the number of commits in addition to the number of smells in a test file and combined it to find the impact of each smell and the smell that have more impact on changes will assigned higher priority. Furthermore, we found the occurrences of each smell in test files as well as in test methods which can provide practitioners an outline that which test smell occur frequently in real world scenarios and how many methods in a file are smelly.From the obtained results, we analyzed that the smells that occur frequently are not the smells that causes more changes.We also found out that Assertion Roulette, Exception Catching Throwing and Magic Number test smells occur more frequently in test cases as well as in the test methods. Likewise, it is observed that on average, the files that have Empty Test, Magic Number, Lazy test smells, cause more changes and have more impact on maintenance. So, these smells should be refactor first."
"Predicting cancer outcomes from medical images using deep learning algorithms

Maria Tariq (MS-CS)
Supervisor: Dr. Hammad Naveed"	The mortality rate of Breast Cancer in women has increased in both west and east due to late diagnosis. So, early detection is important to improve the survival rate. In our work, we use deep learning models toclassify breast cancer in fourclasses, Normal, Benign, InSitu Carcinoma and Invasive Carcinoma. We use prominent pre-trained convolutional neural network models, Inception-v3 model and ResNet50. These modelsareapplied to whole slide medical images for classification and to automatically recog nize the region of interest on patch level. Moreover, we compare these two pre-trained models and merge them in to anEnsembled Model. We evaluate 10 pixel-wise labeledwhole slide images,extracted from ICIAR grand challenge, each for a different patient. Our Ensembled model (Acc: 78%) outperforms the Benchmark accuracy (Acc: 69%).
"Code smell detection using machine learning 

Bazelah Ghaffar (MS-SE)
Supervisor: Dr. Irum Anayat"	"Context: Bad smells are warning signs due to bad designing techniques or implementation decisions. Code smells is also termed as design inconsistencies or faults that corresponds to design situations badly influencing the maintenance of software. Hence, code smells should be detected efficiently and accurately for building enhanced quality software, less prone to failures and easily maintainable. Machine learning is used efficiently in various research areas for detection purposes, such as fault detection, fake news detection, plant disease detection, pattern recognition, etc. There are already various machine learning approaches used in the identification of bad smells. Machine learning approaches eliminate great expert knowledge or the cognitive load of individuals and consume less time. Objective: However, existing machine learning approaches are not scalable and use the limited dataset for code smell detection. Moreover, according to the Literature, there is one code smell which is not detected through already available bad smell identification approaches. That is ""Alternative classes with different interfaces"". Detecting this smell benefits developers or coders in designing enhanced quality software, less prone to errors. Efficient machine learning approaches are used in order to detect this bad smell type. Dataset is prepared manually comprising of ""Alternative classes with different interfaces"". Features are extracted from the dataset which is best suited for the detection of this particular smell type. Methodology: Non-parametric statistical test is applied on the dataset. An empirical evaluation is conducted, in which different machine learning approaches are evaluated in terms of their detection rate. Result: According to the experiment performed, it is observed that Decision Tree achieved the highest accuracy in 10 fold cross validation i.e. 91.25%. Therefore, it is the best-suited algorithm for the detection of ""Alternative classes with different interfaces"". However, Na{candra}ve Bayes achieved the lowest accuracy (82.5%) and is not much effective for the detection of this particular smell."
"Designing a Serious Game Model Using Problem Based Pedagogy

Fatima Gillani (MS-SE)
Supervisor: Dr. Irum Anayat"	"Serious games are educational games as they succor people to learn about a subject. They are intended in teaching subject to players more than just emphasizing on player&#39;s amusement and entertainment. Their primary objective is to teach and train players. Regardless of the many prevailing design frameworks, these games are too often developed in an ad-hoc manner while overlooking the use of pedagogical aspects. In this thesis, we are aiming to address this issue by designing a serious game model using Problem based learning Pedagogical aspects that will assist the serious game designer in the design process. Also, some game factors have not been considered for serious game model development. For this first, we have mapped the problem based learning principles with the game design factors to implement the pedagogy throughout the model and identified the game design factors that are Collaboration, Feedback, Control, Autonomous, Freedom, challenge, Reward/Punishment, Scenario Exposition, mystery. Secondly, expert reviews were conducted for the evaluation of the proposed model from the perspective of the serious game researcher that results in the review and modified version of the serious game design model. Thirdly an open source Robo Bug game has been altered based on the proposed model and controlled experiment was conducted to check the impact of problem based pedagogical mapped game design factors on the learning outcomes. The evaluation of results indicates that problem based pedagogical mapped game design factors have a positive impact on the learning outcome of students through serious games
"
"Computational characterization of Protien-peptide interaction 

Shahnila Rahim (MS-CS)
Supervisor: Dr. Hammad Naveed"	Protein-peptide interaction is an important part in cellular processes and related with different human diseases. To analyze these cellular processes and diseases it is essential to learn these molecular details of interaction. Peptides are difficult to study experi-mentally due to its flexibility and transient nature. Thus, the computational methods for predicting binding affinity are needed. In the proposed work, I have extracted the structural features from protein-peptide complexes and used them to predict the bind-ing affinity. The features extracted are binding energy, hydrogen bonds, contact maps, VDWaals, conserved region, eluted ligands, angles, peptide length and etc. Moreover, the model is trained on all subs-types of MHC class 1 protein and with its preferred peptite length which is 9 aa. Several machine learning classifiers are used i.e. random forest, SVM, neural network, decision tree, KNN and a ensemble model to analyze the performance of the model and achieved a maximum fl-score 0.86. In comparison to the previous state-of-the-art NETMHC-4.0, achieved 0.71 fl-score.
"An improved ant miner for hierarchical classification

Syed Muhammad Saad Salman (MS-CS)
Supervisor: Dr. Waseem Shahzad"	There are many classification algorithms for handling data with binary or nominal class labels. As compared to this classification less attention is being given to the classification algorithm for handling data where classes are in hierarchical taxonomy. In hierarchical classification problem the classes that are upper level in the hierarchy are usually abstract and are easy to predict, as we go deeper in the hierarchy the classes are more specific. The number of examples for classes at the upper levels of the hierarchy are more than the number of examples at deeper level, this creates class im-balance problem at the deeper levels of the hierarchy and the classification gets more challenging at the deeper levels. We have proposed an ant-miner based approach for hierarchical classification. In this method we used two search spaces for class hierarchy and terms graphs respectively. Further we have proposed a heuristic function for se-lecting terms for rule construction. This function helps us to overcome class imbalance problem and avoids overfitting. In the proposed technique we have tow pheromone function, One function is use for desecrate attributes while other function is used for continuous attributes. The continuous pheromone function helps us to use continuous attributes without discretization. We have used Roulette wheel based selection method for updating the pheromone on the path, Which helps us to converge quickly avoids convergence to a local optima. We have applied this method on Six different dataset in-cluding ion-Chanel data sets and two data-sets from UCI machine learning repository. The proposed algorithm performed better than the available solutions in the literature in terms of specificity and prediction accuracy.
"Automated test data generation for data-intensive systems

Maheen Arshad Malik (MS-SE)
Supervisor: Dr. Zohaib Zafar Iqbal"	3#$aData-intensive systems make use of a vast amount of data and their essential operations are strongly dependent on the correct specification of data. These systems impose different types of constraints at the schema level and make rigorous use of queries to implement their complex logic. Some types of data-intensive systems are highly critical. such as safety-critical systems and financial systems. Hence, testing these systems is of utmost importance as faults in these systems can have acute consequences for the end users and other stakeholders. In case of automated testing of data-intensive systems, a significant challenge is to generate the test data that satisfy all query level restrictions and constraints which are applied for the enforcement of consistency, validity, and integrity of data. Existing test data generation techniques proposed in the literature have a limitation that these approaches are not able to generate data for all schema level constraints. Furthermore, there is no automated approach available that can eenerate data for queries containing multiple joins and other SQL operators and these existing approaches are not even scalable for large and complex systems. Hence there is a need for an automated approach that can address all these limitations. Therefore. in this thesis, we propose an automated test data generation approach that generates valid instances of test data satisfying both the queries and schema level constraints simultaneously and provides higher query coverage.
"Handling dependencies and uncertainties in requirements prioritisation

Khush Bakht Ijaz (MS-SE)
Supervisor: Dr. Irum Anayat"	3#$aIn order to deliver a good quality software product, both its Functional requirements (FRs) and Non-Functional requirements (NFRs) must be considered in earlier stages of software development life cycle. NFRs are usually ignored due to time-intensive software development specifically in agile methods. However, neglecting them during prioritisation phase may lead to inaccurate estimations for software projects resulting in high maintenance cost. For prioritisation, identification of the inter-dependencies among requirements is foremost. Nevertheless, the stakeholders are not always familiar with the dependency types that can possibly occur between requirements. Another major factor involved in the intended neglect of the NFRs is the inherent uncertainties. The uncertainty factor in NFRs makes it difficult to get accurate priority values. The subjective and uncertain nature of NFRs makes them unfit to be prioritized using conventional prioritisation methods. Therefore, the literature lacks prioritisation approaches developed for NFRs, in particular. The few existing NFRs prioritisation approaches also have some associated limitations i.e. scalability issue (inability to prioritise large number of requirements), improper uncertainties handling and ignorance of dependencies among FRs and NFRs. Moreover, many of these NFRs prioritisation approaches are not evaluated using case studies. We address all these issues, by proposing a meta-model that not only deals with multiple types of dependencies among requirements but also handles various uncertainties inherent in them. Suggested approach is also capable of prioritizing varying sized requirements datasets. Proposed Meta-Model has been evaluated by conducting an experiment using the data from the case study of Smart Home System comprising of 200 requirements (FRs and NFRs). Requirements have been prioritised using (i) Interval type-2 Fuzzy Logic and (ii) Technique for Order Preference by Similarity to Ideal Solution (TOPSIS). The reason for using two prioritisation techniques in the evaluation of our meta-model was to assess and compare their strength in terms of accuracy, efficiency, and scalability thus discovering the best. The dependencies among requirements were identified prior to prioritisation step. Prioritisation results produced by applying both of the above-mentioned prioritisation approaches were compared with each other. Experimental results confirm that Interval Type-2 Fuzzy Logic produces accurate results as compared to TOPSIS. Moreover, it is also better than TOPSIS in terms of efficiency. Therefore, we conclude that it may be best to use Interval Type-2 Fuzzy Logic for prioritising a large number of uncertain requirements i.e. (200 or more). Besides this, we also discovered that the Risk factor contributes the most in calculating final priority values using both TOPSIS and Interval Type-2 Fuzzy Logic. We also proved the applicability of proposed meta-model in the context of large number of software requirements and successfully managed various types of dependencies and uncertainties in them during their prioritisation. Our research adds to the existing body of knowledge and motivates the practitioners to focus on NFRs prioritisation along with FRs by highlighting the limitations of the existing prioritisation methods.
